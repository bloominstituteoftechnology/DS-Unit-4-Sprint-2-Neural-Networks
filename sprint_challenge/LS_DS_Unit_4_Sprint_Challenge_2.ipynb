{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "\n",
    "A neuron is a single node of a neural network that takes input, sums values of the input, applies an activation function,\n",
    "and then sends output.\n",
    "\n",
    "- **Input Layer:** \n",
    "\n",
    "The only layer of the neural network connected to the dataset, where each feature used in the model is input.\n",
    "\n",
    "- **Hidden Layer:**\n",
    "\n",
    "A hidden layer is a layer between input and output. They are considered hidden because they take input from\n",
    "the previous layer as opposed to the dataset.\n",
    "\n",
    "- **Output Layer:**\n",
    "\n",
    "The layer of the neural network where the final value is output. The layer has One output node for regression problems\n",
    "and for classification problems there are as many output nodes as there are categories.\n",
    "\n",
    "- **Activation:**\n",
    "\n",
    "The activation function is a function applied to the weighted sum before output from one layer moves on to the next.\n",
    "\n",
    "- **Backpropagation:**\n",
    "\n",
    "Back propagration is the method of using information from the cost function to recursivley update the weights\n",
    "of previous layers to reduce loss and improve the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "<!--\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "Name: ate, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks baseline\n",
    "candy['ate'].value_counts()\n",
    "\n",
    "# 50/50 split so baseline would be 50% to always guess one way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = np.array(candy[['chocolate', 'gummy']].values)\n",
    "y = np.array(candy['ate'].values)\n",
    "\n",
    "# reshapes y\n",
    "y = y.reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting sigmoid functions\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)\n",
    "\n",
    "# defines a function to create binary predictions\n",
    "def binary_predict(x):\n",
    "    predictions = []\n",
    "    for i in x:\n",
    "        if i < .5:\n",
    "            predictions.append([0])\n",
    "        else:\n",
    "            predictions.append([1])\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation values:\n",
      " [[0.18823174]\n",
      " [0.18831957]\n",
      " [0.18823174]\n",
      " ...\n",
      " [0.18823174]\n",
      " [0.18823174]\n",
      " [0.18831957]]\n",
      "\n",
      "Average error: 0.2675655007619143\n"
     ]
    }
   ],
   "source": [
    "# set iterations\n",
    "iters = 1000\n",
    "\n",
    "# set learning rate\n",
    "lr = .01\n",
    "\n",
    "# set initial weights\n",
    "weights = 2 * np.random.random((2,1)) - 1\n",
    "\n",
    "# updates weights for the ammount of times in iters\n",
    "for _ in range(iters):\n",
    "    \n",
    "    # gets weighted sums\n",
    "    w_sum = np.dot(X, weights)\n",
    "\n",
    "    # activates weighted sums\n",
    "    act_out = sigmoid(w_sum)\n",
    "\n",
    "    # gets error\n",
    "    error = y - act_out\n",
    "\n",
    "    # finds adjustment value and applies learning rate\n",
    "    adjustments = lr * error * sigmoid_derivative(act_out)\n",
    "\n",
    "    # updates weights\n",
    "    weights += np.dot(X.T, adjustments)\n",
    "     \n",
    "# returns most recent activation values        \n",
    "print(f'Activation values:\\n {act_out}\\n')\n",
    "print(f'Average error: {error.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy score: 0.2764\n"
     ]
    }
   ],
   "source": [
    "# gets predictions\n",
    "y_pred = binary_predict(act_out)\n",
    "correct_predictions = np.sum(y_pred == y)\n",
    "total_predictions = len(y)\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Acuracy score: {accuracy}')\n",
    "\n",
    "# accuracy only about half that of the baseline majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for the perceptron is low because this is very similar to the XOR problem.\n",
    "If a pieice of candy is just gummy or just choclate a child is very likley to eat it,\n",
    "but if the candy is both or neither the child is not likley to eat it. The perceptron\n",
    "can not seperate these outcomes effectivly and thus has a poor accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, inputs, hiddenNodes, outputNodes=1):\n",
    "        self.inputs = inputs\n",
    "        self.hiddenNodes =  hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        self.inputWeights = np.random.randn(self.inputs, self.hiddenNodes)\n",
    "        self.hiddenWeights = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "        \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1-s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        self.hiddenSum = np.dot(X, self.inputWeights)\n",
    "        self.hiddenActv = self.sigmoid(self.hiddenSum)\n",
    "        self.outputSum = np.dot(self.hiddenActv, self.hiddenWeights)\n",
    "        self.outputActv = self.sigmoid(self.outputSum)\n",
    "        \n",
    "        return(self.outputActv) # used as output for backward\n",
    "    \n",
    "    def backward(self, X, y, output, learning_rate=.1):\n",
    "        self.outputError = y - output\n",
    "        self.outputDelta = learning_rate * (self.outputError * self.sigmoidPrime(output)) \n",
    "        self.hiddenError = self.outputDelta.dot(self.hiddenWeights.T)\n",
    "        self.hiddenDelta = self.hiddenError * self.sigmoidPrime(self.hiddenActv)\n",
    "        self.hiddenWeights += self.hiddenActv.T.dot(self.outputDelta)\n",
    "        self.inputWeights += X.T.dot(self.hiddenDelta)\n",
    "        \n",
    "    def train(self, X, y, epochs=100, learning_rate=.1):\n",
    "        for _ in range(epochs):\n",
    "            output = self.feed_forward(X)\n",
    "            self.backward(X, y, output, learning_rate=learning_rate)\n",
    "        self.loss = np.mean(np.square(y - self.feed_forward(X)))\n",
    "        print(f'\\nLoss after {epochs} epochs was {self.loss}\\n')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = self.feed_forward(X)\n",
    "        predictions = []\n",
    "        for i in output:\n",
    "            if i[0] >= 0.5:\n",
    "                predictions.append([1])\n",
    "            else:\n",
    "                predictions.append([0])\n",
    "        self.predictions = np.array(predictions)\n",
    "        \n",
    "    def check(self, y):\n",
    "        correct_predictions = np.sum(self.predictions == y)\n",
    "        total_predictions = len(self.predictions)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        return(f'The model had a {accuracy} accuracy score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss after 10000 epochs was 0.05125916383849586\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The model had a 0.9458 accuracy score'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates an instance of neural network class\n",
    "nn = NeuralNetwork(inputs=2, hiddenNodes=8)\n",
    "\n",
    "# trains network and gets loss\n",
    "nn.train(X, y, epochs=10000, learning_rate=.01)\n",
    "\n",
    "# creates predictions\n",
    "nn.predict(X)\n",
    "\n",
    "# checks the models accuracy\n",
    "nn.check(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Multilayer perceptron works better because it can adapt to the non-linearity of the data in a way that the perceptron could not.\n",
    "The model could not get a perfect score because some kids were brave enough to try bad candy, and there was no feature for the model to detect this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "238   77    1   0       125   304    0        0      162      1      0.0   \n",
       "55    52    1   1       134   201    0        1      158      0      0.8   \n",
       "200   44    1   0       110   197    0        0      177      0      0.0   \n",
       "184   50    1   0       150   243    0        0      128      0      2.6   \n",
       "170   56    1   2       130   256    1        0      142      1      0.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "238      2   3     2       0  \n",
       "55       2   1     2       1  \n",
       "200      2   1     2       0  \n",
       "184      1   0     3       0  \n",
       "170      1   1     1       0  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puts data into numpy array\n",
    "X2 = np.array(df.drop(columns=['target']))\n",
    "y2 = np.array(df['target'])\n",
    "\n",
    "# reshapes y\n",
    "y2 = y2.reshape(303,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiates scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# scales values\n",
    "X_t = scaler.fit_transform(X2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates train test split\n",
    "X_train, X_test, y_train, y_test = tts(X_t, y2, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 13)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks shape of X to know how many input nodes to have\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'weight_func': 'RandomUniform', 'optimizer': 'Adam', 'input_act': 'sigmoid', 'hidden_nodes': 5, 'epochs': 100, 'dropout_rate': 0, 'batch_size': 10}  --- Which gave an accuracy score of 0.8161764815449715\n"
     ]
    }
   ],
   "source": [
    "# sets number of inputs\n",
    "inputs = 13\n",
    "\n",
    "# sets up paramaters to tune with initial values\n",
    "param_grid = {'batch_size': [10],\n",
    "              'epochs': [100],\n",
    "              'optimizer': ['Adam'],\n",
    "              'input_act': ['sigmoid'],\n",
    "              'hidden_nodes': [5],\n",
    "              'dropout_rate': [0],\n",
    "              'weight_func': ['RandomUniform'],\n",
    "              }\n",
    "\n",
    "# defines function for building model for keras classifier\n",
    "def create_model(optimizer, input_act, hidden_nodes, dropout_rate, weight_func,):\n",
    "    mod = Sequential()\n",
    "    mod.add(Dense(hidden_nodes, input_shape=(inputs,), kernel_initializer=weight_func, activation=input_act, name='input'))\n",
    "    mod.add(Dropout(dropout_rate))\n",
    "    mod.add(Dense(hidden_nodes, kernel_initializer=weight_func, activation=input_act, name='central')) # uses same activation/weight initializer as input layer\n",
    "    mod.add(Dense(1, activation='sigmoid', name='output'))\n",
    "    mod.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return(mod)\n",
    "\n",
    "# create model\n",
    "mod = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# creates grid\n",
    "grid = RandomizedSearchCV(estimator=mod, param_distributions=param_grid, n_jobs=1, cv=3)\n",
    "\n",
    "# fits grid\n",
    "grid_fit = grid.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score = grid_fit.best_score_\n",
    "best_params = grid_fit.best_params_\n",
    "\n",
    "# prints results from inital run through\n",
    "print(f'Best Params were: {best_params}  --- Which gave an accuracy score of {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'weight_func': 'RandomUniform', 'optimizer': 'Adam', 'input_act': 'relu', 'hidden_nodes': 10, 'epochs': 100, 'dropout_rate': 0, 'batch_size': 100}  --- Which gave an accuracy score of 0.8088235309457078\n"
     ]
    }
   ],
   "source": [
    "# adds more values to paramater grid\n",
    "param_grid2 = {'batch_size': [100, 200, 300],\n",
    "               'epochs': [100],\n",
    "               'optimizer': ['Adam', 'Adagrad', 'Nadam'],\n",
    "               'input_act': ['sigmoid', 'relu'],\n",
    "               'hidden_nodes': [5, 10, 20],\n",
    "               'dropout_rate': [0, 0.01, 0.05],\n",
    "               'weight_func': ['RandomUniform', 'Ones', 'RandomNormal'],\n",
    "               }\n",
    "\n",
    "# create grid search\n",
    "grid2 = RandomizedSearchCV(estimator=mod, param_distributions=param_grid2, n_jobs=1, cv=3)\n",
    "\n",
    "# fits grid\n",
    "grid_fit2 = grid2.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score2 = grid_fit2.best_score_\n",
    "best_params2 = grid_fit2.best_params_\n",
    "\n",
    "# prints results from second run\n",
    "print(f'Best Params were: {best_params2}  --- Which gave an accuracy score of {best_score2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'weight_func': 'RandomUniform', 'optimizer': 'Adam', 'input_act': 'relu', 'hidden_nodes': 10, 'epochs': 100, 'dropout_rate': 0.01, 'batch_size': 100}  --- Which gave an accuracy score of 0.8419117741286755\n"
     ]
    }
   ],
   "source": [
    "# checks more values\n",
    "param_grid3 = {'batch_size': [50, 100],\n",
    "               'epochs': [100],\n",
    "               'optimizer': ['Adam', 'Adagrad'],\n",
    "               'input_act': ['sigmoid', 'relu'],\n",
    "               'hidden_nodes': [5, 10],\n",
    "               'dropout_rate': [0.01, 0.05],\n",
    "               'weight_func': ['RandomUniform', 'RandomNormal'],\n",
    "               }\n",
    "\n",
    "# create grid search\n",
    "grid3 = RandomizedSearchCV(estimator=mod, param_distributions=param_grid3, n_jobs=1, cv=3, n_iter=20) # increased iterations from the default of 10\n",
    "\n",
    "# fits grid\n",
    "grid_fit3 = grid3.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score3 = grid_fit3.best_score_\n",
    "best_params3 = grid_fit3.best_params_\n",
    "\n",
    "# prints results from second run\n",
    "print(f'Best Params were: {best_params3}  --- Which gave an accuracy score of {best_score3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'weight_func': 'RandomNormal', 'optimizer': 'Nadam', 'input_act': 'relu', 'hidden_nodes': 10, 'epochs': 100, 'dropout_rate': 0, 'batch_size': 100}  --- Which gave an accuracy score of 0.8382353037595749\n"
     ]
    }
   ],
   "source": [
    "# checks more values\n",
    "param_grid4 = {'batch_size': [80, 100, 120], # 100 seemed to be a good number so I am checking values around 100\n",
    "               'epochs': [100],\n",
    "               'optimizer': ['Adam', 'Adagrad', 'Nadam'],\n",
    "               'input_act': ['relu'], # relu was better twice so I will stick with it\n",
    "               'hidden_nodes': [5, 10],\n",
    "               'dropout_rate': [0.01, 0],  # 0 won first time, and then the lower number the second so seeing if 0 is just better\n",
    "               'weight_func': ['RandomUniform', 'RandomNormal', 'Ones'],\n",
    "               }\n",
    "\n",
    "# create grid search\n",
    "grid4 = RandomizedSearchCV(estimator=mod, param_distributions=param_grid4, n_jobs=1, cv=3, n_iter=20) \n",
    "\n",
    "# fits grid\n",
    "grid_fit4 = grid4.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score4 = grid_fit4.best_score_\n",
    "best_params4 = grid_fit4.best_params_\n",
    "\n",
    "# prints results from second run\n",
    "print(f'Best Params were: {best_params4}  --- Which gave an accuracy score of {best_score4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'weight_func': 'RandomUniform', 'optimizer': 'Nadam', 'input_act': 'relu', 'hidden_nodes': 10, 'epochs': 100, 'dropout_rate': 0, 'batch_size': 100}  --- Which gave an accuracy score of 0.8419117741286755\n"
     ]
    }
   ],
   "source": [
    "# checks more values\n",
    "param_grid5 = {'batch_size': [100],\n",
    "               'epochs': [100],\n",
    "               'optimizer': ['Adam', 'Nadam'], # choosing between these two now\n",
    "               'input_act': ['relu'],\n",
    "               'hidden_nodes': [10, 20, 30], # raising node count since 10 always won over 5\n",
    "               'dropout_rate': [0], # sticking with 0\n",
    "               'weight_func': ['RandomUniform', 'RandomNormal'], # just going to check between the two to save time\n",
    "               }\n",
    "\n",
    "# create grid search\n",
    "grid5 = RandomizedSearchCV(estimator=mod, param_distributions=param_grid5, n_jobs=1, cv=3, n_iter=20) \n",
    "\n",
    "# fits grid\n",
    "grid_fit5 = grid5.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score5 = grid_fit5.best_score_\n",
    "best_params5 = grid_fit5.best_params_\n",
    "\n",
    "# prints results from second run\n",
    "print(f'Best Params were: {best_params5}  --- Which gave an accuracy score of {best_score5}')\n",
    "\n",
    "# same score as with grid3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'weight_func': 'RandomUniform', 'optimizer': 'Nadam', 'input_act': 'relu', 'hidden_nodes': 10, 'epochs': 1000, 'dropout_rate': 0, 'batch_size': 100}  --- Which gave an accuracy score of 0.8088235408067703\n"
     ]
    }
   ],
   "source": [
    "# creates final paramaters and increaes epochs for the final run\n",
    "param_grid_final = {'batch_size': [100],\n",
    "                    'epochs': [1000], # increases epochs for\n",
    "                    'optimizer': ['Nadam'], # Nadam won the times it was included\n",
    "                    'input_act': ['relu'],\n",
    "                    'hidden_nodes': [10], # 10 worked best when both lower and higher options were there\n",
    "                    'dropout_rate': [0], \n",
    "                    'weight_func': ['RandomUniform'], # better most of the time\n",
    "                    }\n",
    "\n",
    "# create grid search\n",
    "grid_final = RandomizedSearchCV(estimator=mod, param_distributions=param_grid_final, n_jobs=1, cv=3, n_iter=1) # just 1 iteration since theres only 1 to go through\n",
    "\n",
    "# fits grid\n",
    "grid_fit_final = grid_final.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score_final = grid_fit_final.best_score_\n",
    "best_params_final = grid_fit_final.best_params_\n",
    "\n",
    "# prints results from second run\n",
    "print(f'Best Params were: {best_params_final}  --- Which gave an accuracy score of {best_score_final}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params were: {'batch_size': 100, 'dropout_rate': 0, 'epochs': 100, 'hidden_nodes': 10, 'input_act': 'relu', 'optimizer': 'Nadam', 'weight_func': 'RandomUniform'}  --- Which gave an accuracy score of 0.8419117741286755\n"
     ]
    }
   ],
   "source": [
    "# checks if lower epochs were better\n",
    "param_grid_final2 = {'batch_size': [100],\n",
    "                    'epochs': [90, 100, 120], # checks if lower epoch is better?\n",
    "                    'optimizer': ['Nadam'], \n",
    "                    'input_act': ['relu'],\n",
    "                    'hidden_nodes': [10], \n",
    "                    'dropout_rate': [0], \n",
    "                    'weight_func': ['RandomUniform'], \n",
    "                    }\n",
    "\n",
    "# create grid search\n",
    "grid_final2 = GridSearchCV(estimator=mod, param_grid=param_grid_final2, n_jobs=1, cv=3) # now using grid search\n",
    "\n",
    "# fits grid\n",
    "grid_fit_final2 = grid_final2.fit(X_train, y_train)\n",
    "\n",
    "# gets best score and params\n",
    "best_score_final2 = grid_fit_final2.best_score_\n",
    "best_params_final2 = grid_fit_final2.best_params_\n",
    "\n",
    "# prints results from second run\n",
    "print(f'Best Params were: {best_params_final2}  --- Which gave an accuracy score of {best_score_final2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the same accuracy as run 5 and 3, with the same parameters including epochs.\n",
    "So these are going to be my final hyper parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
