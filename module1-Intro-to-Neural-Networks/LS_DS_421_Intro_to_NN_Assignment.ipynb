{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "Like a function/program, an input(data,number,whatever) is provided. It actually touches the raw data, and is therefore visible and not hidden\n",
    "### Hidden Layer:\n",
    "A hidden layers is any layer that isn't either an output or an input. This is where the 'black box' stuff occurs. You can also view it as the place where the 'learning' happens. As more epochs (trials) occur, the weights in this layer are manipulated in the same way the pulling levers / pushing buttons allows the network to learn what weightings achieve the best results in the model.\n",
    "### Output Layer:\n",
    "The output layer is the result of all the analysis and input layers. The activation function is applied to this layer so in attempt to reach the desired target results\n",
    "### Neuron:\n",
    "A node within a neural network. These neurons make up every layer of the neural network and represent data being transformed, depending on the layer that it's in.\n",
    "### Weight:\n",
    " A factor/vector to multiply the inputs by based on the inputs actual correspondence to the correct outcome\n",
    "### Activation Function:\n",
    "An activation function, or transfer function, can update weights using back propogation to create a better outcome. An activation function at its core is typically the same throughout all layers of the NN. It determines how much signal to 'transfer' to the next layer by determining if that given node will activate the next portion of a neural network, conrolling how much ifnormation is passed downstream within the network.here are many types such as a stepwise (binary) as well as sigmoid (similar to a logistic regression) and tanh which has a steeper center portion of the curve than the sigmoid\n",
    "### Perceptron:\n",
    "The simpliest neural network. A single node with no hidden layers, it can take any number of inputs and at this simplest level looks very similar to linear regression.It has the following properties: (n) inputs, 0 hidden layers, 1 output; goes one direction, left-to-right; inputs multiplied by weight, sum all products and pass sum through activation function and outputs as result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "#### Answer above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  1\n",
       "1   1   0  1\n",
       "2   0   1  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = { 'x1': [0,1,0,1],\n",
    "         'x2': [0,0,1,1],\n",
    "         'y':  [1,1,1,0]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data).astype('int')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "#remember, the final column of all 1's represents our \"bias\" value\n",
    "inputs = np.array([\n",
    "    [0,0,1],\n",
    "    [1,0,1],\n",
    "    [0,1,1],\n",
    "    [1,1,0]\n",
    "])\n",
    "\n",
    "correct_outputs = [[1],[1],[1],[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining our sigmoid functions for our activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58937111],\n",
       "       [-0.32476087],\n",
       "       [ 0.47774362]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating weights between 0 and 1\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47774362],\n",
       "       [1.06711473],\n",
       "       [0.15298275],\n",
       "       [0.74235386]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying our weights to our input values\n",
    "weighted_sum = np.dot(inputs,weights) \n",
    "weighted_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with our weights applied, we can enter our output layer with a sigmoid function\n",
    "activated_output = sigmoid(weighted_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38278508],\n",
       "       [ 0.25595217],\n",
       "       [ 0.46182873],\n",
       "       [-0.67751037]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#then we can find the error on the output and our true values\n",
    "error = correct_outputs - activated_output\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08713121],\n",
       "       [ 0.05588935],\n",
       "       [ 0.10748486],\n",
       "       [-0.15133642]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with our error values measured we can make adjustments, using gradient descent and backpropogation\n",
    "adjustments = error * sigmoid_derivative(activated_output)\n",
    "adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49392404],\n",
       "       [-0.36861243],\n",
       "       [ 0.57691262]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with the adjustments determined, we can apply them to our original weights\n",
    "weights += np.dot(inputs.T,adjustments)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[-11.839825  ]\n",
      " [-11.839825  ]\n",
      " [ 17.80860207]]\n",
      "Output after training\n",
      "[[0.99999998]\n",
      " [0.9974489 ]\n",
      " [0.9974489 ]\n",
      " [0.00281227]]\n"
     ]
    }
   ],
   "source": [
    "#now we can iterate across this to increase our accuracy\n",
    "for iteration in range(10000):\n",
    "    \n",
    "    # Weighted sum of inputs / weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate!\n",
    "    activated_output = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Cac error\n",
    "    error = correct_outputs - activated_output\n",
    "    \n",
    "    adjustments = error * sigmoid_derivative(activated_output)\n",
    "    \n",
    "    # Update the Weights\n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "\n",
    "print(\"Output after training\")\n",
    "print(activated_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "feats = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'bias']\n",
    "target = 'Outcome'\n",
    "# introducing bias into familiar machine learning workflows as part of the neural network\n",
    "diabetes['bias'] = np.ones(diabetes.shape[0])\n",
    "\n",
    "#converting our pandas dataframe into split numpy arrays into features and target\n",
    "X = diabetes[feats].to_numpy()\n",
    "y = diabetes[target].to_numpy()\n",
    "y = y * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although neural networks can handle non-normalized data, \n",
    "# scaling or normalizing your data will improve your neural network's learning speed.\n",
    "# Try to apply the sklearn MinMaxScaler or Normalizer to your diabetes dataset\n",
    "\n",
    "# we should apply a transformation to our features for more efficient models\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, rate = 0.1, niter = 10):\n",
    "        self.rate = rate\n",
    "        self.niter = niter\n",
    "    \n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "    \n",
    "    def __sigmoid_derivative(self, x):\n",
    "        sx = self.__sigmoid(X)\n",
    "        return sx * (1-sx)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit training data\n",
    "        X : Training vectors, X.shape : [#samples, #features]\n",
    "        y : Target values, y.shape : [#samples]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Randomly Initialize Weights\n",
    "        #assign weights of 0 for the length of features + 1 (bias)\n",
    "        self.weight = np.zeros(1 + X.shape[1])\n",
    "        \n",
    "            \n",
    "        #initialize errors\n",
    "        self.errors = []\n",
    "\n",
    "\n",
    "        for i in range(self.niter):\n",
    "            #reset errors for function calling\n",
    "            err = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                #for loop that breaks out for each prediction\n",
    "                \n",
    "                #the delta for each pass\n",
    "                delta_w = self.rate * (target - self.predict(xi))\n",
    "                # Weighted sum of inputs / weights\n",
    "                self.weight[1:] += delta_w * xi\n",
    "                self.weight[0] += delta_w\n",
    "                err += int(delta_w != 0.0)\n",
    "            self.errors.append(err)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def weighted_sum(self, X):\n",
    "        \"\"\"Calculate weighted sum of neuron\"\"\"\n",
    "        \"\"\"The dot product of an input times the weights plus a bias\"\"\"\n",
    "        return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Returns what the class is for the logic gate, 0 or 1 based on if the prediction is above or below 0.5\"\"\"\n",
    "        return np.where(self.weighted_sum(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXyU9bn38c+VBQgEkrBDyMImbqiMKFGwVVsP59g+detpwaVWK5zWta3Htvacp7ZP62kt1ardTlHb2iNLe5RStbbuS20FS4LIvsiagBAQCDshuZ4/5k4YJIQBMrln+b5fr3nNzD1zz1xJK9/cv9XcHREREYCssAsQEZHkoVAQEZFmCgUREWmmUBARkWYKBRERaZYTdgEnomfPnl5eXh52GSIiKaWysnKzu/dq6bWUDoXy8nLmzJkTdhkiIinFzNYc6TU1H4mISDOFgoiINFMoiIhIM4WCiIg0UyiIiEizlB59dDxmzq1h0vNLWb9tD/0L87hr7DAuH1EcdlkiIkkho0Jh5twa7p4xnz31DQDUbNvD3TPmAygYRETIsOajSc8vbQ6EJnvqG5j0/NKQKhIRSS4ZFQrrt+05puMiIpkmo0Khf2HeMR0XEck0GRUKd40dRl5u9iHH8nKzuWvssJAqEhFJLhnV0dzUmTzp+aXUbNtDlsF/XXG6OplFRAIZdaUA0WD42zcu5t4rTqfRYURpUdgliYgkjYwLhSaRIAyq1m4NuRIRkeSRsaFwUp+u5HfMUSiIiMTI2FDIzjLOLCmgas22sEsREUkaGRsKAGeXFrHk/Tp27TsQdikiIkkho0NhRFkRjQ7zqnW1ICICCQwFMysxs1fNbLGZLTSzO4LjvzOzd4LbajN7J+acu81shZktNbOxiaqtSaQk6Gxeo34FERFI7DyFA8Cd7l5lZl2BSjN70d0/2/QGM7sf2B48PhUYB5wG9AdeMrOT3L2hhc9uEwWdcxncqwtVa3WlICICCbxScPcN7l4VPN4BLAaaZ4mZmQGfAaYFhy4Dprv7PndfBawAzk1UfU0ipUXMXbsVd0/0V4mIJL126VMws3JgBDA75vAFwEZ3Xx48LwbWxbxeTUyIxHzWRDObY2ZzamtrT7i2s8uK2Lq7nlWbd53wZ4mIpLqEh4KZ5QNPAV9297qYl8Zz8CoBwFo4/bA/3919sruPdPeRvXr1OuH6ImVNk9jUhCQiktBQMLNcooEwxd1nxBzPAa4Efhfz9mqgJOb5AGB9IusDGNIrn66dNIlNRAQSO/rIgMeAxe7+wIde/jiwxN2rY449DYwzs45mNhAYCrydqPqaZGUZZ5UUagSSiAiJvVIYDVwHXBwzBPXS4LVxHNp0hLsvBH4PLAL+AtySyJFHsSKlRSzduIMde+vb4+tERJJWwoakuvubtNxPgLt//gjH7wXuTVRNRxIpK8Id5q3bzpihPdv760VEkkZGz2huclZJIWZaMVVERKEAFOTlMrR3vkJBRDKeQiEQKS2ias1WGhs1iU1EMpdCIRApLaJu7wFWbt4ZdikiIqFRKAQiZYUA2l9BRDKaQiEwqGc+3TSJTUQynEIhkJVlRMqKFAoiktEUCjEipUUs37ST7Xs0iU1EMpNCIUakNDqJ7Z116lcQkcykUIhxZklBdBKb1kESkQx11FAws8Fm1jF4fKGZ3W5mhYkvrf117ZTLsD5d1a8gIhkrniuFp4AGMxtCdNXTgcDUhFYVokhZEe+s26ZJbCKSkeIJhUZ3PwBcATzo7l8B+iW2rPBESovYsfcAK2o1iU1EMk88oVBvZuOB64Fng2O5iSspXJHSpklsakISkcwTTyjcAJwH3Ovuq4INcJ5IbFnhGdizC0Wdc6lUKIhIBjrqfgruvgi4Peb5KuAHiSwqTGbGiFJNYhORzBTP6KPRZvaimS0zs5VmtsrMVrZHcWGJlBbyXu0utu3eH3YpIiLtKp6d1x4DvgJUAu2yPWbYImVFAMxdt42LhvUOuRoRkfYTT5/Cdnf/s7tvcvctTbeEVxaiMwcUkmUwV/0KIpJh4rlSeNXMJgEzgH1NB929KmFVhaxLxxxO7tuNSvUriEiGiScURgX3I2OOOXBx25eTPCJlhfyhqoaGRic7y8IuR0SkXcQz+uii9igk2URKi3hi1lqWbdzBKf26hV2OiEi7iGf0UYGZPWBmc4Lb/WZW0B7FhSlSGu1s1tBUEckk8XQ0/wrYAXwmuNUBv05kUcmgrEdnenTpoO05RSSjxNOnMNjdr4p5/h0zeydRBSWLpklsc3WlICIZJJ4rhT1mNqbpiZmNBvYkrqTkESkrZOXmXXywS5PYRCQzxHOl8CXg8aAfwYAPgM8nsqhk0dSvMHftVj52Sp+QqxERSbx4Rh+9A5xpZt2C53UJrypJnDGggOwso0qhICIZ4oihYGbXuvsTZvbVDx0HwN0fSHBtoevcIYdT+3VTZ7OIZIzW+hS6BPddW7jlJ7iupBEpLWRe9TYONDSGXYqISMId8UrB3X8ZPHzJ3f8W+1rQ2ZwRImVFPP7WGpZu3MFp/dN+eoaIZLh4Rh/9JM5jaal5EpsWxxORDNBan8J5wPlArw/1K3QDshNdWLIYUJRHz/yOVK3dxnXnhV2NiEhitXal0IFo30EOh/Yn1AGfPtoHm1mJmb1qZovNbKGZ3RHz2m1mtjQ4/sOY43eb2YrgtbHH+0O1JTMjUlqo5S5EJCO01qfwOvC6mf3G3dccx2cfAO509yoz6wpUmtmLQB/gMuAMd99nZr0BzOxUYBxwGtAfeMnMTnL30Df2ObusiBcWbWTzzn30zO8YdjkiIgkTz+S13cF+CqcBnZoOunurS2e7+wZgQ/B4h5ktBoqBCcAP3H1f8Nqm4JTLgOnB8VVmtgI4F3jr2H6ktte8E9vabVxyquYriEj6iqejeQqwBBgIfAdYDfzjWL7EzMqBEcBs4CTgAjObbWavm9k5wduKgXUxp1UHxz78WRObVmytra09ljKO2/DiAnKyjEp1NotImosnFHq4+2NAvbu/7u43AhXxfoGZ5QNPAV8OZkPnAEXBZ9wF/N6iM+Ja2snGDzvgPtndR7r7yF69esVbxgnplJvNaf27qV9BRNJePKFQH9xvMLNPmNkIYEA8H25muUQDYYq7zwgOVwMzPOptoBHoGRwviTl9ALA+nu9pDyNKi3i3ehv1msQmImksnlD4XrAY3p3AvwOPAl852knBX/+PAYs/tCTGTIKtPM3sJKKjnDYDTwPjzKyjmQ0EhgJvH8PPklBnlxWxt76RJRt2hF2KiEjCxLMg3rPBw+3AsWzNORq4Dpgfs//CN4lu2vMrM1sA7Aeud3cHFprZ74FFREcu3ZIMI4+aNHU2V63dyvABmtksIunpqKFgZo8Dd7j7tuB5EXB/0LdwRO7+Ji33EwBce4Rz7gXuPVpNYehf0Ik+3TpStXYr159fHnY5IiIJEU/z0RlNgQDg7luJjiTKKNFJbEUagSQiaS2eUMgKrg4AMLPuxDe/Ie1ESouo3rqHTTv2hl2KiEhCxBMK9wN/N7Pvmtl3gb8DPzzKOWkpUlYIoP0VRCRtHTUU3P23wFXARmATcKW7/0+iC0tGp/UvoEN2FnM1X0FE0lRrq6R2c/e6oLnofWBqzGvd3f2D9igwmXTKzea0Yk1iE5H01VrfwFTgk0Alh84stuD5oATWlbQipUX8z6w17D/QSIeceFrfRERSR2v/qv0guD/F3QfF3Aa6e0YGAkRDYf+BRhZtqAu7FBGRNtdaKDwU3P+9PQpJFQc7m9WEJCLpp7Xmo3oz+zUwwMwe/vCL7n574spKXv0K8uhX0ImqtVu5kYFhlyMi0qZaC4VPAh8nuk5RZfuUkxoiZUXMXathqSKSflrbeW0zMN3MFrv7vHasKelFSov407sbeH/7XvoWdDr6CSIiKaK1Ialfc/cfAjeZWUv7GmRk8xFApDToV1i7lUuH9wu5GhGRttNa89Hi4H5OexSSSk7rX0CHnCyq1igURCS9tNZ89Exw/3jTMTPLAvKDHdQyVoecLIYXF2gSm4iknaPOvjKzqWbWzcy6EN3rYKmZ3ZX40pLb2WVFLKipY9+BpNnyQUTkhMUzJffU4MrgcuA5oJTo5jkZLVJayP6GRhauz+iLJhFJM/GEQm6w1/LlwB/dvZ5Dl73ISJHSYCc2TWITkTQSTyj8ElgNdAHeMLMyIOP/PO7drRPFhXnqVxCRtBLP0tkPu3uxu1/qUWs4tr2a01akrEh7K4hIWomno/mOoKPZzOwxM6siOss540VKC3m/bi/rt+0JuxQRkTYRT/PRjUFH8z8BvYAbOLiCakY7uyzoV1ATkoikiXhCwYL7S4FfB0teWCvvzxin9OtGp9wsNSGJSNqIJxQqzewFoqHwvJl1BRoTW1ZqyM3O4oziQip1pSAiaSKeUPgC8A3gHHffDXQg2oQkwIiyQhat387eek1iE5HUF8/oo0ZgFXCSmX0EOA0oTHRhqSJSWkR9g7OgZnvYpYiInLB4Rh/dBLwBPA98J7j/dmLLSh3Nk9jUhCQiaSCe5qM7gHOANe5+ETACqE1oVSmkV9eOlHbvrM5mEUkL8YTCXnffC2BmHd19CTAssWWllkhptLPZPeNX/xCRFBdPKFSbWSEwE3jRzP4IrE9sWaklUlZE7Y59VG/VJDYRSW2tbbIDgLtfETz8tpm9ChQAf0loVSkmtl+hpHvnkKsRETl+R7xSMLPuH74B84E3gfx2qzAFnNy3K3m52cxdq34FEUltrV0pVBJdIjt29nLTcwcGJbCulJKTncWZJdqJTURSX2vbcQ5sz0JSXaS0iMlvrGRvfQOdcrPDLkdE5LjEM0/hCjMriHleaGaXx3FeiZm9amaLzWyhmd0RHP+2mdWY2TvB7dKYc+42sxVmttTMxh7vDxWGSGkRBxqdd6s1iU1EUlc8o4/ucffmf+ncfRtwTxznHQDudPdTgArgFjM7NXjtx+5+VnB7DiB4bRzRGdP/DPzczFLmT+4RpdFJ3pXaiU1EUlg8odDSe+IZtbTB3auCxzuAxUBxK6dcBkx3933uvgpYAZwbR31JoUd+R8p7dFa/goiktHhCYY6ZPWBmg81skJn9mGgndNzMrJzoTOjZwaFbzexdM/uVmRUFx4qBdTGnVdNCiJjZRDObY2ZzamuTa2J1pLSIuZrEJiIpLJ5QuA3YD/wO+F9gL3BLvF9gZvnAU8CXg816fgEMBs4CNgD3N721hdMP+9fV3Se7+0h3H9mrV694y2gXkbIiNu/cz7oPNIlNRFJTPM1Au4gunU3Qxt8lOHZUZpZLNBCmuPuM4PM2xrz+CPBs8LQaKIk5fQApNnM6dhJbaQ9NYhOR1BPP6KOpwR7NXYCFwFIzuyuO8wx4DFjs7g/EHO8X87YrgAXB46eBcWbW0cwGAkOBt+P/UcI3rG9XunTIVmeziKSso14pAKe6e52ZXQM8B3ydaJ/CpKOcNxq4DphvZu8Ex74JjDezs4g2Da0G/g3A3Rea2e+BRURHLt3i7im1c012lnFmSaE6m0UkZcUTCrlBM9DlwE/dvd7MjtqT6u5v0nI/wXOtnHMvcG8cNSWtSGkRv3j9PXbvP0DnDvH8ekVEkkc8Hc2/JPoXfRfgDTMrA+oSWVQqi5QV0tDozFunSWwiknri2Y7zYXcvdvdLPWoNcFE71JaSRpRoJzYRSV1HbN8ws2vd/Qkz++oR3vLAEY5ntKIuHRjUqwtzFQoikoJaa/TuEtx3bY9C0kmktIhXlmzC3YkOwhIRSQ2trZL6y+D+O+1XTnqIlBbxZGU1q7fsZmDPLkc/QUQkSRx1eEwwZ+A2oDz2/e7+qcSVldoiZdHF8arWbFUoiEhKiWfM5Eyik9CeARoTW056GNq7K1075lC1ditXnT0g7HJEROIWTyjsdfeHE15JGsnOMs4qLaRK23OKSIqJZ57CQ2Z2j5mdZ2aRplvCK0txI0qLWPp+HTv3HQi7FBGRuMVzpTCc6HIVF3Ow+ciD53IEkdJCGh3mrdvG6CE9wy5HRCQu8YTCFcAgd9+f6GLSSfMktjVbFQoikjLiaT6aBxQmupB0U9A5lyG98zWzWURSSjxXCn2AJWb2D2Bf00ENST26s0uLeH7R+5rEJiIpI55QuCfhVaSpSFkhv5uzjpWbdzG4V37Y5YiIHFU8O6+93h6FpKOmndgq12xVKIhISoinT0GO0+Be+XTrlKPF8UQkZSgUEigryzirtIiqNZrEJiKp4YihYGYvB/f3tV856SdSWsiyTTuo21sfdikiIkfV2pVCPzP7KPApMxsRO5tZM5rjd3ZZER5MYhMRSXatdTR/C/gGMIDDN9TRjOY4nVVSiBlUrdnGBUN7hV2OiEirWttP4UngSTP7v+7+3XasKa107ZTLSb27UqnOZhFJAfEMSf2umX0K+Ehw6DV3fzaxZaWXSFkhz767gcZGJytLk9hEJHkddfSRmX0fuANYFNzuCI5JnEaUFrFj7wHeq90ZdikiIq2KZ0bzJ4Cz3L0RwMweB+YCdyeysHRydlmwON7arQztoy2vRSR5xTtPIXZBvIJEFJLOBvXsQmHnXM1XEJGkF8+VwveBuWb2KmBE+xZ0lXAMzIwRJYXqbBZJYTPn1jDp+aWs37aH/oV53DV2GJePKA67rDYXT0fzNDN7DTiHaCh83d3fT3Rh6SZSWsSrS2vZvruegs65YZcjIsdg5twa7p4xnz31DQDUbNvD3TPmA6RdMMTVfOTuG9z9aXf/owLh+ESCfoW563S1IJJqJj2/tDkQmuypb2DS80tDqihxtPZROzmzpJAsg6q16lcQSTXrt+1p8XjNtj3s3p9e+7ArFNpJfscchvXtphVTRVJM9dbdrc4vuuC+V/nv199j1770CIdWQ8HMssxsQXsVk+4ipYW8s3YbDY0edikiEod1H+xm3ORZ5GZBx5xD/7nMy83mjo8N5bTiAn7w5yVc8MNX+cVrqR8OrYZCMDdhnpmVtlM9aS1SWsSOfQdYvmlH2KWIyFE0BcKOvQf43y+O5r6rzqC4MA8Digvz+P6Vw/nKJSfx2xvPZcbN5zO8uID7/rKEMfe9ws9eXcHOFA2HeIak9gMWmtnbwK6mg9qj+dg1dTZXrdnGyX27hVyNiBxJUyDs3HeAKTeN4vTiAoYPKDjiSKNIaRGP33guc9du5aGXlzPp+aU88teVTLhgEJ87r4yunVJnxGE8ofCd4/lgMysBfgv0BRqBye7+UMzr/w5MAnq5+2aL7mz/EHApsBv4vLtXHc93J6vyHp3p3qUDVWu3cvWo5Lj4ypSx1yLxWrtlN+MfmcWu/QcDIV4jSov4zQ3n8s66bTwchMPkN1Yy4YKBXH9+eUqEQ1x7NJtZGTDU3V8ys85AdhyffQC4092rzKwrUGlmL7r7oiAwLgHWxrz/X4ChwW0U8IvgPm2YGZHSQqqSpLM5k8Zei8RjzZZdjJ88i931DUy5aRSn9T++BRzOKinkV58/h3lBOPzohWU88tdVfGHMQD4/upxuSRwO8SyINwF4EvhlcKgYmHm084K5DVXB4x3A4uBcgB8DXyO6L0OTy4DfetQsoNDM+sX7g6SKEaVFrKzdxbbd+8MuJaPGXosczZotuxjXBoEQ68ySQh77/Dk8c+sYzikv4oEXlzHmB6/w0EvL2b4nOXdjjGdI6i3AaKAOwN2XA72P5UvMrBwYAcwOluGucfd5H3pbMbAu5nk1B0Mk9rMmmtkcM5tTW1t7LGUkhUhpMIktxPkKtTv28ehfV1JzhLHXRxqTLZKuVm+OBsLe+gam3lTRJoEQa/iAAh69/hyevW0Mowb14McvLWPMfa/w4EvLki4c4ulT2Ofu+6NN/mBmORz6F36rzCwfeAr4MtEmpf8A/qmlt7Zw7LDvcffJwGSAkSNHptzYzjNLCsjOMirXbOWik48pW0/IvgMNvLJ4E09VVfPq0loaGp3cbKO+4fBfYb/CTu1Wl0jYVm2ONhntb2hk6oQKTumXuEEgpxcX8MjnRrKgZjsPv7ycB19azmNvruKG0QP5wuiBSbEETjyh8LqZfRPIM7NLgJuBZ+L5cDPLJRoIU9x9hpkNBwYSHeYK0a0+q8zsXKJXBiUxpw8A1sf9k6SIzh1yOLlv13bpV3B35tds58nKap6et55tu+vp3bUjN10wkE9HBrBwfd0hfQpNynt01oZAkhFWbd7FuMlvUd/gTJ0wqt1GBZ5eXMDkz41k4fpoODz88nJ+/eYqbhhdzo1jBlLYuUO71NGSeELhG8AXgPnAvwHPAY8e7aRgNNFjwGJ3fwDA3ecT0/RkZquBkcHoo6eBW81sOtEO5u3uvuHYfpzUECktYkZVNQ2NTnYC/uHdVLeXP8yt4cnKapZv2kmHnCzGntaXqyLFjBnSk5zsaKth094OB0cfdeLkft14efEm/vOPC/jeZacrGCRtrazdyfhHZrV7IMQ6rX8Bv7xuJIvW1/GTV5bz8Csr+NXfVnPD6HK+EFI4mPvRW2DMrANwMtHmnKXuftReUjMbA/yVaJg0Boe/6e7PxbxnNQdDwYCfAv9MdEjqDe4+p7XvGDlypM+Z0+pbktLMuTV8+Xfv8NztF3Bq/7b5P+Le+gZeXLSRp6qqeWNZLY0enUH96bNL+MQZ/SjIi++y1N2Z9PxSfv7ae4w/t4R7Lx+uYJC0817tTsZPnkVDozN1QgXD+ibH5leLN0TD4bn575PfMYfrzy/jpjGDKOrStuFgZpXuPrKl1456pWBmnwD+G3iPaLv/QDP7N3f/c2vnufubtNxPEPue8pjHTrRTO+01dTZXrd16QqHg7sxdt40nK6t5dt566vYeoF9BJ7504WCujAxgcK/8Y/5MM+OuscPIMuOnr67AHf7rCgWDpI+mQGh0Z9rECk5Kot0QT+nXjZ9fczZL3q/jJy+v4Oevvcdv/raa688v56YLBtG9S4eEzy2Kp/nofuAid18BYGaDgT8BrYaCHFlJ9zx65negas1Wrq0oO+bzN2zfw4yqGp6qrGbl5l10ys3iX07vx1WRAZw3uMcJN0mZGXf+00mYwU9eiQbD969UMEjqW7Ep2mTk7kybUJG02+Oe3LcbP7smwrKNO3j45eX84vX3+M3fV3PeoB787b3N7K2PNr4kYm5RPKGwqSkQAiuBTW3y7RnKzBhRWnRMnc179jfw/ML3eaqqmjdXbMYdzi3vzhc/Oph/Gd63zWdKmhlfveQkDHj4lRU4zg+uPEPBIClrxaYdjH9kNu4kdSDEOqlPV356dYQ7Nu7g4VdW8My8w8feNM0tSngomNmVwcOFZvYc8HuifQr/CvyjTb49g0VKi3hx0Ua27NxHj/yOLb7H3ZmzZitPzqnmT/M3sHPfAQYU5XHbxUO5KlJMWY8uCa3RzPjqPw3DzHjo5eW4w31XKRgk9SzfGA0EgOkTRzGkd/IHQqyhfbryk/EjeHbe+hbnA7Tl3KLWrhT+T8zjjcBHg8e1QFGbVZChIqWFQHQS28dP7XPIa9Vbd0ebh6qqWbNlN507ZHPp8Gjz0KiB3dv9H+WvXHISQDQYiAZDIkZNiSRCNBBmYWZMm1DBkN7H3teWLPoX5rU46bR/YV6bfccRQ8Hdb2izb5HDrNmyG4CbfjuH4sI8br94CNnZWTxVWc1bK7cAcN6gHtx28VD+5fS+dOkYT0tf4nzlkmgfw4MvLafRnUmfPlPBIElv2cYdXJ0mgQBw19hhh80tysvN5q6xw9rsO+IZfTQQuA0oj32/ls4+fjPn1nDP0wubn9ds28PXg86i0u6d+eolJ3HFiGJKuncOq8QWffnjJ5FlxgMvLgOHSf+qYJDktfT9aCBkZxnTJlYc12i8ZNPUbxD26KOZRCehPcPB+QZyAlpaiA6gZ34HXr/rQpqWFElGt39sKAbc/+IyHPiRgkGSUFMg5GRHrxAGpUEgNLl8RHFCVzGOJxT2uvvDCasgAx2pU2jLzv1JHQhNbvvYUMzgRy8sw925/zNnKRgkaSx5v46rH5lNbrYxfeJ5DOyZ2AEZ6SaeUHjIzO4BXgD2NR1Mtw1w2lN7dBYl2q0XD8XMmPT8Uhy4/1/PbF4+QyQsizfUcfUjs+iYk820iRUKhOMQTygMB64DLuZg85EHz+U4tEdnUXu45aIhmMEP/7IUd3jgMwoGCc+i9XVc8+gsOuVmM21CBeUKhOMSTyhcAQyKZ70jiU97dBa1l5svHIJh3PeXJTjwYwWDhGDh+u1c++hsOuVmM31iRcLn8KSzeEJhHlCIZjG3qUR3FrWnL104GDP4wZ+X4O48+NmzFAzSbhbUbOfax2bTOTfaZKRAODHxhEIfYImZ/YND+xQ0JFWaffGjg8ky+K/nluAOD447i1wFgyTYgprtXPPobPI75jBtQgWlPZJrGHcqiicU7kl4FZIWJn5kMIZx73OLcZyHxo1QMEjCxAbC9IkVSTevJ1UdNRTc/fX2KETSw4SPDMIMvvenxbjP5eHxCgZpe/Ort3PNo7Po2ilXgdDGjvpfq5ntMLO64LbXzBrMrK49ipPUdNMFg/jPT5zCnxe8z21T51LfoDmP0nberd6mQEigeK4UDllO0MwuB85NWEWSFm66YBBmxnefXcStU6v4yfgIHXJ0xZBKEr2Zy/HU0bNrR3bs2U/Prp2YPrGCAUUKhLZ2zP+VuvtMNEdB4vCFMQP51idP5fmFG7l1ahX7D+iKIVXMnFvD3TPmU7NtD87BzVxmzq0JtY7aHfvYd8C5cXS5AiFB4lkQ78qYp1nASGhxSW+Rw9w4ZiBZBt9+ZhG3TK3iZ1friiEVtLQ+1576Br71xwVUb93dbnVMfmPlYXU48Nibq7lxzKB2qyOTxDP6KHZfhQPAauCyhFQjaenzowdiZtzz9EJunlLFz69RMCS7I63PVbf3AD96YVk7V3O4ttxURg4VT5+C9lWQE3b9+eWYwbf+uJCbp1Tys2sidMzJDrssOYLe3TqysW7fYcf7F3bi9bsuarc6PjrpVdZv29tCHamzTliqaW07zm+1cp67+3cTUI+ksc+dV44B//ePC7n5iSp+fq2CIRlVb93d4oixvNxsvjb25HYdYvy1sSenxTphqaS1/3V3tXAD+ALw9QTXJWnquhwrbeoAAA0jSURBVPPK+e7lp/Pykk186Ykq9h04fF8JCU/11t2MmzyL+gbnq5cMpbgwDwOKC/P4/pXD23300eUjivn+lcNDryOTmPvR+4zNrCtwB9FA+D1wv7uHvhbSyJEjfc6cOWGXIcdhyuw1/McfFnDRsF784tqz6ZSrK4awrftgN+MfmUXdnnqeuGkUZwwoDLskSRAzq3T3kS291up1oJl1N7PvAe8SbWqKuPvXkyEQJLVdM6qM/7piOK8ureWLT1Syt4Wd6KT9rPsgeoVQt6eeKTdVKBAyWGt9CpOAK4HJwHB339luVUlGuHpUKWZw94z5XP6zv1G3p54N2/em9FLiqagpEHbuO8CUmyoYPqAg7JIkRK2NPrqT6Kqo/wn8R8w2kUa0o7lbgmuTDDD+3FLeWbuV382pbj7WNFEKUDAk2Not0SajaCCM4vRiBUKmO2LzkbtnuXueu3d1924xt64KBGlLb67YctixPfUNTHp+aQjVZI61W3YzbvJb7NqvQJCDNINIQnekiUg12/bQ0KjJ84mwZssuxk1+i931DQoEOYRCQULX2kSkSx54nT/MreaAVlptM6s372Lc5FnNgXBafwWCHKRQkNDdNXYYeR8akpqXm8UNo8vokJPFV343j0t+/AZPVSocTlRTIOytb2DqTRUKBDlMPGsfiSRUU2dyS8s0NzY6LyzayEMvL+fO/53HT15Zzq0XD+Xys/prH+hjtGrzLsZPnsX+hkamTqjglH7qGpTDxTV5LVlp8lrmaGx0Xly8kYdeWs6iDXWU9ejMrRcN4YoRxQqHOKys3cn4R6IzladOGMXJfRUImey4J6+d4JeWmNmrZrbYzBaa2R3B8e+a2btm9o6ZvWBm/YPjZmYPm9mK4PVIomqT1JOVZYw9rS9/un0Mk687m/yOOdz15LtcfP/r/H7OOu3u1oqVtTubl65QIMjRJOxKwcz6Af3cvSpYJqMSuByodve64D23A6e6+xfN7FLgNuBSYBTwkLuPau07dKWQudydlxdv4sGXl7Ggpo6S7nncetEQrowM0J7QMd6r3cn4ybNoaHSmTqhgWN+uRz9J0l4oVwruvsHdq4LHO4DFQHFTIAS6cHDDnsuA33rULKAwCBaRw5gZHz+1D8/cOobHrh9JYV4Hvv7UfC760WtMf3utrhyAFZuigdDozrSJCgSJT7v8SWVm5cAIYHbw/F4zWwdcAzQt0V0MrIs5rTo49uHPmmhmc8xsTm1tbSLLlhRgZnzslD48fetofvX5kfTo0oFvzJjPhZNeY9rbazN2C9AVm6J9CI3uTJtQwUl9FAgSn4SHgpnlA08BX266SnD3/3D3EmAKcGvTW1s4/bC2LXef7O4j3X1kr169ElW2pBgz4+KT+zDzltH8+oZz6Nm1I3fPiF45TJm9JqPCYcWmHYybPAt3mDahgqEKBDkGCQ0FM8slGghT3H1GC2+ZClwVPK4GSmJeGwCsT2R9kn7MjIuG9WbmzefzmxvOoVfXjtElun/0Gk/MWpP2+zcs37iDcZNnAzB94igFghyzRI4+MuAxYLG7PxBzfGjM2z4FLAkePw18LhiFVAFsd/cNiapP0puZceGw3vzh5vN5/MZz6d2tI/85cwEXTXqN/0nTcFi2cQfjH5mFGUyfWMGQ3goEOXaJHH00BvgrMB9ounb/JtGNeoYFx9YAX3T3miBEfgr8M7AbuMHdWx1apNFHEi9356/LN/PQy8upXLOVfgWduPnCwXzmnJK02BJ02cYdjJ88i6wsY9qECob0zg+7JElirY0+0uQ1ySjuzt9WbOHBl5YxZ81W+nbrxJcuHMxnzylJ2d3flr6/g6sfmUV2ljFtYgWDeykQpHUKBZEPcXf+/l40HP6xeit9unXkSx8dTJeOOTz40vLDlttIVkver+OaR2aTkx29QhikQJA4tBYKWvtIMpKZMXpIT84f3IO33tvCgy8t59vPLDrkPcm+2c/iDXVc8+hscrON6RPPY2DPLmGXJGlAUz8lo5kZ5w/pye/+rYKe+R0Oe31PfQP/75mFbNm5L4TqjmzxhjqufmQWHbKzFAjSpnSlIEI0HLbs3N/iax/srufs773EsD5dGTWoOxWDenDuwO70zO/YzlVGLVpfxzWPzqJTbjbTJlRQrkCQNqRQEAn0L8yjpoVd4Hrmd+CG0QOZtXIL/zunmt++tQaAob3zqRjUozkkenVNfEgsXL+dax6dTV5uNtMnVlDWQ4EgbUsdzSKBmXNruHvGfPbUH5zDkJebzfevHN7cp1Df0Mj8mu3MWrmFWSs/YM7qD9i9P/r+Ib3zqRjUnVEDezBqUHd6d+3UpvUtqNnOtY/NpnNuNtMUCHICNPpIJE4z59a0uNnPkdQ3NLKgZjuzVn7A7FVb+MeqD9gVhMTgXl0YFVxJVAzsTu9uxx8SC2qiVwj5HXOYNqGC0h6dj/uzRBQKIu3kQEMjC9bXMXvlFmat3MI/Vm9l574DAAzq2RQS0X6JPnGGRGwgTJ9YQUl3BYKcGIWCSEgONDSyaENdc3PTP1Z9wI4gJAb27NLc3FQxqAd9Cw6GROwVC0BBXi7P3DZGgSBtQvMUREKSk53FGQMKOWNAIRM/MpiGRmfR+mhIzF61hWff3cC0t6Mrxpf36MyogT3IyYEn59SwL2Zl1z31DVSu2apQkITTlYJIiBoancUxVxJvr9pC3d4DLb63uDCPv33j4nauUNKRrhREklR2lnF6cQGnFxdw0wWDaGh0hnzzucM3EoHmpiSRRNKMZpEkkp1l9C/Ma/G1Ix0XaUsKBZEkc9fYYeR9aMXWvNxs7ho7LKSKJJOo+UgkyTTNiziW+RIibUWhIJKELh9RrBCQUKj5SEREmikURESkmUJBRESaKRRERKSZQkFERJql9DIXZlYLrAm7jhPUE9gcdhFJRL+PQ+n3cZB+F4c6kd9Hmbv3aumFlA6FdGBmc460Bkkm0u/jUPp9HKTfxaES9ftQ85GIiDRTKIiISDOFQvgmh11AktHv41D6fRyk38WhEvL7UJ+CiIg005WCiIg0UyiIiEgzhUJIzKzEzF41s8VmttDM7gi7prCZWbaZzTWzZ8OuJWxmVmhmT5rZkuD/I+eFXVOYzOwrwX8nC8xsmpl1Crum9mRmvzKzTWa2IOZYdzN70cyWB/dFbfFdCoXwHADudPdTgArgFjM7NeSawnYHsDjsIpLEQ8Bf3P1k4Ewy+PdiZsXA7cBIdz8dyAbGhVtVu/sN8M8fOvYN4GV3Hwq8HDw/YQqFkLj7BnevCh7vIPoffcYuoG9mA4BPAI+GXUvYzKwb8BHgMQB33+/u28KtKnQ5QJ6Z5QCdgfUh19Ou3P0N4IMPHb4MeDx4/DhweVt8l0IhCZhZOTACmB1uJaF6EPga0Bh2IUlgEFAL/DpoTnvUzLqEXVRY3L0G+BGwFtgAbHf3F8KtKin0cfcNEP0jE+jdFh+qUAiZmeUDTwFfdve6sOsJg5l9Etjk7pVh15IkcoAI8At3HwHsoo2aBlJR0FZ+GTAQ6A90MbNrw60qfSkUQmRmuUQDYYq7zwi7nhCNBj5lZquB6cDFZvZEuCWFqhqodvemK8cniYZEpvo4sMrda929HpgBnB9yTclgo5n1AwjuN7XFhyoUQmJmRrTNeLG7PxB2PWFy97vdfYC7lxPtQHzF3TP2L0F3fx9YZ2bDgkMfAxaFWFLY1gIVZtY5+O/mY2Rwx3uMp4Hrg8fXA39siw/NaYsPkeMyGrgOmG9m7wTHvunuz4VYkySP24ApZtYBWAncEHI9oXH32Wb2JFBFdNTeXDJsyQszmwZcCPQ0s2rgHuAHwO/N7AtEg/Nf2+S7tMyFiIg0UfORiIg0UyiIiEgzhYKIiDRTKIiISDOFgoiINFMoiLTAzBrM7J2YW5vNKDaz8tjVLkWSieYpiLRsj7ufFXYRIu1NVwoix8DMVpvZfWb2dnAbEhwvM7OXzezd4L40ON7HzP5gZvOCW9PyDNlm9kiwR8ALZpYXvP92M1sUfM70kH5MyWAKBZGW5X2o+eizMa/Vufu5wE+Jru5K8Pi37n4GMAV4ODj+MPC6u59JdP2ihcHxocDP3P00YBtwVXD8G8CI4HO+mKgfTuRINKNZpAVmttPd81s4vhq42N1XBgsavu/uPcxsM9DP3euD4xvcvaeZ1QID3H1fzGeUAy8Gm6NgZl8Hct39e2b2F2AnMBOY6e47E/yjihxCVwoix86P8PhI72nJvpjHDRzs3/sE8DPgbKAy2FRGpN0oFESO3Wdj7t8KHv+dg1tEXgO8GTx+GfgSNO9B3e1IH2pmWUCJu79KdMOhQuCwqxWRRNJfISIty4tZvRai+yU3DUvtaGazif5RNT44djvwKzO7i+iuaU2rmt4BTA5WsmwgGhAbjvCd2cATZlYAGPBjbcMp7U19CiLHIOhTGOnum8OuRSQR1HwkIiLNdKUgIiLNdKUgIiLNFAoiItJMoSAiIs0UCiIi0kyhICIizf4/6U5QyUoLux0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looks like peak optimization was reached with 6 epochs\n",
    "\n",
    "#initializating the perceptron class\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nn = Perceptron()\n",
    "\n",
    "#fitting on the diabetes data\n",
    "nn.fit(X_scaled,y)\n",
    "plt.plot(range(1, len(nn.errors) + 1), nn.errors, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Number of misclassifications')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
