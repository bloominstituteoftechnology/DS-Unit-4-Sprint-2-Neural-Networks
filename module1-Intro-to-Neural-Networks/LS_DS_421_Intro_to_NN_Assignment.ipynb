{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dVfaLrjLvxvQ"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Neural Networks\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxtoY12mwmih"
   },
   "source": [
    "## Define the Following:\n",
    "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
    "\n",
    "### Input Layer:\n",
    "- The input layer is the beginning of the flow of a neural network. This is the data that is going to be processed by the subsequent layers. The dimensionality of the data is what determines how many nodes make up the input layer.\n",
    "\n",
    "### Hidden Layer:\n",
    "- This is the layer between the input and output layers. The hidden layer takes in the data from the input layer, performs a function on it, then transforms it into outputs.\n",
    "\n",
    "### Output Layer:\n",
    "- The output layer is the results of the transformed data. The number of nodes in the output layer is determined by the number of classes in the data.\n",
    "\n",
    "### Neuron:\n",
    "- Neurons are the individual units that make up a neural network. A neuron is esseantially a function that takes in data, activates/transforms it, and outputs the data.\n",
    "![image](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/47_blog_image_2.png)\n",
    "\n",
    "### Weight:\n",
    "- A weight determines how much significance an input will have on an output. Each input has a weight value associated with it, representing the strength of the connection.\n",
    "\n",
    "### Activation Function:\n",
    "- Also called the transfer function, the activation function determines if the neuron will be activated or not. The purpose of this is to introduce non-linearlity to a model, making it capable of learning and performing more complex tasks.\n",
    "\n",
    "### Node Map:\n",
    "- A node map is a visual diagram of a neural network, showing the path from inputs to outputs. \n",
    "\n",
    "### Perceptron:\n",
    "- Perceptron is a single layer of a neural network. It takes each input, multiplies it by the weight, sums the products, and passes it through the activation function.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXuy9WcWzxa4"
   },
   "source": [
    "## Inputs -> Outputs\n",
    "\n",
    "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PlSwIJMC0A8F"
   },
   "source": [
    "\n",
    "![image](https://miro.medium.com/max/1170/1*lk7bbg9gbYKpDYSHABaDOg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sWR43PTwhSk"
   },
   "source": [
    "## Write your own perceptron code that can correctly classify a NAND gate. \n",
    "\n",
    "| x1 | x2 | y |\n",
    "|----|----|---|\n",
    "| 0  | 0  | 1 |\n",
    "| 1  | 0  | 1 |\n",
    "| 0  | 1  | 1 |\n",
    "| 1  | 1  | 0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sgh7VFGwnXGH"
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "inputs = np.array([[1,0,0],[1,1,0],[1,0,1],[1,1,1]])\n",
    "correct_outputs = [[1], [1], [1], [0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid activation function and derivative\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1-sx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22123647],\n",
       "       [-0.73027631],\n",
       "       [ 0.1360908 ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize random weights for inputs\n",
    "\n",
    "weights = 2 * np.random.random((3,1)) - 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights after training\n",
      "[[10.87158056]\n",
      " [-7.210552  ]\n",
      " [-7.21055151]]\n",
      "Output after training\n",
      "[[0.99998095]\n",
      " [0.97491392]\n",
      " [0.97491394]\n",
      " [0.02796291]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1000):\n",
    "    \n",
    "    # Weighted sum of inputs/weights\n",
    "    weighted_sum = np.dot(inputs, weights)\n",
    "    \n",
    "    # Activate\n",
    "    activated_outputs = sigmoid(weighted_sum)\n",
    "    \n",
    "    # Calculate error\n",
    "    error = correct_outputs - activated_outputs\n",
    "    \n",
    "    # Adjsutments\n",
    "    adjustments = error * sigmoid_derivative(activated_outputs)\n",
    "    \n",
    "    weights += np.dot(inputs.T, adjustments)\n",
    "    \n",
    "print(\"Weights after training\")\n",
    "print(weights)\n",
    "    \n",
    "print(\"Output after training\")\n",
    "print(activated_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = [0, 1, 0, 1]\n",
    "x2 = [0, 0, 1, 1]\n",
    "\n",
    "x = [0, 1, 0]\n",
    "y = [0, 0, 1]\n",
    "\n",
    "plt.scatter(x, y, color='red', marker='o', label='y = one')\n",
    "plt.scatter(1,1, color='blue', marker='x', label='y = zero')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend(loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xf7sdqVs0s4x"
   },
   "source": [
    "## Implement your own Perceptron Class and use it to classify a binary dataset like: \n",
    "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
    "- [Titanic](https://raw.githubusercontent.com/ryanleeallred/datasets/master/titanic.csv)\n",
    "- [A two-class version of the Iris dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/Iris.csv)\n",
    "\n",
    "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-W0tiX1F1hh2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0    male  22.0                        1                        0   7.2500  \n",
       "1  female  38.0                        1                        0  71.2833  \n",
       "2  female  26.0                        0                        0   7.9250  \n",
       "3  female  35.0                        1                        0  53.1000  \n",
       "4    male  35.0                        0                        0   8.0500  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"Survived\"].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.,  3.],\n",
       "       [38.,  1.],\n",
       "       [26.,  3.],\n",
       "       ...,\n",
       "       [ 7.,  3.],\n",
       "       [26.,  1.],\n",
       "       [32.,  3.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[[\"Age\", \"Pclass\"]].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "  def __init__(self, rate = 0.01, niter = 10):\n",
    "    self.rate = rate\n",
    "    self.niter = niter\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"Fit training data\n",
    "    X : Training vectors, X.shape : [#samples, #features]\n",
    "    y : Target values, y.shape : [#samples]\n",
    "    \"\"\"\n",
    "\n",
    "    # weights\n",
    "    self.weight = np.zeros(1 + X.shape[1])\n",
    "\n",
    "    # Number of misclassifications\n",
    "    self.errors = []  # Number of misclassifications\n",
    "\n",
    "    for i in range(self.niter):\n",
    "      err = 0\n",
    "      for xi, target in zip(X, y):\n",
    "        delta_w = self.rate * (target - self.predict(xi))\n",
    "        self.weight[1:] += delta_w * xi\n",
    "        self.weight[0] += delta_w\n",
    "        err += int(delta_w != 0.0)\n",
    "      self.errors.append(err)\n",
    "    return self\n",
    "\n",
    "  def net_input(self, X):\n",
    "    \"\"\"Calculate net input\"\"\"\n",
    "    return np.dot(X, self.weight[1:]) + self.weight[0]\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Return class label after unit step\"\"\"\n",
    "    return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QR4oAW1xdyu"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
    "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
    "- Try and implement your own backpropagation algorithm.\n",
    "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_431_Intro_to_NN_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
