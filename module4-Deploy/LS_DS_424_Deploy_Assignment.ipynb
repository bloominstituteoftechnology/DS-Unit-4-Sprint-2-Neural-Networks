{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_424_Deploy_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "py37  (Python3)",
      "language": "python",
      "name": "py37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanleeallred/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/module4-Deploy/LS_DS_424_Deploy_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# *Data Science Unit 4 Sprint 2 Assignment 4*\n",
        "\n",
        "Continue to use TensorFlow Keras and a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Apply regularization techniques to your model. \n",
        "\n",
        "**Don't forget to switch to GPU on Colab!**\n",
        "\n",
        "\n",
        "## Objective \n",
        "\n",
        "You were exposed to Lp space regularization, Max Norn weight constraints, and dropout in the lecture. \n",
        "\n",
        "In this assignment, you will run several experiments to perform a deeper analysis of various regularization techniques' effects on model performance and the learned model weights. \n",
        "\n",
        "By the end of this assignment, these regularization techniques should no longer feel like black boxes to you (i.e., completely mysterious as to how they work.) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJ2b3wk62Ud"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy"
      },
      "source": [
        "# native libraries \n",
        "import os\n",
        "from time import time \n",
        "\n",
        "# data analysis libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# deep learning libraries \n",
        "from keras import Sequential\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Flatten, Dense, Dropout\n",
        "from keras.layers import ReLU\n",
        "from keras.initializers import GlorotUniform\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# regularizers \n",
        "from keras.regularizers import l2, l1\n",
        "from keras.constraints import MaxNorm\n",
        "\n",
        "# required for compatibility between sklearn and keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# native python unit test library\n",
        "from unittest import TestCase\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4iRIkW2pVGR"
      },
      "source": [
        "-----\n",
        "\n",
        "# $L_p$ Space Regularization \n",
        "\n",
        "## Bridging Theory and Practice \n",
        "\n",
        "The idea of infinitely many vector spaces, each with its very own distance metric for measuring distance differently, can seem very abstract. However, we will take that distance metric general formula and look at a few special cases by writing custom regularization functions and noting their effect on the model's learning outcomes. \n",
        "\n",
        "Don't forget to review the theory of $L_p$ Space Regularization in the guided project. \n",
        "\n",
        "Also, watch this video if you haven't already. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfdD8qcppVGT"
      },
      "source": [
        "# check out this video for an animated explanation of Lp Space and distance metrics \n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('FiSy6zWDfiA', width=800, height=300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY225z9BpVGU"
      },
      "source": [
        "### Distance Metric General Formula\n",
        "$${\\displaystyle \\left\\|x\\right\\|_{p}=\\left(|x_{1}|^{p}+|x_{2}|^{p}+\\dotsb +|x_{n}|^{p}\\right)^{1/p}.}$$\n",
        "\n",
        "Let's create a class for the distance metric general formula.\n",
        "\n",
        "\n",
        "There are 2 classes below: \n",
        "\n",
        "```python\n",
        "class Test_distance_metric_solution()\n",
        "```\n",
        "\n",
        "You don't need to change anything in this class. This class is here to calculate each portion of the distance metric general formula correctly.\n",
        "\n",
        "\n",
        "```python\n",
        "class Lp_distance_metric_general_formula()\n",
        "```\n",
        "\n",
        "This is the class that you will complete. \n",
        "\n",
        "Each of the non `__call__` methods calculates one portion of the distance metric general formula. \n",
        "\n",
        "Breaking up each portion of the formula into a separate method is unnecessary. \n",
        "\n",
        "Including the entire calculation of the general formula into a single method is ideal, however it is more difficult to write granular unit tests that way. \n",
        "\n",
        "So, for instructional purposes, it was broken up into 3 methods. However, outside of an academic environment, we would only need the `__init__` and `__call__` methods. \n",
        "\n",
        "It is good for you to see how a custom unit test class is used to test the calculations of another class. This is a portion of what software engineering looks like. Get used to it. You'll need good software engineering practices to make it in the world. You'll learn more about this in your CS unit. For now, consider it a bit of foreshadowing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nec3V1gZpVGV"
      },
      "source": [
        "class Test_distance_metric_solution(TestCase):\n",
        "    \"\"\"\n",
        "    This unit test class is designed to ensure that the students correctly calculates each Distance Metric General Formula component, thereby getting real-time feedback and correction. \n",
        "    \"\"\"\n",
        "    \n",
        "    def test_squared_vector_comps(self, test_array):\n",
        "        \"\"\"\n",
        "        This test makes sure that students calculate the sum_of_squared_comp correctly. \n",
        "        \"\"\"\n",
        "        answer = np.array([1., 4.])\n",
        "        # error message in case if test case got failed\n",
        "        message = \"you did not calculate sum_of_squared_comp correctly\"\n",
        "        # assert function() to check if values are almost equal\n",
        "        np.testing.assert_array_equal(answer, test_array,  err_msg=message)\n",
        "        \n",
        "        \n",
        "    def test_sum_of_squared_comp(self, test_sum):\n",
        "        \"\"\"\n",
        "        This test makes sure that students calculate the sum_of_squared_comp correctly. \n",
        "        \"\"\"\n",
        "        answer = 5\n",
        "        # error message in case if test case got failed\n",
        "        message = \"you did not calculate sum_of_squared_comp correctly\"\n",
        "        # assert function() to check if values are almost equal\n",
        "        np.testing.assert_array_equal(answer, test_sum,  err_msg=message)\n",
        "        \n",
        "    def test_vector_norm(self, test_norm):\n",
        "        \"\"\"\n",
        "        This test makes sure that students calculate the vector_norm correctly. \n",
        "        \"\"\"\n",
        "        answer = 2.236\n",
        "        decimalPlace = 3\n",
        "        # error message in case if test case got failed\n",
        "        message = \"you did not calculate sum_of_squared_comp correctly\"\n",
        "        # assert function() to check if values are almost equal\n",
        "        self.assertAlmostEqual(answer, test_norm,  decimalPlace, message)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzlyrAUfpVGW"
      },
      "source": [
        "### Fill in the Missing Code in the Class Below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b8830110178a58a6fe1973906f649d36",
          "grade": false,
          "grade_id": "cell-0bd59a2d10fbf254",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "GzA8-uanpVGX"
      },
      "source": [
        "class Lp_distance_metric_general_formula(object):\n",
        "    \"\"\"\n",
        "    This class takes the Lp distance metric general formula and sets p equal to a value provided by the user. \n",
        "    This has the effect of deriving a distance metric for a specific metric space and calculating the distance \n",
        "    of a vector in that metric space.\n",
        "    \n",
        "    Example\n",
        "    -------\n",
        "    If the user sets p = 2, then the euclidean distance formula is derived.\n",
        "    If the user sets p = 1, then the taxicab distance formula is derived. \n",
        "    \n",
        "    Note\n",
        "    ----\n",
        "    It is possible to use p values less than 1, but those are special cases that we will ignore. \n",
        "    These special values are interesting for academic purposes, but in practice, you very likely won't need to know \n",
        "    about them.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p=2, reg_strength = 1.0):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        \n",
        "        p: int or float\n",
        "            p-value used for calculating the distance of a vector in a certain metric space\n",
        "            \n",
        "        reg_strength: int or float\n",
        "            usually set to a value less than 1.0 to decrease the strength of the distance metric when used as a model regularizer\n",
        "            keep this value at 1.0 when measuring vector norms (i.e., vector lengths)\n",
        "        \"\"\"\n",
        "        \n",
        "        assert p >=1 , \"p-value must be greater than or equal to 1\"\n",
        "        \n",
        "        self.p = p\n",
        "        self.reg_strength = reg_strength\n",
        "                \n",
        "    def calc_squared_vector_comps(self):\n",
        "    \n",
        "        # raise each vector component in self.x to the power of p\n",
        "        # save result to self.squared_vector_comps\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def calc_sum_of_squared_comp(self):\n",
        "        # take the sum of the squared components in self.squared_vector_comps\n",
        "        # save to self.sum_of_squared_comp\n",
        "        # hint: use tf.reduce_sum\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def calc_vector_norm(self):\n",
        "        \n",
        "        # take the 1/p root of the self.sum_of_squared_comp in order to calculate the norm, i.e. ||x||\n",
        "        # save result to self.vector_norm\n",
        "        # YOUR CODE HERE\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "        \n",
        "    def __call__(self, x):\n",
        "        \"\"\"\n",
        "        This method calculates the distance (i.e., norm) for vector x in Lp space for a value p given by the use.\n",
        "        \n",
        "        ‚Äñùë•‚Äñùëù = (|ùë•_1|^ùëù + |ùë•_2|^ùëù + ‚ãØ +|ùë•_ùëõ|^ùëù )^1/ùëù\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x: N-dimensional NumPy array or tensorflow tensor of floats \n",
        "            x is our vector, could be a weight vector, but any vector is valid \n",
        "            \n",
        "            \n",
        "        HINT\n",
        "        -----\n",
        "        It would help if you used self.p when calculating squared_vector_comps and vector_norm   \n",
        "        \"\"\"\n",
        "        \n",
        "        self.x = x\n",
        "        \n",
        "        # calculate these parts |ùë•_i|^ùëù\n",
        "        self.calc_squared_vector_comps()\n",
        "        \n",
        "        # calculate this |ùë•_1|^ùëù + |ùë•_2|^ùëù + ‚ãØ +|ùë•_ùëõ|^ùëù\n",
        "        self.calc_sum_of_squared_comp()\n",
        "        \n",
        "        # calculate this (|ùë•_1|^ùëù + |ùë•_2|^ùëù + ‚ãØ +|ùë•_ùëõ|^ùëù )^1/ùëù\n",
        "        self.calc_vector_norm()\n",
        "        \n",
        "        # return the vector norm scaled by a regularization penalty\n",
        "        # we say penalty because the value is usually less than 1.0 thereby scaling down the norm\n",
        "        return self.reg_strength * self.vector_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYy6mbdVpVGY"
      },
      "source": [
        "------\n",
        "### Unit Test Your Code\n",
        "\n",
        "You know you wrote your class correctly when all the unit tests pass. \n",
        "\n",
        "So the code in the following cell should run without throwing a single error. \n",
        "\n",
        "Protip: you can comment out the 2nd and 3rd unit test to test your results for the first method and then uncomment as you go. Feel free to create a new cell and run your testing there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5NxP9SLpVGY"
      },
      "source": [
        "# instantiate the unit test class that will check the calculates of Lp_distance_metric_general_formula's methods\n",
        "tests = Test_distance_metric_solution()\n",
        "\n",
        "# instantiate Lp_distance_metric_general_formula, set p = 2 in order to derive the euclidean distance metric\n",
        "lp = Lp_distance_metric_general_formula( p=2, reg_strength = 1.0)\n",
        "\n",
        "# don't change this test_vector\n",
        "# Test_distance_metric_solution assumes that you're using ths exact test_vector\n",
        "test_vector = np.array([1., 2.])\n",
        "lp(test_vector)\n",
        "\n",
        "# test the calculations that are performed in each of the following lp class methods \n",
        "tests.test_squared_vector_comps(lp.squared_vector_comps)\n",
        "tests.test_sum_of_squared_comp(lp.sum_of_squared_comp)\n",
        "tests.test_vector_norm(lp.vector_norm.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hT7iIwxpVGZ"
      },
      "source": [
        "# note: because we use tf.reduce_sum to calculate sum_of_squared_comp\n",
        "# the result is inside of a tensor and we need to use .numpy() to get the scalar out of the tensor \n",
        "print (lp.vector_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jVhEpLCpVGZ"
      },
      "source": [
        "print (lp.vector_norm.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXV065JspVGZ"
      },
      "source": [
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiX087upVGa"
      },
      "source": [
        "### Apply Our $L_p$ Space Class\n",
        "\n",
        "Next, we will use our distance metric class to calculate our vector's euclidean and taxicab distance below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd1yFi-2pVGa"
      },
      "source": [
        "# W is a 2D vector with an x and y component, i.e. (x, y) = (4,3)\n",
        "w = np.array([4., 3.])\n",
        "\n",
        "# origin point - we need to specify the starting point for plotting\n",
        "origin = np.array([0,0])\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = plt.axes()\n",
        "\n",
        "ax.arrow(origin[0], origin[1], w[0], w[1], head_width=0.5, head_length=0.7, fc='lightblue', ec='black')\n",
        "\n",
        "plt.grid()\n",
        "plt.yticks(np.arange(0,5))\n",
        "plt.xticks(np.arange(0,6));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6ciqvcBpVGa"
      },
      "source": [
        "## Derive Euclidean Distance From the General Formula \n",
        "\n",
        "Below is the general formula for distance metrics. Where we have an N-dimensional weight vector **w**, notice that the general formula has a vector component for each N dimension. Hence, it is the general formula.\n",
        "\n",
        "$${\\displaystyle \\left\\|\\textbf{w}\\right\\|_{p}=\\left(|w_{1}|^{p}+|w_{2}|^{p}+\\dotsb +|w_{n}|^{p}\\right)^{1/p}.}$$\n",
        " \n",
        "\n",
        "Let N = 2 such that our weight vector now exists in 2-dimensional space. \n",
        "\n",
        "Let p = 2 such that our weight vector's distance will be calculated in $L_{p=2}$ space.\n",
        "\n",
        "In which case, our general formula gets reduced from N-dimensions to 2-dimensions. So now we only need to consider a distance formula for a vector with 2 components, one for each dimension.\n",
        "\n",
        "$$||\\textbf{w}||_{p=2} = ((x_2 - x_1)^2 + (y_2 - y_1)^2)^{1/2}$$\n",
        "\n",
        "Now re-express the square root, and we arrive at the familiar euclidean distance from high school algebra. \n",
        "\n",
        "$$||\\textbf{w}||_{p=2} = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$\n",
        "\n",
        "\n",
        "You might wonder why the general case doesn't differ for the components, but the euclidean distance explicitly shows the component-wise differences. It is common in mathematics to suppress certain information, especially if it is \"obvious\" - however, it is highly relative. \n",
        "\n",
        "The general formula assumes that the vector starts at the origin, in which case, there's no need to show the subtraction of zero from a vector component. \n",
        "\n",
        "Assuming that our vector starts at the origin (and it does), the formula can be reduced to \n",
        "\n",
        "$$||\\textbf{w}||_{p=2} = \\sqrt{(x_2 - 0)^2 + (y_2 - 0)^2}$$\n",
        "\n",
        "$$||\\textbf{w}||_{p=2} = \\sqrt{x_2^2 + y_2^2}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtzoTS4KpVGa"
      },
      "source": [
        "### Euclidean Distance of Our Vector \n",
        "\n",
        "With **p=2** in our `Lp_distance_metric_general_formula` class, we can calculate the euclidean distance of our vector **w**. Therefore, I encourage you to either solve the euclidean distance of our vector either in your head or on paper to prove to yourself that the above formula that we derived works and gives you `5` as an answer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bf0cdea85e37c69f73956bf851cba8d6",
          "grade": false,
          "grade_id": "cell-74dae14f4bbad1ab",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3THiIg4NpVGb"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i80uH20KpVGb"
      },
      "source": [
        "-----\n",
        "\n",
        "## Derive Taxicab Distance From the General Formula \n",
        "\n",
        "This formula is the general formula for distance metrics. Where we have an N-dimensional weight vector **w**, notice that the general formula has a vector component for each N dimensions. Hence, it is the general formula.\n",
        "\n",
        "$${\\displaystyle \\left\\|\\textbf{w}\\right\\|_{p}=\\left(|w_{1}|^{p}+|w_{2}|^{p}+\\dotsb +|w_{n}|^{p}\\right)^{1/p}.}$$\n",
        " \n",
        "\n",
        "Let N = 2 such that our weight vector now exists in 2-dimensional space. \n",
        "\n",
        "Let p = 1 such that our weight vector's distance will be calculated in $L_{p=1}$ space \n",
        "\n",
        "\n",
        "In which case, our general formula gets reduced from N-dimensions to 2-dimensions. So now we only need to consider a distance formula for a vector with 2 components, one for each dimension.\n",
        "\n",
        "$$||\\textbf{w}||_{p=1} = ((x_2 - x_1)^1 + (y_2 - y_1)^1)^{1/1}$$\n",
        "\n",
        "There's no need to express all those 1's\n",
        "\n",
        "$$||\\textbf{w}||_{p=1} = (x_2 - x_1) + (y_2 - y_1) $$\n",
        "\n",
        "Assuming that our vector starts at the origin (which it does)\n",
        "\n",
        "$$||\\textbf{w}||_{p=1} = (x_2 - 0) + (y_2 - 0) $$\n",
        "\n",
        "\n",
        "\n",
        "$$||\\textbf{w}||_{p=1} = x + y $$\n",
        "\n",
        "We have just derived the taxicab distance metric from the general formula. The above equation tells us to add up all the x and y-direction steps to calculate the Taxicab distance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghRTEZgJpVGb"
      },
      "source": [
        "### Taxicab distance of our Vector \n",
        "\n",
        "With **p=1** in our `Lp_distance_metric_general_formula` class, we can calculate the taxicab distance of our vector **w**. This distance we can easily calculate in our head. Look at the vector plot and add up all the x and y components, i.e., count up all the steps you have to take to \"walk\" from the origin to the head of the vector. Do this to prove to yourself that the taxicab distance of our vector is `7`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9a527c635255f30979d1759e4ecc480d",
          "grade": false,
          "grade_id": "cell-9bf41d7142ad35e9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "BMLafKBPpVGb"
      },
      "source": [
        "# use Lp_distance_metric_general_formula class to calculate the taxicab distance of w\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msu3E_XIpVGc"
      },
      "source": [
        "### Elastic Net Distance \n",
        "\n",
        "\n",
        "Elastic Net is a combination of L1 and L2. Compare the geometry below. \n",
        "\n",
        "![](https://ds100.org/sp17/assets/notebooks/linear_regression/norm_balls.png)\n",
        "\n",
        "The mathematical derivation of the distance metric for  $L_{p=3/2}$ space will be left to you as an optional exercise. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0f19be155b2e5be75c855710eab34cdd",
          "grade": false,
          "grade_id": "cell-d657c845dbb1ab23",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "bwkcuPDcpVGc"
      },
      "source": [
        "# use Lp_distance_metric_general_formula class to calculate the Elastic Net distance of w\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVo2vFzVpVGc"
      },
      "source": [
        "-----\n",
        "\n",
        "## Use Custom Lp Space Class in Modeling\n",
        "\n",
        "Let's create a function that returns compiled keras models so that we can run an experiment in order to compare the modeling results from using a keras L2 and our custom L2 regularizer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHfaf24qpVGc"
      },
      "source": [
        "-----\n",
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXxiW2mopVGc"
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load in and normalize the image data set\n",
        "    \"\"\"\n",
        "    \n",
        "    # load in our dataset \n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # normalize pixel values between 0 and 1 \n",
        "    max_pixel_value = X_train.max()\n",
        "    X_train, X_test = X_train /max_pixel_value , X_test / max_pixel_value\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kopv9HFcpVGc"
      },
      "source": [
        "X_train, y_train, X_test, y_test = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrOV89eypVGd"
      },
      "source": [
        "# this is equal to the number of nodes in the output layer\n",
        "N_labels = len(np.unique(y_train))\n",
        "N_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeUVmADkpVGd"
      },
      "source": [
        "def create_model(reg=None):\n",
        "    # instantiate Sequential class\n",
        "    model = Sequential([\n",
        "\n",
        "    # flatten images \n",
        "        Flatten(input_shape=(28,28)), # images will be flattend out to 784 dims row vectors \n",
        "\n",
        "    # hidden layer 1\n",
        "        Dense(500, kernel_regularizer=reg),\n",
        "\n",
        "    # act func 1\n",
        "        ReLU(negative_slope=0.01),\n",
        "\n",
        "    # output layer \n",
        "        Dense(10, activation =\"softmax\")   \n",
        "    ])\n",
        "\n",
        "    # compile model \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                  optimizer= \"adam\", \n",
        "                  metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu_L8DqwpVGd"
      },
      "source": [
        "----\n",
        "\n",
        "## Experiment 1: Calculate Vector Lengths Using Keras and Custom Regularizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyImp6cgpVGd"
      },
      "source": [
        "\n",
        "\n",
        "If you read the [**Keras Documentation**](https://keras.io/api/layers/regularizers/) for their implementation of L2 regularization, you'll see this:\n",
        "\n",
        "    The L2 regularization penalty is computed as: loss = l2 * reduce_sum(square(x))\n",
        "    \n",
        "Notice that Keras isn't taking the square root for L2 whereas we are taking the square root.\n",
        "\n",
        "Why isn't Keras taking the square root? I don't know, but we will stay true to the math and take the square root for our implementation of L2 regularization. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD8SmKfgpVGd"
      },
      "source": [
        "custom_l2 = Lp_distance_metric_general_formula(p=2, reg_strength = 1.0)\n",
        "# the length of the W vector from above as calculated by the formula that we derived \n",
        "custom_l2(W).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I1aE-O9pVGd"
      },
      "source": [
        "from keras.regularizers import L2\n",
        "keras_l2 = L2(l2=1.0)\n",
        "# again Keras doesn't take the square root\n",
        "keras_l2(W).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGYuR3ikpVGe"
      },
      "source": [
        "# but if we take the square root, then we get the same answer that our custom regularizer class gives us \n",
        "np.sqrt(keras_l2(W).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTBbzHFXpVGe"
      },
      "source": [
        "----\n",
        "## Experiment 2: Compare Keras L2 and Custom L2 Regularization in a Model\n",
        "\n",
        "\n",
        "### Use Keras Built-in L2 Regularizer \n",
        "\n",
        "Make sure to use the same regularization strength in the Keras pre-built L2 regularizer and our custom L2 regularizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c18sXQmJpVGe"
      },
      "source": [
        "model_keras_l2 = create_model(reg=L2(l2=0.01))\n",
        "keras_l2_results = model_keras_l2.fit(X_train, y_train,\n",
        "                                      epochs=1,\n",
        "                                      validation_data=(X_test, y_test), \n",
        "                                      workers=10) # check! You might not be able to use 10 processors on your machine "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6y0exm1pVGe"
      },
      "source": [
        "### Use Custom Regularization Class \n",
        "\n",
        "Make sure to use the same regularization strength in the Keras pre-built L2 regularizer and our custom L2 regularizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N_n4ZdNpVGf"
      },
      "source": [
        "# set p= 2 so that we are using the same L2 regularizer as above\n",
        "lp = Lp_distance_metric_general_formula(p=2, reg_strength = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGmzLHkepVGf"
      },
      "source": [
        "model_custom_l2 = create_model(reg=lp)\n",
        "custom_l2_results = model_custom_l2.fit(X_train, y_train,\n",
        "                                      epochs=1,\n",
        "                                      validation_data=(X_test, y_test), \n",
        "                                      workers=10) # check! You might not be able to use 10 processors on your machine "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5cdq1n1pVGf"
      },
      "source": [
        "----\n",
        "### Compare Model Results\n",
        "\n",
        "Let's compare the modeling results between the two models. \n",
        "\n",
        "Whatever the specific test accuracies are, it should be the case that using our custom class leads to slightly better results than using the Keras version of $L_2$ regularization.\n",
        "\n",
        "There is a small difference between test accuracies, possiblly due to the random sampling for the initial weight values. But also possibly from the observation that we made above - Keras isn't taking the square root. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGzW7n7apVGf"
      },
      "source": [
        "_, keras_acc = model_keras_l2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PUfFGYBpVGf"
      },
      "source": [
        "_, custom_acc = model_custom_l2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhvfMYxdpVGf"
      },
      "source": [
        "\n",
        "### Conclusion \n",
        "\n",
        "In this experiment, we have bridged the gap between the theory of **$L_p$ Space Regularization** and the practice of using the general formula as a starting point to derive and build our very own regularizers. \n",
        "\n",
        "This experiment (and the perceptron that we built from scratch in Sprint 2 Module 1) are examples of **mathematical algorithms** - an algorithm in mathematics is a procedure, a description of a set of steps that can be used to solve a mathematical computation.\n",
        "\n",
        "It's one thing to use open-source pre-built mathematical algorithms like Keras regularizers and Sklearn ML models, but building them from scratch is quite another thing. \n",
        "\n",
        "You'll need to know when you should build something from scratch and when to use an open-source solution in the industry. The rule of thumb is don't build it if someone else already has because maintaining the code and fixing bugs is something that other developers (i.e., the open-source community) can spend their time on, and you don't have to. But if an open-source solution doesn't exist for a solution you need, you'll need to build it or try an alternative solution.\n",
        "\n",
        "It's a good thing you're taking the time to practice building some mathematical algorithms from scratch. It's a very valuable skill to have. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8_vE67ppVGg"
      },
      "source": [
        "-----\n",
        "# GridSearch Experiments \n",
        "\n",
        "The next set of experiments will all involve gridsearching regularization parameter values. \n",
        "\n",
        "The rest of the notebook will require very little coding on your part. Instead, the focus is to run those gridsearches and answer the questions at the end of each experiment. Those questions are designed to help you capture the insights that there are to learn from each experiment. \n",
        "\n",
        "The following experiments are designed to help you better understand the relationship between the various regularization techniques and how they affect model performance. \n",
        "\n",
        "\n",
        "### Build Model\n",
        "\n",
        "Let's build out the model that we'll be using throughout our experiments. \n",
        "\n",
        "Remember that **the whole point of regularization is to prevent overfitting.**\n",
        "\n",
        "\n",
        "![](https://hackernoon.com/hn-images/1*vuZxFMi5fODz2OEcpG-S1g.png)\n",
        "\n",
        "Overfitting happens when our models are too complex, so to benefit from regularization techniques, we need to build a relatively complex model. \n",
        "\n",
        "You might not have the computational resource to train a complex model in a reasonable amount of time. So if this describes you, then you might want to consider using `build_simple_model`. Otherwise, I recommend that you use `build_complex_model`. \n",
        "\n",
        "This notebook will be using  `build_complex_model` to run our experiments. \n",
        "\n",
        "**NOTE:** Whichever function you use to build a model, take time to read through the code and make sure you understand what is happening. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqm8Ix_hpVGg"
      },
      "source": [
        "def build_complex_model(Lp_reg=None, reg_penality=None, dropout_prob=0.0, maxnorm_wc=None):\n",
        "    \"\"\"\n",
        "    Build and return a regularized 3 hidden layer FCFF model \n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    Lp_reg: None or object\n",
        "        If object, Lp_reg is either l1 or l2 regularization \n",
        "        If None, that means that l1 or l2 regularization will not be used.\n",
        "     \n",
        "    reg_penality: None or float\n",
        "        If float, reg_penality is a value typically between 1.0 and 0.0001\n",
        "        This is the regularization strength for l1 or l2 \n",
        "        \n",
        "        \n",
        "    dropout_prob: float\n",
        "        This is the probability that dropout regularization will exclude a node from a training iteration. \n",
        "        If this value is 0.0, that means that dropout will not be used. \n",
        "        \n",
        "    maxnorm_wc: None or float\n",
        "        If float, maxnorm_wc is the weight constraint that is used for Max Norm regularization\n",
        "        If None, that means that Max Norm regularization will not be used.\n",
        "        \n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    model: compiled Keras model\n",
        "    \"\"\"\n",
        "    \n",
        "    # if reg_type is not None, then pass in the penality strength to whatever form of Lp space regularization this is \n",
        "    if Lp_reg is not None:\n",
        "        Lp_regularizer = Lp_reg(reg_penality)\n",
        "    else:\n",
        "        Lp_regularizer = None\n",
        "                \n",
        "    if maxnorm_wc is not None:\n",
        "        wc = MaxNorm(max_value=maxnorm_wc)\n",
        "    else:\n",
        "        wc = None\n",
        "\n",
        "\n",
        "    # instantiate Sequential class\n",
        "    model = Sequential([\n",
        "\n",
        "    # flatten images \n",
        "    Flatten(input_shape=(28,28)),\n",
        "\n",
        "    # hidden layer 1\n",
        "    Dense(500, kernel_regularizer=Lp_regularizer , kernel_constraint=wc), # remember that Keras refers to weight matrix as a kernel, i.e. weights = kernel\n",
        "    # act func 1\n",
        "    ReLU(negative_slope=0.01),\n",
        "    Dropout(dropout_prob),\n",
        "\n",
        "    # hidden layer 2\n",
        "    Dense(250, kernel_regularizer=Lp_regularizer, kernel_constraint=wc),\n",
        "    # act func 2\n",
        "    ReLU(negative_slope=0.01),\n",
        "    Dropout(dropout_prob),\n",
        "\n",
        "    # hidden layer 3\n",
        "    Dense(100, kernel_regularizer=Lp_regularizer, kernel_constraint=wc),\n",
        "    # act func 2\n",
        "    ReLU(negative_slope=0.01),\n",
        "    Dropout(dropout_prob),\n",
        "\n",
        "    # output layer   \n",
        "    Dense(N_labels, activation=\"softmax\")  \n",
        "\n",
        "    ])\n",
        "    # compile model \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                 optimizer=\"adam\", \n",
        "                 metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0RsVlytpVGg"
      },
      "source": [
        "Again, only use `build_simple_model` instead of `build_complex_model` if you're working on a machine with a very limited computational resource. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2dSG5sbpVGg"
      },
      "source": [
        "# def build_simple_model(Lp_reg=None, reg_penality=None, dropout_prob=0, maxnorm_wc=None):\n",
        "#     \"\"\"\n",
        "#     Build and return a regularized 1 hidden layer FCFF model \n",
        "    \n",
        "#     Parameters\n",
        "#     ----------\n",
        "#     Lp_reg: None or object\n",
        "#         If object, Lp_reg is either l1 or l2 regularization \n",
        "#         If None, that means that l1 or l2 regularization will not be used.\n",
        "     \n",
        "#     reg_penality: None or float\n",
        "#         If float, reg_penality is a value typically between 1.0 and 0.0001\n",
        "#         This is the regularization strength for l1 or l2 \n",
        "        \n",
        "        \n",
        "#     dropout_prob: float\n",
        "#         This is the probability that dropout regularization will exclude a node from a training iteration. \n",
        "#         If this value is 0.0, that means that dropout will not be used. \n",
        "        \n",
        "#     maxnorm_wc: None or float\n",
        "#         If float, maxnorm_wc is the weight constraint that is used for Max Norm regularization\n",
        "#         If None, that means that Max Norm regularization will not be used.\n",
        "        \n",
        "        \n",
        "#     Return\n",
        "#     ------\n",
        "#     model: compiled Keras model\n",
        "#     \"\"\"\n",
        "    \n",
        "#     if Lp_reg is not None:\n",
        "#         Lp_regularizer = Lp_reg(reg_penality)\n",
        "#     else:\n",
        "#         Lp_regularizer = None\n",
        "\n",
        "#     # instantiate Sequential class\n",
        "#     model = Sequential([\n",
        "\n",
        "#     # flatten images \n",
        "#     Flatten(input_shape=(28,28)),\n",
        "\n",
        "#     # hidden layer 1\n",
        "#     Dense(128,  kernel_regularizer=Lp_regularizer, kernel_constraint=maxnorm_wc), # remember that Keras refers to weight matrix as a kernel, i.e. weights = kernel\n",
        "#     # act func 1\n",
        "#     ReLU(negative_slope=0.01),\n",
        "#     Dropout(p_dropout),\n",
        "\n",
        "#     # output layer   \n",
        "#     Dense(N_labels, activation=\"softmax\")  \n",
        "\n",
        "#     ])\n",
        "#     # compile model \n",
        "#     model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "#                  optimizer=\"adam\", \n",
        "#                  metrics=[\"accuracy\"])\n",
        "    \n",
        "#     return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b61xjXBpVGg"
      },
      "source": [
        "Since we'll be using Sklearn's GridserchCV class, we need to wrap our Keras models in `KerasClassifier`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m7WfjA-pVGh"
      },
      "source": [
        "# remember to wrap KerasClassifier around build_model for sklearn's GridsearchCV compatibility \n",
        "model = KerasClassifier(build_fn = build_complex_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkD-6BpCpVGh"
      },
      "source": [
        "-------\n",
        "\n",
        "# Experiment 1: Identify the Relationship Between Model Performance and L2 Penalty Strength\n",
        "\n",
        "![](https://www.researchgate.net/publication/334159821/figure/fig1/AS:776025558495234@1562030319993/Ridge-regression-variable-selection.png)\n",
        "\n",
        "We will run a gridsearch solely on the l2 regularization penalty value and see the effect on model performance.\n",
        "\n",
        "By running a gridseach on a single hyperparameter (while using the same data and model) we can isolate the effect of that hyperparameter. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu6LRmoppVGh"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hyper_parameters = {\n",
        "    # take note that Lp_reg penalty/strength values are in powers of 10 \n",
        "    \"reg_penalty\": [1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001], \n",
        "    # Since we only want to test l2, provide l2 as the sole option \n",
        "    \"Lp_reg\": [l2],\n",
        "    # default is 1, in order to change it we must provide value here because we can't provide a parameter value for model.fit() directly when using gridsearch\n",
        "    # protip: consider changing epochs to 1 if the gridsearch run-time is too long for you\n",
        "    \"epochs\": [1] \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qPDMf_upVGh"
      },
      "source": [
        "start=time()\n",
        "# Create and run Grid Search\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-3, \n",
        "                    verbose=1, \n",
        "                    cv=2)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "end=time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_h1v4_GpVGh"
      },
      "source": [
        "print(\"Gridsearch runtime {0:.3} mins\".format( (end-start)/60 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlBJNA3qpVGh"
      },
      "source": [
        "# use the mean accuracy from the CV splits for determining best model score \n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "# move l2 penalty values outside of dictionary and into a list\n",
        "param_values = [dic[\"reg_penality\"] for dic in params]\n",
        "\n",
        "# plot accuracy vs l2_reg_penalty\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.grid()\n",
        "\n",
        "# this plot is using the std of the CV splits to plot error bars however those values are so small that they aren't visable\n",
        "plt.errorbar(param_values, means, yerr=stds, ecolor=\"orange\")\n",
        "plt.xscale(\"log\") # use a log scale for ease of reading, recall that l2_reg_penalty were in powers of 10 \n",
        "plt.title(\"L2 Regularization: Model Accuracy vs L2 Penalty Strength\")\n",
        "plt.ylabel(\"Validation Accuracy\", )\n",
        "plt.xlabel(\"L2 Penalty Strength using a Log Scale\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyCsl3XcpVGh"
      },
      "source": [
        "### Observations\n",
        "\n",
        "Write down some observations. What do you notice from the plot?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "089b55b5a84d9c96c51fd341d9e6c74f",
          "grade": true,
          "grade_id": "cell-010212fc0915b976",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ly8MMw5xpVGh"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo3bQsu_pVGi"
      },
      "source": [
        "\n",
        "## Compare Weights Between Best and Worst Model \n",
        "\n",
        "Next, we will compare the hidden layer weights between the best and worst-performing models while noting the respective l2 penalty strengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQo_DOg7pVGi"
      },
      "source": [
        "# get the best l2 penalty term \n",
        "best_lr_penalty = grid_result.best_params_[\"reg_penality\"]\n",
        "\n",
        "# get the best trained model \n",
        "best_model = grid_result.best_estimator_.build_fn(Lp_reg=l2, reg_penalty=best_lr_penalty)\n",
        "\n",
        "# get the weights from the best trained model \n",
        "best_weights = best_model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_DXJH8lpVGi"
      },
      "source": [
        "# train a model using the l2_reg_penalty value at scored the lowest \n",
        "worse_l2_reg_penalty = 1.0\n",
        "\n",
        "worse_model = build_complex_model(Lp_reg=l2, reg_penalty=worse_l2_reg_penalty)\n",
        "\n",
        "# fit model \n",
        "worse_model.fit(X_train, y_train, epochs=1)\n",
        "\n",
        "# get weights from worse performing model \n",
        "worse_weights = worse_model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX1haiBdpVGi"
      },
      "source": [
        "-----\n",
        "## Understanding How Weights and Biases Are Stored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8EvxJiXpVGi"
      },
      "source": [
        "Let's take a minute to understand that`.get_weights()` returns a list with 8 elements (if you're using `build_complex_model`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwmuBYI-pVGi"
      },
      "source": [
        "len(best_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K0ODK_5pVGi"
      },
      "source": [
        "There are **weights matrices and bias vectors between each layer,** and we have five layers. \n",
        "\n",
        "- Input\n",
        "- Hidden 1\n",
        "- Hidden 2\n",
        "- Hidden 3\n",
        "- Output \n",
        "\n",
        "So that means we should have four weight matrices, but we see eight. **This is because there are also four weight vectors for the biases between each layer.** So that accounts for the eight. \n",
        "\n",
        "\n",
        "#### Index for Weight Matrices \n",
        "If you index for a weight matrix, you can see its shape and are indeed matrices. \n",
        "\n",
        "Notice how you can see the dims of the layers that the matrices are sandwiched between?\n",
        "\n",
        "The input layer has 784 dims, and hidden layer 1 has 500 dims. Given this understanding, the numbers you see in the shapes should make sense. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gN5ozNQpVGj"
      },
      "source": [
        "# between input and 1st hidden layer\n",
        "best_weights[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acsqSY-jpVGj"
      },
      "source": [
        "# between 1st and 2nd hidden layer\n",
        "best_weights[2].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORHvjdW_pVGj"
      },
      "source": [
        "# between 2st and 3nd hidden layer\n",
        "best_weights[4].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEn-PGeApVGj"
      },
      "source": [
        "# between 3rd hidden layer and output layer\n",
        "best_weights[6].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZN_t4SupVGj"
      },
      "source": [
        "#### Index for the Bias Vectors\n",
        "\n",
        "The shapes of the bias vectors should exactly match up the dims/nodes of each layer (excluding the input layer). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ft41YyZpVGj"
      },
      "source": [
        "# for hidden layer 1 \n",
        "best_weights[1].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgaFYrrqpVGj"
      },
      "source": [
        "# for hidden layer 2 \n",
        "best_weights[3].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxDbEyqppVGj"
      },
      "source": [
        "# for hidden layer 3\n",
        "best_weights[5].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-O-T-3QpVGk"
      },
      "source": [
        "# for output layer\n",
        "best_weights[7].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM1DajHrpVGk"
      },
      "source": [
        "-----\n",
        "\n",
        "### Back to Our Analysis of L2 Space Regularization (also known as Ridge)\n",
        "\n",
        "Let's compare the first weight matrix (between the input and 1st hidden layer) for the best, and worst-performing model and the initial weight values randomly sampled from the GlorotUniform distribution.\n",
        "\n",
        "[**Check out the Keras docs for the Dense layer**](https://keras.io/api/layers/core_layers/dense/); you'll see that GlorotUniform is the default weight initializer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEYGmSnlpVGk"
      },
      "source": [
        "Before we compare weights, let's take note of the following. \n",
        "\n",
        "Both `best_weights[0]` or `worst_weights[0]` are matrices with shape `(784, 500)`. \n",
        "\n",
        "If we flatten them, then we get `784 * 500 = 392000` weights. What does this mean exactly?\n",
        "\n",
        "Remember that we are working with the 'Fully Connected Forward Feeding' model which looks like this. \n",
        "\n",
        "![](https://pyimagesearch.com/wp-content/uploads/2016/08/simple_neural_network_header.jpg)\n",
        "\n",
        "The important thing to notice is that each component in the input vectors gets passed to all the nodes in the next layer is fully connected models. This means for our input vector with 784 dims, there are 784 **$w_1$** weights, each with a slightly different value, one for each of the 784 components in the input vector. \n",
        "\n",
        "So to keep our analysis simple, we are going to analyze one column of the weight matrix. You could index for whatever column you want, but this notebook will assume that you have indexed the weights in column one. This means we will compare the effect regularization had on all of the 784 **$w_1$** weights in the 500-dimensional space of hidden layer 1. \n",
        "\n",
        "In other words, by looking at just one column, we are narrowing our analysis to the distribution of values for w_1 instead of mixing the distributions of all the weights w_1, w_2, ..., w_500. But, again, this is done for simplicity of analysis, the goal being to observe the effect of regularization on the weights empirically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a3f75126a80a74dd71fb0a9ab2b8b89f",
          "grade": false,
          "grade_id": "cell-7882876b8973bc7b",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "4baJ3DRlpVGk"
      },
      "source": [
        "# index for the 1st column in the 1st hidden layer weights in best_weights and save to best_hidden_weights\n",
        "\n",
        "# index for the 1st column in the 1st hidden layer weights in worst_weights and save to worst_hidden_weights\n",
        "\n",
        "# Keras models samples from the GlorotUniform distribution for the initial values of model weights randomly \n",
        "# instantiate GlorotUniform and sample 500 weights and save to initial_weight_values\n",
        "# hint: use shape=(500,1)\n",
        "\n",
        "# lastly, flatten all of the above 3 variables so that you go from a matrix to a vector \n",
        "# otherwise, pandas will not like you and throw a fit \n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83166EmLpVGk"
      },
      "source": [
        "# move all weights to a dataframe for ease of analysis \n",
        "cols = [\"best_hidden_weights\", \"worst_hidden_weights\", \"initial_weight_values\"]\n",
        "data = [best_hidden_weights, worst_hidden_weights, initial_weight_values]\n",
        "df = pd.DataFrame(data=data).T\n",
        "df.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG-0V1-6pVGk"
      },
      "source": [
        "# check out the statistics for each weight column \n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUtNQVpqpVGk"
      },
      "source": [
        "# plot the distributions for each weight column \n",
        "df.hist(figsize=(20,12));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn5DyFospVGk"
      },
      "source": [
        "## Observations \n",
        "\n",
        "Take a look at the statistical table and the plots. Then answer the following questions. \n",
        "\n",
        "**How do the hidden layer weights from the best performing model compare to the initial weight values?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5eacb66f89b216ae3b4bb3c4b7bd6d38",
          "grade": true,
          "grade_id": "cell-6add7cc400c4c716",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ef7CKUNEpVGk"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqdDDjRdpVGk"
      },
      "source": [
        "**What was the effect of using a small l2 penalty value?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "92ac1689b72d727ab7f4d261c5e76daa",
          "grade": true,
          "grade_id": "cell-5b4f11bba2d49639",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "sQlxzMgZpVGl"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrmN0mKgpVGl"
      },
      "source": [
        "**What was the effect of using a large l2 penalty value?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3048a6d2805f61d6fb58372c42c3ac54",
          "grade": true,
          "grade_id": "cell-0a30b62e5e119555",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "VkttESZSpVGl"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eqj2BzLpVGl"
      },
      "source": [
        "**Given what you know about L2 regularization, are you surprised by these results?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d8a2034f67badfe53f601873f7026dc0",
          "grade": true,
          "grade_id": "cell-c04d067161064011",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "63jFQZnUpVGl"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxTesknfpVGl"
      },
      "source": [
        "----\n",
        "\n",
        "# Experiment 2: Identify the Relationship Between mMdel Performance and Max Norm Weight Constraint\n",
        "\n",
        "![](https://qph.fs.quoracdn.net/main-qimg-9d0dbf8074761b541ba80543ddfc9f73.webp)\n",
        "\n",
        "Recall from the lecture that the **norm** of a vector is just another word for the **length** of a vector.\n",
        "\n",
        "MaxNorm weight constraint puts a limit on the length of a weight vector.\n",
        "\n",
        "$$ \\text{Max_value_of_norm} >= {\\displaystyle \\left\\|x\\right\\|_{p}=\\left(|x_{1}|^{p}+|x_{2}|^{p}+\\dotsb +|x_{n}|^{p}\\right)^{1/p}.}$$  \n",
        "\n",
        "The effect that Lp regularization and 'Max Norm Weight Constraint' have on the weights should be the same, but they go about it differently. \n",
        "\n",
        "Lp regularization (l1/Lasso and l2/Ridge) shrink the value of the weights. At the same time, 'Max Norm Weight Constraint' limits how big the weight vector can be, which, in effect, keeps the individual weight values small enough to keep the norm below that limit. \n",
        "\n",
        "IIn this experiment, we are going to run another gridseach. Still, instead of using Lp space regularization as we did in the previous experiment, we will use MaxNorm and see what kind of effect this type of regularization has on model performance and the learned weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiWKV_CkpVGl"
      },
      "source": [
        "Since we already built our model, we need to update the `hyper_parameters` dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXY7eUs5pVGl"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hyper_parameters = {\n",
        "    \n",
        "    \"maxnorm_wc\": np.linspace(0.5, 10.0, num=20), \n",
        "    # default is 1, in order to change it we must provide value here because we can't provide a parameter value for model.fit() directly when using gridsearch\n",
        "    # protip: consider changing epochs to 1 if the gridsearch run-time is too long for you    \n",
        "    \"epochs\": [1] \n",
        "}\n",
        "\n",
        "hyper_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXF3p3WlpVGl"
      },
      "source": [
        "start=time()\n",
        "# Create and run Gridsearch\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=2)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "end=time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll5oU05RpVGl"
      },
      "source": [
        "print(\"Gridsearch runtime {0:.3} mins\".format( (end-start)/60 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL12Su73pVGl"
      },
      "source": [
        "# use the mean accuracy from the CV splits for determining best model score \n",
        "means = grid.cv_results_['mean_test_score']\n",
        "stds = grid.cv_results_['std_test_score']\n",
        "params = grid.cv_results_['params']\n",
        "\n",
        "# move l2 penalty values outside of dictionary and into a list\n",
        "param_values = [dic[\"maxnorm_wc\"] for dic in params]\n",
        "\n",
        "# plot accuracy vs l2_reg_penalty\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.grid()\n",
        "plt.errorbar(param_values, means, yerr=stds, ecolor=\"orange\")\n",
        "plt.title(\"L1 Regularization: Model Accuracy vs L1 Penalty Strength\")\n",
        "plt.ylabel(\"Validation Accuracy\", )\n",
        "plt.xlabel(\"Max Norm for Weight Vector \");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cfe7bd54a7a14ba7ee63c88d6d1828b4",
          "grade": false,
          "grade_id": "cell-f67372e0b9b30614",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "yDjHSDCapVGo"
      },
      "source": [
        "# get the best l2 penalty term from grid and save to best_max_norm_val\n",
        "\n",
        "# get the best-trained model from grid and save to best_model\n",
        "\n",
        "# get the weights from the best-trained model and save to best_weights\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJkiJWFwpVGo"
      },
      "source": [
        "best_max_norm_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sDvprbjpVGo"
      },
      "source": [
        "# we see that the norm of our weights are indeed below the maximum allowed value \n",
        "np.linalg.norm(best_weights[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "67f65bd636e3b3b3bc7d20c02ba6b666",
          "grade": false,
          "grade_id": "cell-e752c1a8c853985d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "DzVWlPVXpVGp"
      },
      "source": [
        "# train a model using the max_norm_val value that scored the lowest \n",
        "\n",
        "# build a model using build_complex_model and worse_max_norm_val and save it to worst_model\n",
        "\n",
        "# fit model \n",
        "\n",
        "# get weights from worst-performing model \n",
        "\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a38d5d4db707124b31a662fb4743b049",
          "grade": false,
          "grade_id": "cell-5c1aa4543e68487d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7nBulGQqpVGp"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2H1Jop8pVGp"
      },
      "source": [
        "# move all weights to a dataframe for ease of analysis \n",
        "cols = [\"best_hidden_weights\", \"worst_hidden_weights\", \"initial_weight_values\"]\n",
        "data = [best_hidden_weights, worst_hidden_weights, initial_weight_values]\n",
        "df_maxnorm= pd.DataFrame(data=data).T\n",
        "df_maxnorm.columns = cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0e15SNHpVGp"
      },
      "source": [
        "df_maxnorm.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dWttFtopVGp"
      },
      "source": [
        "# plot the distributions for each weight column \n",
        "df_maxnorm.hist(figsize=(20,12));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSckJcg4pVGp"
      },
      "source": [
        "## Observations \n",
        "\n",
        "Take a look at the statistical table and the plots. Then answer the following questions. \n",
        "\n",
        "**How do the hidden layer weights from the best performing model compare to the initial weight values?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f43fe1110cdcea8d1e4b432fe78d4e49",
          "grade": true,
          "grade_id": "cell-40a44d19694941b8",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "2diA2N6upVGp"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqW6nm7lpVGp"
      },
      "source": [
        "**What was the effect of using the weight constraint value in MaxNorm in the best-performing model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b1c59c58a5abdbc0b509983821198dba",
          "grade": true,
          "grade_id": "cell-4f9e1e134124e512",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "upVYTz8vpVGp"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnkgBUdapVGq"
      },
      "source": [
        "**What was the effect of using the weight constraint value in MaxNorm in the worst performing model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0062b4ddfad487c39633c37f4710b752",
          "grade": true,
          "grade_id": "cell-4c289ce70c34048a",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "psau0IuBpVGq"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4qoyDvXpVGq"
      },
      "source": [
        "**Given what you know about MaxNorm regularization, are you surprised by these results?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3c36931d3532a8cbcb4ea0c956378728",
          "grade": true,
          "grade_id": "cell-77366a912217da5d",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "lY99-fdEpVGq"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJBs5R24pVGq"
      },
      "source": [
        "-----\n",
        "# Experiment 3: Identify the Relationship Between Model Performance and Dropout\n",
        "\n",
        "\n",
        "![](https://miro.medium.com/max/981/1*EinUlWw1n8vbcLyT0zx4gw.png)\n",
        "\n",
        "In the 3rd and final experiment, we will use gridsearch to see how model performance is affected by varying the value of the dropout probability. \n",
        "\n",
        "Recall from the lecture that dropout tends to perform best when used with the weight constraint. Since this is the case, we will gridsearch both dropout probability and the weight constraint for MaxNorm.\n",
        "\n",
        "If interested, feel free to read through the original publication on [**Drop Out**](https://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf). \n",
        "\n",
        "**Key Takeaways:** \n",
        "\n",
        "1. During training, dropout will probabilistically \"turn off\" some neurons in the layer that dropout is implemented in. \n",
        "2. All neurons are used during inference (i.e., making predictions on the test set) (i.e., no dropout is applied).\n",
        "3. Dropout works best when used with MaxNorm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_lTEUmvpVGq"
      },
      "source": [
        "# build out our hyperparameter dictionary \n",
        "hyper_parameters = {\n",
        "    # for the sake of runtime, let's vary maxnorm_wc between 0.5 and 5.0\n",
        "    \"maxnorm_wc\": np.linspace(0.5, 5, num=10),\n",
        "    # take note that l1_reg_penalty values are in powers of 10 \n",
        "    \"dropout_prob\": np.linspace(0.0, 0.6, num=7), \n",
        "    \"epochs\": [1] # default is 1, in order to change it we must provide value here because we can provide a parameter value for model.fit() directly when using gridsearch\n",
        "}\n",
        "\n",
        "hyper_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mplKg5iipVGq"
      },
      "source": [
        "start=time()\n",
        "# Create and run GridSearch\n",
        "grid = GridSearchCV(estimator=model, \n",
        "                    param_grid=hyper_parameters, \n",
        "                    n_jobs=-2, \n",
        "                    verbose=1, \n",
        "                    cv=3)\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "end=time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xErt5EpVGq"
      },
      "source": [
        "print(\"Gridsearch runtime {0:.3} mins\".format( (end-start)/60 ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh-GjpDvpVGr"
      },
      "source": [
        "# use the mean accuracy from the CV splits for determining best model score \n",
        "means = grid.cv_results_['mean_test_score']\n",
        "stds = grid.cv_results_['std_test_score']\n",
        "params = grid.cv_results_['params']\n",
        "\n",
        "# move l2 penalty values outside of dictionary and into a list\n",
        "param_values = [dic[\"dropout_prob\"] for dic in params]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRf0Cpp4pVGr"
      },
      "source": [
        "Since there are two independdent variables this time around (dropout_prob and maxnorm_wc) that affect the validation accuracy, it's best to use a different plot. A heat map will work. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX5-DeKKpVGr"
      },
      "source": [
        "dropout_prob_list = [  dic[\"dropout_prob\"]  for dic in params]\n",
        "maxnorm_wc_list = [  dic[\"maxnorm_wc\"]  for dic in params]\n",
        "data = [means, dropout_prob_list, maxnorm_wc_list ]\n",
        "\n",
        "cols = [\"val_acc\", \"dropout_prob\", \"maxnorm_wc\"]\n",
        "df_exp3 =pd.DataFrame(data=data).T\n",
        "df_exp3.columns = cols\n",
        "df_exp3.dropout_prob = df_exp3.dropout_prob.round(2)\n",
        "\n",
        "# pivot dataframe in preparation for heat map\n",
        "df_exp3 = df_exp3.pivot(\"maxnorm_wc\", \"dropout_prob\", \"val_acc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ea72fzvpVGr"
      },
      "source": [
        "# Draw a heatmap with the val_acc values in each cell\n",
        "f, ax = plt.subplots(figsize=(18, 8))\n",
        "sns.heatmap(df_exp3, annot=True,  linewidths=.5, ax=ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_E1Q529pVGr"
      },
      "source": [
        "### Observations \n",
        "\n",
        "We can see the dropout probabilities in the horizontal axis and the maxnorm weight constraint values in the vertical axis. The values in the cells are the validation accuracy that corresponds to a pair of regularization values.\n",
        "\n",
        "Take a look at the heat map and answer the following questions. Note that your answers might differ from others depending on which model you used (the simple or complex one). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf-NEuacpVGr"
      },
      "source": [
        "**What range of dropout probability values tend to produce the highest validation accuracy?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0f0013d4e07104a03b4d51664a308f53",
          "grade": true,
          "grade_id": "cell-4e0cb7a9240b1531",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "oSN1IABcpVGr"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35-eE2uspVGr"
      },
      "source": [
        "**What range of maxnorm weight constraints tend to produce the highest validation accuracy?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "9fd88f0bb870a910b925d60b38d17694",
          "grade": true,
          "grade_id": "cell-99539755d7d328f7",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "E5SxnVunpVGr"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdxUQWVBpVGr"
      },
      "source": [
        "**What pair of dropout probability and maxnorm weight constraints tend to produce the highest validation accuracy when taken together?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "fee1e09ed8f6d354bd7b6e2986c2b811",
          "grade": true,
          "grade_id": "cell-5e19a56b4a2d975d",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "DA5d3AL-pVGr"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nVpSppEpVGs"
      },
      "source": [
        "**Do you think that using dropout helped increase model performance?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "de9c1bcff3c5eb6266cc80632d0956f0",
          "grade": true,
          "grade_id": "cell-d2a2f7b284c801dc",
          "locked": false,
          "points": 0,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "5IUb_6dGpVGs"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKWWbpRJpVGs"
      },
      "source": [
        "-----\n",
        "# Stretch Goals for $L_p$ Space Section\n",
        "\n",
        "Here are some ideas that you can explore using the custom distance metric class that you have built. Though if you think of something else, go for it!\n",
        "\n",
        "- Run a similar experiment but instead of comparing L2 between Keras and our custom class, compare L1 (Lasso) \n",
        "- Run a similar experiment but instead of comparing L2 between Keras and our custom class, compare L1_L2 (Elastic Net) \n",
        "- Run a gridsearch across several different Lp distance metrics and strengths and see which Lp distance leads to the best performing model\n",
        "    - Consider selecting a p range between **[1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, ..., 10]** step size of 0.5\n",
        "    - Consider selecting a p range between **[1, 10, 100, 1000, 10000]** step size in powers of 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHpO9kwkpVGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXsECVaopVGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeMGvgTKpVGs"
      },
      "source": [
        "_____\n",
        "\n",
        "### Experiment 4: Train, Save, and Load a Keras Model\n",
        "\n",
        "Let's get some practice with how to save and load trained Keras models. \n",
        "\n",
        "For this experiment, review the section on saving and loading models from the guided project to help you to: \n",
        "\n",
        "- Build a model of your choosing\n",
        "- Gridsearch, the model with a method of your choosing\n",
        "- Save the trained model to file\n",
        "- Load the trained model from the file\n",
        "- Just as we did in the guided project, evaluate the loaded model using a test set and make sure the results of the loaded model match that of the saved model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ZNRxrnpVGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhdS3gLQpVGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ek-sHt3pVGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}