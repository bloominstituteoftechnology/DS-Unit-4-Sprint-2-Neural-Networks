{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aaron_Huizenga_LS_DS_432_Backprop_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nusc2016/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/Module2/Aaron_Huizenga_LS_DS_432_Backprop_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "\n",
        "# Backpropagation Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 2*\n",
        "\n",
        "Using TensorFlow Keras, Implement a 3 input, 4 node hidden-layer, 1 output node Multilayer Perceptron on the following dataset:\n",
        "\n",
        "| x1 | x2 | x3 | y |\n",
        "|----|----|----|---|\n",
        "| 0  | 0  | 1  | 0 |\n",
        "| 0  | 1  | 1  | 1 |\n",
        "| 1  | 0  | 1  | 1 |\n",
        "| 0  | 1  | 0  | 1 |\n",
        "| 1  | 0  | 0  | 1 |\n",
        "| 1  | 1  | 1  | 0 |\n",
        "| 0  | 0  | 0  | 0 |\n",
        "\n",
        "If you look at the data you'll notice that the first two columns behave like an XOR gate while the last column is mostly just noise. Remember that creating an XOR gate was what the perceptron was criticized for not being able to learn.\n",
        "\n",
        "This is your \"Hello World!\" of TensorFlow.\n",
        "\n",
        "### Example TensorFlow Starter Code\n",
        "\n",
        "```python \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(3, activation='sigmoid', input_dim=2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "results = model.fit(X,y, epochs=100)\n",
        "\n",
        "```\n",
        "\n",
        "### Additional Written Tasks:\n",
        "1. Investigate the various [loss functions](https://www.tensorflow.org/api_docs/python/tf/keras/losses). Which is best suited for the task at hand (predicting 1 / 0) and why? \n",
        "2. What is the difference between a loss function and a metric? Why might we need both in Keras? \n",
        "3. Investigate the various [optimizers](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers). Stochastic Gradient Descent (`sgd`) is not the learning algorithm dejour anyone. Why is that? What do newer optimizers such as `adam` have to offer? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nEREYT-3wI1f",
        "colab": {}
      },
      "source": [
        "# Yes my code starts here, it starts by creating a DF\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'x1': [0, 0, 1, 0, 1, 1, 0],\n",
        "    'x2': [0, 1, 0, 1, 0, 1, 0],\n",
        "    'x3': [1, 1, 1, 0, 0, 1, 0],\n",
        "    'y':  [0, 1, 1, 1, 1, 0, 0]\n",
        "})"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_zwWpfaCXgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "3b8ae759-d8d5-4ca6-d964-dba92e601f51"
      },
      "source": [
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  x3  y\n",
              "0   0   0   1  0\n",
              "1   0   1   1  1\n",
              "2   1   0   1  1\n",
              "3   0   1   0  1\n",
              "4   1   0   0  1\n",
              "5   1   1   1  0\n",
              "6   0   0   0  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76VMlIUZCbZo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "fd0d7283-ac2b-459d-94bb-0e32a8fba2fb"
      },
      "source": [
        "# Now I will provide the documentation on indexing\n",
        "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html\n",
        "\n",
        "x = df.loc[:, 'x1' : 'x3']\n",
        "x"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  x3\n",
              "0   0   0   1\n",
              "1   0   1   1\n",
              "2   1   0   1\n",
              "3   0   1   0\n",
              "4   1   0   0\n",
              "5   1   1   1\n",
              "6   0   0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCjt2htOCui8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "da44e272-5303-4590-91c6-6d3e20e3853a"
      },
      "source": [
        "y = df['y']\n",
        "y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "5    0\n",
              "6    0\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qky1MI35C6Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I'd like to have some random numbers come through at ALL times, so I will seed\n",
        "# numpy random\n",
        "\n",
        "np.random.seed(747)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPfqrZcSDJxn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb4902bf-6515-49c8-fc8d-14a2b8fb51c5"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDOpxchiDN94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now I will build the NN class\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "      \n",
        "        # set up the neural network architecture. \n",
        "        self.inputs = 3\n",
        "        self.hiddenNodes = 4\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "        # initialize weights\n",
        "        # the resulting weight needs to be 3 rows - input, and \n",
        "        # 4 columns - number of nodes. \n",
        "        self.weight1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
        "        self.weight2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "        \n",
        "    # sigmoid function\n",
        "    def sigmoid(self, X):\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "    \n",
        "    # feed forward network\n",
        "    def feed_forward(self, X):\n",
        "        \n",
        "        # weighted sum\n",
        "        self.hidden_sum = np.dot(X, self.weight1)\n",
        "        \n",
        "        # activate the output from the hidden layer. \n",
        "        self.activated_hidden_output = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        # second weighted sum\n",
        "        self.output_sum = np.dot(self.activated_hidden_output, self.weight2)\n",
        "        \n",
        "        # active the final output from output layer\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9CO76MnFSvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will define the Neural Network\n",
        "\n",
        "nn = NeuralNetwork()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS4KiE8OFaHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "1a338ec7-a260-4d04-d1f0-e3b330d65ddc"
      },
      "source": [
        "output = nn.feed_forward(x)\n",
        "\n",
        "print('Output \\n', output)\n",
        "print('Actual output \\n', y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output \n",
            " [[0.52278843]\n",
            " [0.48162508]\n",
            " [0.4897447 ]\n",
            " [0.49311907]\n",
            " [0.50622892]\n",
            " [0.47708301]\n",
            " [0.53597474]]\n",
            "Actual output \n",
            " 0    0\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "5    0\n",
            "6    0\n",
            "Name: y, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J88Z5-ZSGYb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "991c5689-5d08-40ca-abd7-f5531fffc3b6"
      },
      "source": [
        "# The following will take 'y' and turn it into a 1 dimensional array\n",
        "\n",
        "y = [[i] for i in y]\n",
        "\n",
        "# calc error\n",
        "error = y - output\n",
        "error"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.52278843],\n",
              "       [ 0.51837492],\n",
              "       [ 0.5102553 ],\n",
              "       [ 0.50688093],\n",
              "       [ 0.49377108],\n",
              "       [-0.47708301],\n",
              "       [-0.53597474]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcinRZKWGYGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What we're going to do next is add back the propagation into the NN to try and \n",
        "# help improve the weights. Let's start by building a NN class.\n",
        "\n",
        "class NeuralNetwork:\n",
        "    \n",
        "    def __init__(self):\n",
        "        # I need to set up the NN infrastructure.\n",
        "        self.inputs = 3\n",
        "        self.hiddenNodes = 4\n",
        "        self.outputNodes = 1\n",
        "        \n",
        "\n",
        "        # I need to initialize the weights.\n",
        "        self.weight1 = np.random.randn(self.inputs, self.hiddenNodes)\n",
        "        self.weight2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "        \n",
        "        \n",
        "    # sigmoid function\n",
        "    def sigmoid(self, X):\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "    \n",
        "    # feed forward network\n",
        "    def feed_forward(self, X):\n",
        "        \n",
        "        # Weighted sum\n",
        "        self.hidden_sum = np.dot(X, self.weight1)\n",
        "        \n",
        "        # I need to activate the output from the hidden layer. \n",
        "        self.activated_hidden_output = self.sigmoid(self.hidden_sum)\n",
        "        \n",
        "        # 2nd weighted sum\n",
        "        self.output_sum = np.dot(self.activated_hidden_output, self.weight2)\n",
        "        \n",
        "        # Finally I need to activate the final output.\n",
        "        self.activated_output = self.sigmoid(self.output_sum)\n",
        "        \n",
        "        return self.activated_output\n",
        "    # Here I need to define the sigmoid derivative\n",
        "    def sigmoidPrime(self, x):\n",
        "        # sigmoid of x\n",
        "        sigmoid_x = self.sigmoid(x)\n",
        "        # derivative of sigmoid\n",
        "        der_sigmoid = sigmoid_x * (1-sigmoid_x)\n",
        "        return der_sigmoid\n",
        "    \n",
        "    def propagation(self, X, y, o):\n",
        "        \"\"\"Back propagation using gradient descent\"\"\"\n",
        "        \n",
        "        # y  =  actual values\n",
        "        # o = predicted values\n",
        "        \n",
        "        # This is my output error\n",
        "        self.output_error = y - o\n",
        "        \n",
        "\n",
        "        # Now I will apply the derivative of sigmoid to my error.\n",
        "        # Then I will multipy the error by the derivative of the second weighted sum\n",
        "        self.output_delta = self.output_error * self.sigmoidPrime(self.output_sum)\n",
        "        \n",
        "        # What is the error in the 2nd weight? \n",
        "        # 2nd weight is the weight that fed into the final output.\n",
        "        self.weight2_error = self.output_delta.dot(self.weight2.T)\n",
        "        \n",
        "\n",
        "        # Now I will work on the layer directly about the final output.\n",
        "        # Now I need to multiply the error in the weights that fed into the hidden layer \n",
        "        self.hidden_delta = self.weight2_error * self.sigmoidPrime(self.hidden_sum)\n",
        "        \n",
        "        # I need to multiply the input by the new gradient\n",
        "        self.weight1 += X.T.dot(self.hidden_delta)\n",
        "        \n",
        "        # Next I will multiply the activated output of the first hidden layer by the \n",
        "        # gradient calculated above. \n",
        "        self.weight2 += self.activated_hidden_output.T.dot(self.output_delta)\n",
        "        \n",
        "    # Finally I will implement back propagation using a training function\n",
        "    def train(self, X, y):\n",
        "        # o = the output of the feed forward function\n",
        "        o = self.feed_forward(X)\n",
        "        # implement the backward propagation function during trainig. \n",
        "        self.propagation(X, y, o)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3xfliHHM3X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "\n",
        "nn.train(x, y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUds-YjVN6rq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b56e7ae-e09c-4f4f-c977-807172951145"
      },
      "source": [
        "# What I want to do next is train the NN with multiple epochs\n",
        "\n",
        "nn = NeuralNetwork()\n",
        "\n",
        "# Number of Epochs / Iterations\n",
        "for i in range(10000):\n",
        "    if (i+1 in [1,2,3,4,5]) or ((i+1) % 1000 ==0):\n",
        "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---'*3 + '+')\n",
        "        print('Input: \\n', x)\n",
        "        print('Actual Output: \\n', y)\n",
        "        print('Predicted Output: \\n', str(nn.feed_forward(x)))\n",
        "        print(\"Loss: \\n\", str(np.mean(np.square(y - nn.feed_forward(x)))))\n",
        "    nn.train(x,y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------EPOCH 1---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.22847567]\n",
            " [0.23464008]\n",
            " [0.18354763]\n",
            " [0.2197748 ]\n",
            " [0.16894322]\n",
            " [0.17408605]\n",
            " [0.18165469]]\n",
            "Loss: \n",
            " 0.3810403608829311\n",
            "+---------EPOCH 2---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.29984445]\n",
            " [0.33199111]\n",
            " [0.25843795]\n",
            " [0.31440547]\n",
            " [0.24066295]\n",
            " [0.25795666]\n",
            " [0.24276059]]\n",
            "Loss: \n",
            " 0.32259482753243035\n",
            "+---------EPOCH 3---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.37877077]\n",
            " [0.44046153]\n",
            " [0.34812055]\n",
            " [0.42377169]\n",
            " [0.32939275]\n",
            " [0.36237407]\n",
            " [0.31534703]]\n",
            "Loss: \n",
            " 0.27057275409195225\n",
            "+---------EPOCH 4---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.44408144]\n",
            " [0.52920324]\n",
            " [0.42834604]\n",
            " [0.51579501]\n",
            " [0.41094165]\n",
            " [0.45735118]\n",
            " [0.37903534]]\n",
            "Loss: \n",
            " 0.23998975337990713\n",
            "+---------EPOCH 5---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.48428818]\n",
            " [0.5846945 ]\n",
            " [0.48303435]\n",
            " [0.57437301]\n",
            " [0.46764306]\n",
            " [0.52217942]\n",
            " [0.41972345]]\n",
            "Loss: \n",
            " 0.22680979495193795\n",
            "+---------EPOCH 1000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.0078661 ]\n",
            " [0.95895364]\n",
            " [0.94899302]\n",
            " [0.95487177]\n",
            " [0.95228586]\n",
            " [0.06783967]\n",
            " [0.07583707]]\n",
            "Loss: \n",
            " 0.002716438481569664\n",
            "+---------EPOCH 2000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00433421]\n",
            " [0.97347638]\n",
            " [0.96661   ]\n",
            " [0.97205242]\n",
            " [0.96976812]\n",
            " [0.04119184]\n",
            " [0.04935233]]\n",
            "Loss: \n",
            " 0.001094947700772413\n",
            "+---------EPOCH 3000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00323842]\n",
            " [0.97887176]\n",
            " [0.97366982]\n",
            " [0.97853939]\n",
            " [0.97651421]\n",
            " [0.03138142]\n",
            " [0.03885183]]\n",
            "Loss: \n",
            " 0.0006652238967024542\n",
            "+---------EPOCH 4000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00267453]\n",
            " [0.98189245]\n",
            " [0.97769255]\n",
            " [0.9820589 ]\n",
            " [0.98023379]\n",
            " [0.02605978]\n",
            " [0.03293402]]\n",
            "Loss: \n",
            " 0.0004727153217146158\n",
            "+---------EPOCH 5000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00232045]\n",
            " [0.98388859]\n",
            " [0.98035198]\n",
            " [0.98431257]\n",
            " [0.9826442 ]\n",
            " [0.02264678]\n",
            " [0.02904361]]\n",
            "Loss: \n",
            " 0.00036496199301167686\n",
            "+---------EPOCH 6000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.0020729 ]\n",
            " [0.98533379]\n",
            " [0.9822675 ]\n",
            " [0.98590146]\n",
            " [0.98435892]\n",
            " [0.02023837]\n",
            " [0.02624924]]\n",
            "Loss: \n",
            " 0.0002965518498238341\n",
            "+---------EPOCH 7000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00188779]\n",
            " [0.98644273]\n",
            " [0.98372724]\n",
            " [0.98709432]\n",
            " [0.9856551 ]\n",
            " [0.01843017]\n",
            " [0.02412259]]\n",
            "Loss: \n",
            " 0.0002494385316781326\n",
            "+---------EPOCH 8000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00174283]\n",
            " [0.98732867]\n",
            " [0.98488506]\n",
            " [0.98803028]\n",
            " [0.98667758]\n",
            " [0.0170123 ]\n",
            " [0.02243669]]\n",
            "Loss: \n",
            " 0.000215092290910967\n",
            "+---------EPOCH 9000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00162544]\n",
            " [0.98805777]\n",
            " [0.98583124]\n",
            " [0.98878904]\n",
            " [0.98750998]\n",
            " [0.01586417]\n",
            " [0.02105903]]\n",
            "Loss: \n",
            " 0.00018897905155046386\n",
            "+---------EPOCH 10000---------+\n",
            "Input: \n",
            "    x1  x2  x3\n",
            "0   0   0   1\n",
            "1   0   1   1\n",
            "2   1   0   1\n",
            "3   0   1   0\n",
            "4   1   0   0\n",
            "5   1   1   1\n",
            "6   0   0   0\n",
            "Actual Output: \n",
            " [[0], [1], [1], [1], [1], [0], [0]]\n",
            "Predicted Output: \n",
            " [[0.00152792]\n",
            " [0.9886716 ]\n",
            " [0.98662257]\n",
            " [0.98941977]\n",
            " [0.98820426]\n",
            " [0.01491119]\n",
            " [0.01990659]]\n",
            "Loss: \n",
            " 0.00016847414811092936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlZ8LXTFAl4w",
        "colab_type": "text"
      },
      "source": [
        "## Build a Tensor Keras Perceptron\n",
        "\n",
        "Try to match the architecture we used on Monday - inputs nodes and one output node. Apply this architecture to the XOR-ish dataset above. \n",
        "\n",
        "After fitting your model answer these questions: \n",
        "\n",
        "Are you able to achieve the same results as a bigger architecture from the first part of the assignment? Why is this disparity the case? What properties of the XOR dataset would cause this disparity? \n",
        "\n",
        "Now extrapolate this behavior on a much larger dataset in terms of features. What kind of architecture decisions could we make to avoid the problems the XOR dataset presents at scale? \n",
        "\n",
        "*Note:* The bias term is baked in by default in the Dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MIdi0j0Al4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "596517ff-422f-49f9-d61d-e0dafabe5555"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Creating Data\n",
        "data = {\n",
        "    \"x1\":[0,0,1,0,1,1,0],\n",
        "    \"x2\":[0,1,0,1,0,1,0],\n",
        "    \"x3\":[1,1,1,0,0,1,0],\n",
        "    \"y\": [0,1,1,1,1,0,0]\n",
        "}\n",
        "\n",
        "# Instantiating DataFrame\n",
        "df = pd.DataFrame.from_dict(data).astype(\"int\")\n",
        "\n",
        "# X\n",
        "X = df[[\"x1\", \"x2\", \"x3\"]].values\n",
        "\n",
        "# y\n",
        "y = df[\"y\"].values\n",
        "\n",
        "# Instantiating Model\n",
        "model = Sequential([\n",
        "    Dense(3, activation=\"sigmoid\", input_dim=3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fitting and Results\n",
        "results = model.fit(X, y, epochs=100)\n",
        "\n",
        "# Scores\n",
        "scores = model.evaluate(X, y)\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6939 - accuracy: 0.4286\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.4286\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4286\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 823us/step - loss: 0.6937 - accuracy: 0.4286\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.4286\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4286\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.4286\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.4286\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.4286\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.4286\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6932 - accuracy: 0.4286\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4286\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6931 - accuracy: 0.4286\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.4286\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.4286\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.4286\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.4286\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.4286\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.4286\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.4286\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.4286\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.4286\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.4286\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.4286\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6923 - accuracy: 0.4286\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.4286\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.4286\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.4286\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6921 - accuracy: 0.4286\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5714\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.5714\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5714\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.5714\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5714\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5714\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.5714\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5714\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.5714\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6915 - accuracy: 0.5714\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6915 - accuracy: 0.5714\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.5714\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6914 - accuracy: 0.5714\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5714\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5714\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5714\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5714\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5714\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6911 - accuracy: 0.5714\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5714\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5714\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5714\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6909 - accuracy: 0.5714\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.5714\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6908 - accuracy: 0.5714\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6907 - accuracy: 0.5714\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6907 - accuracy: 0.5714\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5714\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.5714\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5714\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5714\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5714\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5714\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5714\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5714\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.5714\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5714\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5714\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6901 - accuracy: 0.5714\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6901 - accuracy: 0.5714\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5714\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.5714\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5714\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.5714\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5714\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5714\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.5714\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5714\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6897 - accuracy: 0.5714\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5714\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6896 - accuracy: 0.5714\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5714\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6895 - accuracy: 0.5714\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.5714\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5714\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5714\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5714\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5714\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.5714\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5714\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.5714\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5714\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5714\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5714\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5714\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5714\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6890 - accuracy: 0.5714\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.6889 - accuracy: 0.5714\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5714\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6889 - accuracy: 0.5714\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 955us/step - loss: 0.6888 - accuracy: 0.5714\n",
            "accuracy: 57.14285969734192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8b-r70o8p2Dm"
      },
      "source": [
        "## Try building/training a more complex MLP on a bigger dataset.\n",
        "\n",
        "Use TensorFlow Keras & the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) to build the canonical handwriting digit recognizer and see what kind of accuracy you can achieve. \n",
        "\n",
        "If you need inspiration, the Internet is chalk-full of tutorials, but I want you to see how far you can get on your own first. I've linked to the original MNIST dataset above but it will probably be easier to download data through a neural network library. If you reference outside resources make sure you understand every line of code that you're using from other sources, and share with your fellow students helpful resources that you find.\n",
        "\n",
        "\n",
        "### Parts\n",
        "1. Gathering & Transforming the Data\n",
        "2. Making MNIST a Binary Problem\n",
        "3. Estimating your Neural Network (the part you focus on)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bxTbhrfAl4z",
        "colab_type": "text"
      },
      "source": [
        "### Gathering the Data \n",
        "\n",
        "`keras` has a handy method to pull the mnist dataset for you. You'll notice that each observation is a 28x28 arrary which represents an image. Although most Neural Network frameworks can handle higher dimensional data, that is more overhead than necessary for us. We need to flatten the image to one long row which will be 784 values (28X28). Basically, you will be appending each row to one another to make on really long row. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXb8fNr_Al4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY6vLFRNAl41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQulKiXJAl44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwrbCsAXAl46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
        "\n",
        "# Normalize Our Data\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh2KcvERAl48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98e19470-cb8c-42d4-eb46-6b5b18f7a38d"
      },
      "source": [
        "# Now the data should be in a format you're more familiar with\n",
        "x_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l3JE-f7Al4_",
        "colab_type": "text"
      },
      "source": [
        "### Making MNIST a Binary Problem \n",
        "MNIST is multiclass classification problem; however we haven't covered all the necessary techniques to handle this yet. You would need to one-hot encode the target, use a different loss metric, and use softmax activations for the last layer. This is all stuff we'll cover later this week, but let us simplify the problem for now: Zero or all else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sla6KaClAl4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "y_temp = np.zeros(y_train.shape)\n",
        "y_temp[np.where(y_train == 0.0)[0]] = 1\n",
        "y_train = y_temp\n",
        "\n",
        "y_temp = np.zeros(y_test.shape)\n",
        "y_temp[np.where(y_test == 0.0)[0]] = 1\n",
        "y_test = y_temp"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnp61mZAl5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecf87398-9c9b-42e6-819c-b4068daf0b87"
      },
      "source": [
        "# A Binary target to work with\n",
        "y_train"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us4B2ldUAl5D",
        "colab_type": "text"
      },
      "source": [
        "### Estimating Your `net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5MOPtYdk1HgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "69ce8f88-35e1-45ee-d1ae-e48df982e621"
      },
      "source": [
        "##### Your Code Here #####\n",
        "\n",
        "# Instantiating Model\n",
        "model = Sequential([\n",
        "    Dense(10, activation=\"sigmoid\", input_dim=3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Results\n",
        "results = model.fit(X,y, epochs=10)\n",
        "\n",
        "# Score\n",
        "scores = model.evaluate(X, y)\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8120e-08 - accuracy: 0.4286\n",
            "accuracy: 42.85714328289032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FwlRJSfBlCvy"
      },
      "source": [
        "## Stretch Goals: \n",
        "\n",
        "- Make MNIST a multiclass problem using cross entropy & soft-max\n",
        "- Implement Cross Validation model evaluation on your MNIST implementation \n",
        "- Research different [Gradient Descent Based Optimizers](https://keras.io/optimizers/)\n",
        " - [Siraj Raval the evolution of gradient descent](https://www.youtube.com/watch?v=nhqo0u1a6fw)\n",
        "- Build a housing price estimation model using a neural network. How does its accuracy compare with the regression models that we fit earlier on in class?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYpLAkDZQpsY",
        "colab_type": "text"
      },
      "source": [
        "## I don't even know if this is a stretch goal or if it was part of the assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fhnj6U7QvGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ProQSiuGQxpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffa42299-8b00-42a1-81a4-a4ede0d221c2"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwoTnEWhRW02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting the dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# setting variables to extract datasets from the dataset. \n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QiXVmPSRlbs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7b4f0ffb-3352-4260-80e1-7885d4a4adc8"
      },
      "source": [
        "# getting an idea of what images are in our dataset. \n",
        "plt.imshow(train_images[4])\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwvElm6QRsT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "6497b4ae-bdf1-4555-92e1-3ca3e88e2d4e"
      },
      "source": [
        "# finding out the values making up an image\n",
        "print(train_images[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRst_dEzRvIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardizing the values to 0's and 1's\n",
        "train_images = train_images/255\n",
        "test_images = test_images/255"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6u9gfbR0i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# designing the model with neural networks\n",
        "model = tf.keras.models.Sequential([keras.layers.Flatten(),\n",
        "                                     keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                     keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ni4rV_gR3Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a class that will cause our model to stop training when we reach 99% accuracy\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print('\\nReached 99% accuracy so cancelling training')\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5suaEyaeR7Sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instatiating callback class. \n",
        "callback = myCallback()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZMEn35qR9sO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "cbaa3a5c-41d4-49db-bc31-fac67d33166d"
      },
      "source": [
        "# compiling the model and fitting the model to training dataset\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs = 10,\n",
        "          callbacks = [callback])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2619 - accuracy: 0.9255\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1152 - accuracy: 0.9661\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0789 - accuracy: 0.9768\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0587 - accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0458 - accuracy: 0.9863\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0369 - accuracy: 0.9890\n",
            "Epoch 7/10\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9908\n",
            "Reached 99% accuracy so cancelling training\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0302 - accuracy: 0.9908\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc65ebb8f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYH2hTzUSBeR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d0caa88b-9401-4cb1-aa0f-1f5604d251b5"
      },
      "source": [
        "# testing to see if our model works and if it can detect an image from a new\n",
        "# untested dataset\n",
        "classification = model.predict(test_images)\n",
        "\n",
        "# testing to see if prediction works. \n",
        "print(classification[5])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.4623670e-07 9.9613613e-01 2.4499980e-06 9.0430859e-07 4.9379014e-06\n",
            " 3.5819275e-10 2.3597444e-08 3.8245185e-03 3.0692587e-05 1.6714218e-07]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKE5yc61SPsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "173b2044-62bb-497f-8c10-80d2027a7bb9"
      },
      "source": [
        "# I want to verify the classification that returned above\n",
        "\n",
        "print(test_labels[4])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQx8ULiISrPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "eaeb2938-451a-4e09-da0c-e0f611f1eb3b"
      },
      "source": [
        "# verifying that test image 4 mathes the label above. \n",
        "plt.imshow(test_images[4])\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}