{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "Aaron_Huizenga_LS_DS_Unit_4_Sprint_Challenge_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nusc2016/DS-Unit-4-Sprint-2-Neural-Networks/blob/main/Aaron_Huizenga_LS_DS_Unit_4_Sprint_Challenge_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SESszLRLS0ns",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2*\n",
        "\n",
        "# Sprint Challenge - Neural Network Foundations\n",
        "\n",
        "Table of Problems\n",
        "\n",
        "1. [Defining Neural Networks](#Q1)\n",
        "2. [Simple Perceptron](#Q2)\n",
        "    - Perceptron\n",
        "    - Multilayer Perceptron\n",
        "    - Analyze and Compare\n",
        "4. [Keras MMP](#Q3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgnAEcEGS0nt",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q1\"></a>\n",
        "## 1. Defining Neural Networks \n",
        "\n",
        "Write *your own* definitions for the following terms:\n",
        "\n",
        "- **Neuron:**\n",
        "  * They make up the neural network.  These nodes are the simple, but highly interconnected elements which are organized in layers which process information using dynamic state responses to external inputs. (artificial neural networks are modeled after how our own biological brains & networks\n",
        "- **Input Layer:**\n",
        "  * These present the patterns to the network.  Which would communicate to one or more hidden layers.  These nodes are passive (they don't change the data); receiving a single value on their input and duplicate the value to their many outputs.\n",
        "  Starting from the input layer, it duplicates each value and sends it to all the hidden nodes.\n",
        "- **Hidden Layer:**\n",
        "  * layers of mathematical functions each designed to produce an output specific to an intended result.  They allow for the function of a neural network to be broken down into specific transformations of the data.\n",
        "  They are found between the input and output of the algorithm.  The function applies weights to the inputs and directs them through an activation function as the input.\n",
        "- **Output Layer:**\n",
        "  * This is where hidden layers link to. Output layers receive connections from hidden layers. It returns an output value that corresponds to the prediction of the response variable.  \n",
        "  In classification problems, only one output mode. In multiclass classification, could be more.  The activate nodes of the output layer combine and change the data to produce output values.\n",
        "- **Activation Function:**\n",
        "  * Each node has one, and the activation function defines the output of that node given an input (or set of inputs).\n",
        "  There are a number of activation functions available. The ones we used for this week's sprint were sigmoid and RelU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBYsxK4eS0nt",
        "colab_type": "text"
      },
      "source": [
        "Explain how back propagation works as if you were explaining it to a five year-old. Use your own words, but feel free to reference external materials for this question. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfdv0DB8V0NY",
        "colab_type": "text"
      },
      "source": [
        "## Explanation of back propagation to a 5yr old"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezn6d89MS0nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Think of it as a set of computers that learn from their mistakes, and as they\n",
        "# learn they get better as time goes by. So as you learn how to use this computer\n",
        "# you will get better as time goes by. So as you look at a car, the computers they\n",
        "# use are able to make the system do bigger and better things - such as driving \n",
        "# itself."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tml0QoA_S0nx",
        "colab_type": "text"
      },
      "source": [
        "Remember our Simple Perceptron Class from Monday. In a simple prediction describe the process of making a prediction. How do you go from inputs to predicted output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "254wWHrGS0nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "A prediction is simply guessing what might happen based on observations you make.\n",
        "How do you go from inputs to the predicted outputs? - It's a typical issue that \n",
        "most Data Scientists run into. It starts by knowing how to fit the model correctly.\n",
        "Then figuring out how to use the model to make predictions one at a time and also \n",
        "in batches. Then you have to figure out how to connect the predicted values with \n",
        "the inputs to the model. This may not explain it in scientific terms, but its\n",
        "much easier to know what to do if you just look at it from a very basic standpoint.\n",
        "\"\"\"D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RYoCV_ES0n1",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"Q2\"></a>\n",
        "## 2. Simple Perceptron\n",
        "\n",
        "In this question, you will build two neural networks using Tensorflow Keras. After you build these two models, compare the results of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "418REVpdS0n2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Our Dataset\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "xx, yy = np.meshgrid(np.linspace(-3, 3, 50),\n",
        "                     np.linspace(-3, 3, 50))\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "\"Use this X & y in the following 2 models\"\n",
        "X = rng.randn(300, 2)\n",
        "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
        "             dtype=int)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxeuvb2YS0n3",
        "colab_type": "text"
      },
      "source": [
        "### Simple Perceptron\n",
        "Construct a simple perceptron using Keras. You model should have 1 dense layer with a single neuron and a sigmoid activation function. Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmh-8pNE0Yhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not going to lie, the above cell has completely freaked me out.... So I'm just\n",
        "# going to take what I have and input it here in the next cell..."
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTiXtzJ6S0n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "96785ad0-ca89-49c6-99a2-991ce197fb6f"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Creating Data\n",
        "data = {\n",
        "    \"x1\":[0,0,1,0,1,1,0],\n",
        "    \"x2\":[0,1,0,1,0,1,0],\n",
        "    \"x3\":[1,1,1,0,0,1,0],\n",
        "    \"y\": [0,1,1,1,1,0,0]\n",
        "}\n",
        "\n",
        "# Instantiating DataFrame\n",
        "df = pd.DataFrame.from_dict(data).astype(\"int\")\n",
        "\n",
        "# X\n",
        "X = df[[\"x1\", \"x2\", \"x3\"]].values\n",
        "\n",
        "# y\n",
        "y = df[\"y\"].values\n",
        "\n",
        "# Instantiating Model\n",
        "model = Sequential([\n",
        "    Dense(3, activation=\"sigmoid\", input_dim=3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=\"sgd\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Fitting and Results\n",
        "results = model.fit(X, y, epochs=100)\n",
        "\n",
        "# Scores\n",
        "scores = model.evaluate(X, y)\n",
        "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7415 - accuracy: 0.4286\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7410 - accuracy: 0.4286\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7405 - accuracy: 0.4286\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7400 - accuracy: 0.4286\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7395 - accuracy: 0.4286\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.4286\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7385 - accuracy: 0.4286\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7381 - accuracy: 0.4286\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7376 - accuracy: 0.4286\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7371 - accuracy: 0.4286\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7367 - accuracy: 0.4286\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7362 - accuracy: 0.4286\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7357 - accuracy: 0.4286\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7353 - accuracy: 0.4286\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7349 - accuracy: 0.4286\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.4286\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7340 - accuracy: 0.4286\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7336 - accuracy: 0.4286\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7331 - accuracy: 0.4286\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7327 - accuracy: 0.4286\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7323 - accuracy: 0.4286\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7319 - accuracy: 0.4286\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7315 - accuracy: 0.4286\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7311 - accuracy: 0.4286\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7307 - accuracy: 0.4286\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.4286\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7299 - accuracy: 0.4286\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7295 - accuracy: 0.4286\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7291 - accuracy: 0.4286\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.4286\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7283 - accuracy: 0.4286\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7280 - accuracy: 0.4286\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7276 - accuracy: 0.4286\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7272 - accuracy: 0.4286\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7269 - accuracy: 0.4286\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.4286\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7262 - accuracy: 0.4286\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7258 - accuracy: 0.4286\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7255 - accuracy: 0.4286\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7251 - accuracy: 0.4286\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7248 - accuracy: 0.4286\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.4286\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7241 - accuracy: 0.4286\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7238 - accuracy: 0.4286\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.4286\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7231 - accuracy: 0.4286\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7228 - accuracy: 0.4286\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7225 - accuracy: 0.4286\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7222 - accuracy: 0.4286\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.4286\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.4286\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7213 - accuracy: 0.4286\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7210 - accuracy: 0.4286\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7207 - accuracy: 0.4286\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7204 - accuracy: 0.4286\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7201 - accuracy: 0.4286\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7198 - accuracy: 0.4286\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7195 - accuracy: 0.4286\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.4286\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7190 - accuracy: 0.4286\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7187 - accuracy: 0.4286\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7184 - accuracy: 0.4286\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7181 - accuracy: 0.4286\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.4286\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7176 - accuracy: 0.4286\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.4286\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.4286\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7168 - accuracy: 0.4286\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.4286\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.4286\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7161 - accuracy: 0.4286\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7158 - accuracy: 0.4286\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7156 - accuracy: 0.4286\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.4286\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.4286\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.4286\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7146 - accuracy: 0.4286\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7144 - accuracy: 0.4286\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7142 - accuracy: 0.4286\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7139 - accuracy: 0.4286\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7137 - accuracy: 0.4286\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7135 - accuracy: 0.4286\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.4286\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.4286\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.4286\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7126 - accuracy: 0.4286\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7124 - accuracy: 0.4286\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7122 - accuracy: 0.4286\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.4286\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7118 - accuracy: 0.5714\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7116 - accuracy: 0.5714\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7114 - accuracy: 0.5714\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.5714\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.5714\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.5714\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.5714\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.5714\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7102 - accuracy: 0.4286\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.5714\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.7098 - accuracy: 0.5714\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.5714\n",
            "accuracy: 57.14285969734192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgPqk3ihS0n5",
        "colab_type": "text"
      },
      "source": [
        "### Multi-Layer Perceptron\n",
        "Now construct a multi-layer perceptron using. Here are some architecture suggestions: \n",
        "- 2 Hidden Layers\n",
        "- 5-32 Neurons in the Hidden Layers\n",
        "- Your pick of activation function and optimizer\n",
        "- Incorporate the Callback function below into your model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXvecT5KS0n6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "  def __init__(self):\n",
        "    # Set up architecture\n",
        "    self.input = 3\n",
        "    self.hiddenNodes = 4\n",
        "    self.outputNodes = 1\n",
        "    \n",
        "    # Initial weights\n",
        "    # 3x4 matrix array for first layer\n",
        "    self.weights1 = np.random.randn(self.input, self.hiddenNodes)\n",
        "    # 4x1 matrix for hidden to output\n",
        "    self.weights2 = np.random.randn(self.hiddenNodes, self.outputNodes)\n",
        "    \n",
        "  def sigmoid(self, s):\n",
        "    return 1 / (1+np.exp(-s))\n",
        "  \n",
        "  def sigmoidPrime(self, s):\n",
        "    return s * (1-s)\n",
        "  \n",
        "  def feed_forward(self,X):\n",
        "    \"\"\"\n",
        "    Calculate the NN inference using feed forward\n",
        "    \"\"\"\n",
        "    \n",
        "    # Weighted sum of inputs & hidden\n",
        "    self.hidden_sum = np.dot(X, self.weights1)\n",
        "    \n",
        "    # Activations of weighted sum\n",
        "    self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
        "    \n",
        "    # Weighted sum between hidden and output\n",
        "    self.output_sum = np.dot(self.activated_hidden, self.weights2)\n",
        "    \n",
        "    # Final activation of output\n",
        "    self.activated_output = self.sigmoid(self.output_sum)\n",
        "    \n",
        "    return self.activated_output\n",
        "  \n",
        "  def backward(self, X, y, o):\n",
        "    \"\"\"\n",
        "    Backward propogate through the network\n",
        "    \"\"\"\n",
        "    self.o_error = y - o #error in output\n",
        "    self.o_delta = self.o_error * self.sigmoidPrime(o) #apply derivative of sigmoid\n",
        "    \n",
        "    self.z2_error = self.o_delta.dot(self.weights2.T)\n",
        "    self.z2_delta = self.z2_error*self.sigmoidPrime(self.activated_hidden)\n",
        "    \n",
        "    self.weights1 += X.T.dot(self.z2_delta)\n",
        "    self.weights2 += self.activated_hidden.T.dot(self.o_delta)\n",
        "    \n",
        "  def train(self, X, y):\n",
        "    o = self.feed_forward(X)\n",
        "    self.backward(X, y, o)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNJP_-7qklI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EljZ-vQqkoGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshaping y_train and y_test\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "y_test = y_test.reshape(-1, 1)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjIiHTO7lNPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLnhQdjXksjy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6c80d80e-69eb-40f0-c1b7-02bee56d88aa"
      },
      "source": [
        "nn = NeuralNetwork()\n",
        "print(X[0])\n",
        "output = nn.feed_forward(X[0])\n",
        "print(\"Output\", output)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1]\n",
            "Output [0.22040521]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hddUWyyaS0n-",
        "colab_type": "text"
      },
      "source": [
        "### Analyze and Compare\n",
        "\n",
        "**Before you Start**: You will need to install an additional library for this next segment. Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
        "\n",
        "\n",
        "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stkcej7uwfg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9087de91-23ac-4c96-f63e-8e6c474f8325"
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.6/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from mlxtend) (49.1.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from mlxtend) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->mlxtend) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.1->mlxtend) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.5.1->mlxtend) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSDrCZWpS0n-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "dd58b36e-d568-4f80-fab9-a917eb05f49b"
      },
      "source": [
        "# Do Not change anything in this cell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "# create a mesh to plot in\n",
        "x_min, x_max = X[:, 0].min() - .2, X[:, 0].max() + .2\n",
        "y_min, y_max = X[:, 1].min() - .2, X[:, 1].max() + .2\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                     np.arange(y_min, y_max, h))\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "\n",
        "for clf, hist, name, grd in zip([model],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
        "\n",
        "    ax = plt.subplot(1,2, grd)\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
        "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
        "    plt.title(title)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-0c0fc04bb22e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Perceptron'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Multi-Layer Perceptron'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7RoyL3ZS0oA",
        "colab_type": "text"
      },
      "source": [
        "Why does the Perceptron (`model1`) only achieve ~70% accuracy? What is the architectural property of the Multi-Layer Perceptron that allows it more accurately learn the relationship between X and y? \n",
        "\n",
        "Why might this property be useful in more complex data such as images?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPrvQ5LXS0oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I am sorry, but I got way too confused to do this section.... I know that I can \n",
        "# do it, but I am running out of time.... I will revisit this Next week and do a\n",
        "# better job"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYD1ix4TS0oC",
        "colab_type": "text"
      },
      "source": [
        "## 3. Keras MMP <a id=\"Q3\"></a>\n",
        "\n",
        "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
        "Use the Heart Disease Dataset (binary classification)\n",
        "Use an appropriate loss function for a binary classification task\n",
        "Use an appropriate activation function on the final layer of your network.\n",
        "Train your model using verbose output for ease of grading.\n",
        "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
        "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
        "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
        "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "outputHidden": false,
        "id": "ZPZ3hB9mS0oD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d3340b42-d95d-4a95-bff6-3a3b8dae1558"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
        "df = df.sample(frac=1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>55</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>262</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>155</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>110</td>\n",
              "      <td>265</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>315</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>177</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>223</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>181</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "114   55    1   1       130   262    0  ...      0      0.0      2   0     2       1\n",
              "60    71    0   2       110   265    1  ...      0      0.0      2   1     2       1\n",
              "98    43    1   2       130   315    0  ...      0      1.9      2   1     2       1\n",
              "31    65    1   0       120   177    0  ...      0      0.4      2   0     3       1\n",
              "283   40    1   0       152   223    0  ...      0      0.0      2   0     3       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgP5RUXQguD1",
        "colab_type": "text"
      },
      "source": [
        "## Step 1 - Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba7gn4vUS0oF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK3mVnezg8U8",
        "colab_type": "text"
      },
      "source": [
        "## Step 2 - Train, test, split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKGI1X6rg7Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_transform = scaler.fit_transform(df)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-gmzpSZhCu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "445ed82f-0593-4a42-e64f-ba1b0acafca5"
      },
      "source": [
        "# Split the values into X and y components:\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_transform[:, :-1], df_transform[:, -1], \n",
        "test_size=0.20, random_state=42)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(242, 13) (61, 13) (242,) (61,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNGagmdMhluJ",
        "colab_type": "text"
      },
      "source": [
        "## Step 3 - Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAw2D4pLhQY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fixing random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(13, input_dim=13, activation='relu'))\n",
        "  #model.add(Dropout(0.2))  # <-- added these later to see effect on score\n",
        "  model.add(Dense(12, activation='sigmoid'))\n",
        "  #model.add(Dropout(0.2))  # <-- added these later to see effect on score, omitted from baseline.\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # compile model\n",
        "  adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Z4DDF-hq3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d8b37497-9529-4dc7-87de-117b735d40ea"
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          validation_data=(X_test,y_test),\n",
        "          epochs=100,\n",
        "          batch_size=15,\n",
        "          verbose=1)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_195 (Dense)            (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "dense_196 (Dense)            (None, 12)                168       \n",
            "_________________________________________________________________\n",
            "dense_197 (Dense)            (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 363\n",
            "Trainable params: 363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 0.6652 - accuracy: 0.6281 - val_loss: 0.6447 - val_accuracy: 0.6393\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.5757 - accuracy: 0.7314 - val_loss: 0.5541 - val_accuracy: 0.6721\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.8182 - val_loss: 0.5098 - val_accuracy: 0.7377\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8347 - val_loss: 0.4978 - val_accuracy: 0.7213\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3863 - accuracy: 0.8388 - val_loss: 0.4859 - val_accuracy: 0.7541\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3827 - accuracy: 0.8264 - val_loss: 0.4753 - val_accuracy: 0.7869\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3758 - accuracy: 0.8388 - val_loss: 0.5905 - val_accuracy: 0.7377\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3974 - accuracy: 0.8264 - val_loss: 0.4999 - val_accuracy: 0.7541\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3673 - accuracy: 0.8430 - val_loss: 0.5458 - val_accuracy: 0.7541\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8471 - val_loss: 0.4945 - val_accuracy: 0.7869\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8430 - val_loss: 0.4989 - val_accuracy: 0.8033\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8512 - val_loss: 0.5020 - val_accuracy: 0.8197\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8471 - val_loss: 0.5124 - val_accuracy: 0.8197\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8554 - val_loss: 0.4967 - val_accuracy: 0.8033\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8512 - val_loss: 0.5147 - val_accuracy: 0.7869\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8512 - val_loss: 0.5050 - val_accuracy: 0.8033\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8554 - val_loss: 0.5296 - val_accuracy: 0.8033\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8719 - val_loss: 0.5220 - val_accuracy: 0.7869\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8512 - val_loss: 0.5105 - val_accuracy: 0.8033\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8471 - val_loss: 0.5137 - val_accuracy: 0.7869\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8595 - val_loss: 0.5204 - val_accuracy: 0.8033\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8678 - val_loss: 0.5193 - val_accuracy: 0.7869\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8636 - val_loss: 0.5173 - val_accuracy: 0.8033\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8678 - val_loss: 0.5029 - val_accuracy: 0.7869\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3254 - accuracy: 0.8595 - val_loss: 0.5310 - val_accuracy: 0.8033\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8636 - val_loss: 0.5381 - val_accuracy: 0.8033\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8554 - val_loss: 0.5405 - val_accuracy: 0.7541\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8471 - val_loss: 0.5631 - val_accuracy: 0.8033\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3117 - accuracy: 0.8595 - val_loss: 0.4996 - val_accuracy: 0.7869\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2984 - accuracy: 0.8843 - val_loss: 0.5241 - val_accuracy: 0.8033\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8843 - val_loss: 0.5143 - val_accuracy: 0.8033\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.8719 - val_loss: 0.5835 - val_accuracy: 0.8033\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.8595 - val_loss: 0.5692 - val_accuracy: 0.8033\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2996 - accuracy: 0.8388 - val_loss: 0.5118 - val_accuracy: 0.7705\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8678 - val_loss: 0.6156 - val_accuracy: 0.7869\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2963 - accuracy: 0.8760 - val_loss: 0.4982 - val_accuracy: 0.8033\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2853 - accuracy: 0.8802 - val_loss: 0.5605 - val_accuracy: 0.8033\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8719 - val_loss: 0.5036 - val_accuracy: 0.8197\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2887 - accuracy: 0.8843 - val_loss: 0.5229 - val_accuracy: 0.8033\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8636 - val_loss: 0.6008 - val_accuracy: 0.7869\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8926 - val_loss: 0.5516 - val_accuracy: 0.8033\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8802 - val_loss: 0.5539 - val_accuracy: 0.8033\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.8843 - val_loss: 0.5616 - val_accuracy: 0.8033\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.8967 - val_loss: 0.5629 - val_accuracy: 0.8197\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9008 - val_loss: 0.5625 - val_accuracy: 0.8033\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2490 - accuracy: 0.9091 - val_loss: 0.5451 - val_accuracy: 0.8033\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.8802 - val_loss: 0.6087 - val_accuracy: 0.7869\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.9091 - val_loss: 0.5518 - val_accuracy: 0.8033\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9050 - val_loss: 0.6525 - val_accuracy: 0.8033\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2305 - accuracy: 0.9132 - val_loss: 0.5734 - val_accuracy: 0.8033\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2264 - accuracy: 0.9174 - val_loss: 0.6388 - val_accuracy: 0.7869\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.8926 - val_loss: 0.5723 - val_accuracy: 0.8033\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.9050 - val_loss: 0.5749 - val_accuracy: 0.8033\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.2320 - accuracy: 0.9174 - val_loss: 0.5494 - val_accuracy: 0.8197\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.8884 - val_loss: 0.6150 - val_accuracy: 0.8033\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.9174 - val_loss: 0.5760 - val_accuracy: 0.8033\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.9050 - val_loss: 0.7149 - val_accuracy: 0.7869\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8884 - val_loss: 0.6260 - val_accuracy: 0.8033\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2250 - accuracy: 0.9256 - val_loss: 0.6356 - val_accuracy: 0.8033\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9174 - val_loss: 0.6568 - val_accuracy: 0.7869\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9050 - val_loss: 0.6156 - val_accuracy: 0.8033\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9132 - val_loss: 0.6278 - val_accuracy: 0.8033\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2178 - accuracy: 0.9215 - val_loss: 0.7429 - val_accuracy: 0.8197\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.9215 - val_loss: 0.6222 - val_accuracy: 0.8033\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9050 - val_loss: 0.6258 - val_accuracy: 0.8033\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.9174 - val_loss: 0.7521 - val_accuracy: 0.8033\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9215 - val_loss: 0.7270 - val_accuracy: 0.8197\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.8884 - val_loss: 0.6415 - val_accuracy: 0.7869\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9215 - val_loss: 0.6652 - val_accuracy: 0.8197\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2107 - accuracy: 0.9215 - val_loss: 0.7723 - val_accuracy: 0.8197\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9008 - val_loss: 0.6129 - val_accuracy: 0.8197\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.9091 - val_loss: 0.5828 - val_accuracy: 0.8033\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.8926 - val_loss: 0.7945 - val_accuracy: 0.7869\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2391 - accuracy: 0.8967 - val_loss: 0.6602 - val_accuracy: 0.8033\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9256 - val_loss: 0.6088 - val_accuracy: 0.8197\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2096 - accuracy: 0.9132 - val_loss: 0.7894 - val_accuracy: 0.8033\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 0.9132 - val_loss: 0.6201 - val_accuracy: 0.8197\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.9256 - val_loss: 0.6805 - val_accuracy: 0.8197\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.1995 - accuracy: 0.9256 - val_loss: 0.6609 - val_accuracy: 0.8197\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1935 - accuracy: 0.9256 - val_loss: 0.7213 - val_accuracy: 0.8197\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9298 - val_loss: 0.7497 - val_accuracy: 0.7869\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.9298 - val_loss: 0.7329 - val_accuracy: 0.8197\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9298 - val_loss: 0.6951 - val_accuracy: 0.8197\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1890 - accuracy: 0.9298 - val_loss: 0.8334 - val_accuracy: 0.8033\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2105 - accuracy: 0.9008 - val_loss: 0.7382 - val_accuracy: 0.8197\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9298 - val_loss: 0.7469 - val_accuracy: 0.8197\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.9339 - val_loss: 0.8437 - val_accuracy: 0.8033\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1904 - accuracy: 0.9256 - val_loss: 0.7651 - val_accuracy: 0.8033\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1809 - accuracy: 0.9298 - val_loss: 0.7916 - val_accuracy: 0.8033\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9380 - val_loss: 0.8339 - val_accuracy: 0.7869\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9380 - val_loss: 0.7803 - val_accuracy: 0.8033\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1790 - accuracy: 0.9256 - val_loss: 0.7420 - val_accuracy: 0.8197\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1784 - accuracy: 0.9339 - val_loss: 0.8215 - val_accuracy: 0.7869\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1812 - accuracy: 0.9256 - val_loss: 0.7296 - val_accuracy: 0.8197\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9256 - val_loss: 0.7999 - val_accuracy: 0.8033\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.9339 - val_loss: 0.8151 - val_accuracy: 0.7869\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1819 - accuracy: 0.9298 - val_loss: 0.8569 - val_accuracy: 0.7869\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.9174 - val_loss: 0.7767 - val_accuracy: 0.8197\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1843 - accuracy: 0.9298 - val_loss: 0.8258 - val_accuracy: 0.8033\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.1693 - accuracy: 0.9298 - val_loss: 0.7314 - val_accuracy: 0.8197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f68bcef5320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja7eLAFphs59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e9e38cb-3e6d-4ee2-dfd2-35558d6b92fc"
      },
      "source": [
        "print(f\"Accuracy: {accuracy_score(np.round(model.predict(X_test)),y_test)}\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.819672131147541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QCyzNLhingG",
        "colab_type": "text"
      },
      "source": [
        "## Step 4 - Grid search to find best parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51osjybPh3F_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create model, required for KerasClassifier:\n",
        "def gridsearch_create_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(64, input_dim=13, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  # compile model\n",
        "  adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "  # create model\n",
        "model2 = KerasClassifier(build_fn=gridsearch_create_model, verbose=0)\n",
        "\n",
        "  # define the grid search parameters\n",
        "param_grid = {'batch_size': [32, 64, 128, 256, 512],\n",
        "                'epochs': [100]}"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AeOwItTiuTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create grid search\n",
        "grid = GridSearchCV(estimator=model2, param_grid=param_grid)\n",
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEU2MLuZiw8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "eaffb124-0781-4565-8981-f2adc3ca8bac"
      },
      "source": [
        "# Report Results\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print(f\"Means: {mean}, Stdev: {stdev} with: {params}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.8514455795288086 using {'batch_size': 256, 'epochs': 100}\n",
            "Means: 0.8430272221565247, Stdev: 0.04258362132403057 with: [{'batch_size': 32, 'epochs': 100}, {'batch_size': 64, 'epochs': 100}, {'batch_size': 128, 'epochs': 100}, {'batch_size': 256, 'epochs': 100}, {'batch_size': 512, 'epochs': 100}]\n",
            "Means: 0.8307823181152344, Stdev: 0.03705375821644967 with: [{'batch_size': 32, 'epochs': 100}, {'batch_size': 64, 'epochs': 100}, {'batch_size': 128, 'epochs': 100}, {'batch_size': 256, 'epochs': 100}, {'batch_size': 512, 'epochs': 100}]\n",
            "Means: 0.8431122541427613, Stdev: 0.03795031327110663 with: [{'batch_size': 32, 'epochs': 100}, {'batch_size': 64, 'epochs': 100}, {'batch_size': 128, 'epochs': 100}, {'batch_size': 256, 'epochs': 100}, {'batch_size': 512, 'epochs': 100}]\n",
            "Means: 0.8514455795288086, Stdev: 0.03716733852281246 with: [{'batch_size': 32, 'epochs': 100}, {'batch_size': 64, 'epochs': 100}, {'batch_size': 128, 'epochs': 100}, {'batch_size': 256, 'epochs': 100}, {'batch_size': 512, 'epochs': 100}]\n",
            "Means: 0.8431972742080689, Stdev: 0.0324507015951221 with: [{'batch_size': 32, 'epochs': 100}, {'batch_size': 64, 'epochs': 100}, {'batch_size': 128, 'epochs': 100}, {'batch_size': 256, 'epochs': 100}, {'batch_size': 512, 'epochs': 100}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}