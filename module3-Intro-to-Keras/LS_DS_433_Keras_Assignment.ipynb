{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(420)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,), (102, 13), (102,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "scaler.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 15)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 706\n",
      "Trainable params: 706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=13, activation=\"relu\"))\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(Dense(15, activation=\"relu\"))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 338us/step\n",
      "mean_squared_error: 542.3704078598778\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_train, y_train)\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 2/150\n",
      "404/404 [==============================] - 0s 100us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 3/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 4/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 5/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 6/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 7/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 8/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 9/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 10/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 11/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 12/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 13/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 14/150\n",
      "404/404 [==============================] - 0s 95us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 15/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 16/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 17/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 18/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 19/150\n",
      "404/404 [==============================] - 0s 100us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 20/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 21/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 22/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 23/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 24/150\n",
      "404/404 [==============================] - 0s 96us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 25/150\n",
      "404/404 [==============================] - 0s 99us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 26/150\n",
      "404/404 [==============================] - 0s 105us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 27/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 28/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 29/150\n",
      "404/404 [==============================] - 0s 94us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 30/150\n",
      "404/404 [==============================] - 0s 107us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 31/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 32/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 33/150\n",
      "404/404 [==============================] - 0s 99us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 34/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 35/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 36/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 37/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 38/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 39/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 40/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 41/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 42/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 43/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 44/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 45/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 46/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 47/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 48/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 49/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 50/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 51/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 52/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 53/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 54/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 55/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 56/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 57/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 58/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 59/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 60/150\n",
      "404/404 [==============================] - 0s 97us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 61/150\n",
      "404/404 [==============================] - 0s 101us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 62/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 63/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 64/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 65/150\n",
      "404/404 [==============================] - 0s 97us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 66/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 67/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 68/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 69/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 71/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 72/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 73/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 74/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 75/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 76/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 77/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 78/150\n",
      "404/404 [==============================] - 0s 72us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 79/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 80/150\n",
      "404/404 [==============================] - 0s 98us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 81/150\n",
      "404/404 [==============================] - 0s 104us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 82/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 83/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 84/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 85/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 86/150\n",
      "404/404 [==============================] - 0s 78us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 87/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 88/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 89/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 90/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 91/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 92/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 93/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 94/150\n",
      "404/404 [==============================] - 0s 77us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 95/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 96/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 97/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 98/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 99/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 100/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 101/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 102/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 103/150\n",
      "404/404 [==============================] - 0s 91us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 104/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 105/150\n",
      "404/404 [==============================] - 0s 78us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 106/150\n",
      "404/404 [==============================] - 0s 85us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 107/150\n",
      "404/404 [==============================] - 0s 77us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 108/150\n",
      "404/404 [==============================] - 0s 86us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 109/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 110/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 111/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 112/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 113/150\n",
      "404/404 [==============================] - 0s 107us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 114/150\n",
      "404/404 [==============================] - 0s 94us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 115/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 116/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 117/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 118/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 119/150\n",
      "404/404 [==============================] - 0s 77us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 120/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 121/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 122/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 123/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 124/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 125/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 126/150\n",
      "404/404 [==============================] - 0s 84us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 127/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 128/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 129/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 130/150\n",
      "404/404 [==============================] - 0s 83us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 131/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 132/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 133/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 134/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 135/150\n",
      "404/404 [==============================] - 0s 89us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 136/150\n",
      "404/404 [==============================] - 0s 92us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 137/150\n",
      "404/404 [==============================] - 0s 88us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 138/150\n",
      "404/404 [==============================] - 0s 94us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 139/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 99us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 140/150\n",
      "404/404 [==============================] - 0s 93us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 141/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 142/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 143/150\n",
      "404/404 [==============================] - 0s 82us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 144/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 145/150\n",
      "404/404 [==============================] - 0s 81us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 146/150\n",
      "404/404 [==============================] - 0s 76us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 147/150\n",
      "404/404 [==============================] - 0s 79us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 148/150\n",
      "404/404 [==============================] - 0s 90us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 149/150\n",
      "404/404 [==============================] - 0s 80us/step - loss: -341.0881 - mean_squared_error: 542.3704\n",
      "Epoch 150/150\n",
      "404/404 [==============================] - 0s 87us/step - loss: -341.0881 - mean_squared_error: 542.3704\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.004800838348142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "LR = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(x_train)\n",
    "\n",
    "mse(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshsolis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from keras.datasets import fashion_mnist\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#global hyperparameters\n",
    "import keras\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,274\n",
      "Trainable params: 13,274\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation = 'relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/joshsolis/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/50\n",
      "54000/54000 [==============================] - 25s 459us/step - loss: 0.9342 - acc: 0.6508 - val_loss: 0.5321 - val_acc: 0.8127\n",
      "Epoch 2/50\n",
      "54000/54000 [==============================] - 20s 376us/step - loss: 0.6372 - acc: 0.7693 - val_loss: 0.4722 - val_acc: 0.8382\n",
      "Epoch 3/50\n",
      "54000/54000 [==============================] - 21s 398us/step - loss: 0.5840 - acc: 0.7903 - val_loss: 0.4535 - val_acc: 0.8428\n",
      "Epoch 4/50\n",
      "54000/54000 [==============================] - 18s 330us/step - loss: 0.5605 - acc: 0.8002 - val_loss: 0.4524 - val_acc: 0.8385\n",
      "Epoch 5/50\n",
      "54000/54000 [==============================] - 22s 410us/step - loss: 0.5422 - acc: 0.8056 - val_loss: 0.4454 - val_acc: 0.8427\n",
      "Epoch 6/50\n",
      "54000/54000 [==============================] - 21s 383us/step - loss: 0.5318 - acc: 0.8124 - val_loss: 0.4379 - val_acc: 0.8468\n",
      "Epoch 7/50\n",
      "54000/54000 [==============================] - 31s 577us/step - loss: 0.5244 - acc: 0.8129 - val_loss: 0.4463 - val_acc: 0.8447\n",
      "Epoch 8/50\n",
      "54000/54000 [==============================] - 24s 436us/step - loss: 0.5106 - acc: 0.8176 - val_loss: 0.4183 - val_acc: 0.8497\n",
      "Epoch 9/50\n",
      "54000/54000 [==============================] - 21s 389us/step - loss: 0.5049 - acc: 0.8210 - val_loss: 0.4213 - val_acc: 0.8520\n",
      "Epoch 10/50\n",
      "54000/54000 [==============================] - 19s 355us/step - loss: 0.4999 - acc: 0.8220 - val_loss: 0.4397 - val_acc: 0.8483\n",
      "Epoch 11/50\n",
      "54000/54000 [==============================] - 13s 238us/step - loss: 0.4962 - acc: 0.8238 - val_loss: 0.4128 - val_acc: 0.8540\n",
      "Epoch 12/50\n",
      "54000/54000 [==============================] - 9s 164us/step - loss: 0.4918 - acc: 0.8248 - val_loss: 0.4324 - val_acc: 0.8502\n",
      "Epoch 13/50\n",
      "54000/54000 [==============================] - 8s 154us/step - loss: 0.4854 - acc: 0.8290 - val_loss: 0.4109 - val_acc: 0.8572\n",
      "Epoch 14/50\n",
      "54000/54000 [==============================] - 8s 155us/step - loss: 0.4842 - acc: 0.8303 - val_loss: 0.4063 - val_acc: 0.8568\n",
      "Epoch 15/50\n",
      "54000/54000 [==============================] - 8s 157us/step - loss: 0.4834 - acc: 0.8295 - val_loss: 0.4128 - val_acc: 0.8572\n",
      "Epoch 16/50\n",
      "54000/54000 [==============================] - 9s 176us/step - loss: 0.4763 - acc: 0.8304 - val_loss: 0.4232 - val_acc: 0.8527\n",
      "Epoch 17/50\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.4754 - acc: 0.8308 - val_loss: 0.4132 - val_acc: 0.8578\n",
      "Epoch 18/50\n",
      "54000/54000 [==============================] - 8s 145us/step - loss: 0.4757 - acc: 0.8309 - val_loss: 0.4118 - val_acc: 0.8573\n",
      "Epoch 19/50\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.4721 - acc: 0.8306 - val_loss: 0.4200 - val_acc: 0.8580\n",
      "Epoch 20/50\n",
      "54000/54000 [==============================] - 12s 217us/step - loss: 0.4718 - acc: 0.8334 - val_loss: 0.4015 - val_acc: 0.8573\n",
      "Epoch 21/50\n",
      "54000/54000 [==============================] - 14s 263us/step - loss: 0.4708 - acc: 0.8321 - val_loss: 0.4066 - val_acc: 0.8580\n",
      "Epoch 22/50\n",
      "54000/54000 [==============================] - 10s 186us/step - loss: 0.4696 - acc: 0.8338 - val_loss: 0.4133 - val_acc: 0.8558\n",
      "Epoch 23/50\n",
      "54000/54000 [==============================] - 10s 182us/step - loss: 0.4644 - acc: 0.8344 - val_loss: 0.4033 - val_acc: 0.8593\n",
      "Epoch 24/50\n",
      "54000/54000 [==============================] - 9s 170us/step - loss: 0.4645 - acc: 0.8356 - val_loss: 0.4216 - val_acc: 0.8552\n",
      "Epoch 25/50\n",
      "54000/54000 [==============================] - 10s 189us/step - loss: 0.4608 - acc: 0.8361 - val_loss: 0.4040 - val_acc: 0.8572\n",
      "Epoch 26/50\n",
      "54000/54000 [==============================] - 10s 187us/step - loss: 0.4604 - acc: 0.8359 - val_loss: 0.4211 - val_acc: 0.8545\n",
      "Epoch 27/50\n",
      "54000/54000 [==============================] - 10s 186us/step - loss: 0.4572 - acc: 0.8391 - val_loss: 0.4118 - val_acc: 0.8528\n",
      "Epoch 28/50\n",
      "54000/54000 [==============================] - 12s 215us/step - loss: 0.4554 - acc: 0.8381 - val_loss: 0.4073 - val_acc: 0.8597\n",
      "Epoch 29/50\n",
      "54000/54000 [==============================] - 10s 192us/step - loss: 0.4584 - acc: 0.8363 - val_loss: 0.4095 - val_acc: 0.8550\n",
      "Epoch 30/50\n",
      "54000/54000 [==============================] - 10s 189us/step - loss: 0.4512 - acc: 0.8388 - val_loss: 0.4381 - val_acc: 0.8492\n",
      "Epoch 31/50\n",
      "54000/54000 [==============================] - 11s 203us/step - loss: 0.4535 - acc: 0.8389 - val_loss: 0.4191 - val_acc: 0.8557\n",
      "Epoch 32/50\n",
      "54000/54000 [==============================] - 10s 190us/step - loss: 0.4503 - acc: 0.8405 - val_loss: 0.4237 - val_acc: 0.8520\n",
      "Epoch 33/50\n",
      "54000/54000 [==============================] - 10s 192us/step - loss: 0.4519 - acc: 0.8396 - val_loss: 0.4164 - val_acc: 0.8573\n",
      "Epoch 34/50\n",
      "54000/54000 [==============================] - 10s 194us/step - loss: 0.4484 - acc: 0.8396 - val_loss: 0.4032 - val_acc: 0.8580\n",
      "Epoch 35/50\n",
      "54000/54000 [==============================] - 10s 182us/step - loss: 0.4497 - acc: 0.8403 - val_loss: 0.4040 - val_acc: 0.8613\n",
      "Epoch 36/50\n",
      "54000/54000 [==============================] - 10s 190us/step - loss: 0.4475 - acc: 0.8424 - val_loss: 0.4020 - val_acc: 0.8623\n",
      "Epoch 37/50\n",
      "54000/54000 [==============================] - 10s 181us/step - loss: 0.4488 - acc: 0.8392 - val_loss: 0.4104 - val_acc: 0.8578\n",
      "Epoch 38/50\n",
      "54000/54000 [==============================] - 10s 183us/step - loss: 0.4499 - acc: 0.8394 - val_loss: 0.4141 - val_acc: 0.8585\n",
      "Epoch 39/50\n",
      "54000/54000 [==============================] - 10s 189us/step - loss: 0.4498 - acc: 0.8403 - val_loss: 0.4079 - val_acc: 0.8560\n",
      "Epoch 40/50\n",
      "54000/54000 [==============================] - 10s 192us/step - loss: 0.4434 - acc: 0.8400 - val_loss: 0.3949 - val_acc: 0.8637\n",
      "Epoch 41/50\n",
      "54000/54000 [==============================] - 10s 181us/step - loss: 0.4480 - acc: 0.8399 - val_loss: 0.4194 - val_acc: 0.8602\n",
      "Epoch 42/50\n",
      "54000/54000 [==============================] - 10s 194us/step - loss: 0.4443 - acc: 0.8429 - val_loss: 0.4139 - val_acc: 0.8588\n",
      "Epoch 43/50\n",
      "54000/54000 [==============================] - 11s 199us/step - loss: 0.4406 - acc: 0.8435 - val_loss: 0.4156 - val_acc: 0.8535\n",
      "Epoch 44/50\n",
      "54000/54000 [==============================] - 11s 202us/step - loss: 0.4473 - acc: 0.8416 - val_loss: 0.4134 - val_acc: 0.8578\n",
      "Epoch 45/50\n",
      "54000/54000 [==============================] - 15s 269us/step - loss: 0.4406 - acc: 0.8440 - val_loss: 0.4008 - val_acc: 0.8625\n",
      "Epoch 46/50\n",
      "54000/54000 [==============================] - 11s 203us/step - loss: 0.4414 - acc: 0.8422 - val_loss: 0.4262 - val_acc: 0.8563\n",
      "Epoch 47/50\n",
      "54000/54000 [==============================] - 11s 202us/step - loss: 0.4392 - acc: 0.8432 - val_loss: 0.4032 - val_acc: 0.8605\n",
      "Epoch 48/50\n",
      "54000/54000 [==============================] - 10s 191us/step - loss: 0.4387 - acc: 0.8436 - val_loss: 0.4088 - val_acc: 0.8642\n",
      "Epoch 49/50\n",
      "54000/54000 [==============================] - 11s 196us/step - loss: 0.4402 - acc: 0.8424 - val_loss: 0.4036 - val_acc: 0.8580\n",
      "Epoch 50/50\n",
      "54000/54000 [==============================] - 10s 184us/step - loss: 0.4363 - acc: 0.8438 - val_loss: 0.4237 - val_acc: 0.8560\n",
      "10000/10000 [==============================] - 1s 72us/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=epochs, validation_split=.1)\n",
    "scores = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
