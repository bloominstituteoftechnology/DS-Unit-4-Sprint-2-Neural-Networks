{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "train, test = boston_housing.load_data(path='boston_housing.npz', test_split=0.3, seed=47)\n",
    "X_train = train[0]\n",
    "y_train = train[1]\n",
    "X_test = test[0]\n",
    "y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((354, 13), (354,), (152, 13), (152,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 00:34:14.494269 10316 deprecation.py:506] From C:\\Users\\nchib\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 378\n",
      "Trainable params: 378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Input ==> Hidden\n",
    "model.add(Dense(13, input_dim=13, activation='relu'))\n",
    "# Hidden\n",
    "model.add(Dense(13, activation='relu'))\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "                    optimizer='adam', \n",
    "                    metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 33us/sample - loss: 15.4031 - mean_squared_error: 15.4031\n",
      "mean_squared_error: 15.403149604797363\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=1000, validation_split=.1, verbose=0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5QcZ3nn8e9TVX2Z0W0keSzrZiSDsOyY+IJiRCAEMDd7c2LHa04ggBXjrJLgJZBkkzUJ5yQ5IVmzm40Ts4kXBwMiIQTHhLVCHMArTLzBsUEKxlcZyRaWxpKlsS4zo7n1pZ79o96RRtJIM5Jmpqerf59z+nTVW293PzUl/ar67eouc3dERCRfokYXICIik0/hLiKSQwp3EZEcUriLiOSQwl1EJIcU7iIiOTRuuJvZhWb22Khbr5l91MwWmNkDZrYt3M8P/c3M7jCz7Wb2uJldMfWrISIio40b7u7+rLtf5u6XAa8FBoCvArcCm9x9FbApzANcDawKt/XAnVNRuIiInNzpDstcBTzn7i8A1wIbQvsG4LowfS3wBc88AnSY2eJJqVZERCYkOc3+7wG+FKYXufseAHffY2bnhvalwK5Rj+kKbXtO9qTnnHOOr1ix4jRLERFpbVu2bHnZ3TvHWjbhcDezIvCzwMfG6zpG2wm/cWBm68mGbTj//PPZvHnzREsRERHAzF442bLTGZa5Gvh3d98b5veODLeE+32hvQtYPupxy4Ddxz+Zu9/l7mvcfU1n55g7HhEROUOnE+7v5eiQDMBGYF2YXgfcN6r9xnDWzFqgZ2T4RkREpseEhmXMrB14O/DLo5pvA+4xs5uBncC7Q/v9wDXAdrIza26atGpFRGRCJhTu7j4ALDyubT/Z2TPH93XglkmpTkREzoi+oSoikkMKdxGRHFK4i4jkUFOH+8A/bWDfh6/H07TRpYiIzChNHe5DWx5m/wPPUN+9o9GliIjMKE0d7snyFQBUtz/e2EJERGaYpg73wsrVAFR3bG1wJSIiM0tzh/urfhyA2q4fNbYQEZEZpqnDPV6yEoud6u4TfrpGRKSlNXW4WxRRmBtR3be/0aWIiMwoTR3uAIX57VT3H250GSIiM0rzh/s586j2VBpdhojIjNL04Z6ccw71IfCqAl5EZETTh3u8YCFg1Pf8qMGViIjMHE0f7klndunW+h59S1VEZETTh3vceR4AtZd2jdNTRKR1NH+4L8ou11rfp3PdRURGNH+4L1kBQK1776k7ioi0kKYP92TxSgDqB/RFJhGREU0f7lZuJyo49UO9jS5FRGTGaPpwB4hKRto/0OgyRERmjAmFu5l1mNm9ZrbVzJ4xs9eb2QIze8DMtoX7+aGvmdkdZrbdzB43syumdhUgLkXUB4em+mVERJrGRI/c/xz4uruvBi4FngFuBTa5+ypgU5gHuBpYFW7rgTsnteIxROUC6cDwVL+MiEjTGDfczWwu8CbgbgB3r7j7IeBaYEPotgG4LkxfC3zBM48AHWa2eNIrHyUqF0iHalP5EiIiTWUiR+4XAN3A58zs+2b2GTObBSxy9z0A4f7c0H8pMPobRV2hbcrE7SXqw/WpfAkRkaYykXBPgCuAO939cqCfo0MwY7Ex2vyETmbrzWyzmW3u7u6eULEnE81qIx1Oz+o5RETyZCLh3gV0ufujYf5esrDfOzLcEu73jeq/fNTjlwEnfH3U3e9y9zXuvqazs/NM6wcgmtVOqh+FFBE5Ytxwd/eXgF1mdmFougp4GtgIrAtt64D7wvRG4MZw1sxaoGdk+GaqxLNn46mRDvRN5cuIiDSNZIL9Pgx80cyKwPPATWQ7hnvM7GZgJ/Du0Pd+4BpgOzAQ+k6paM5cANIDLxG1z5nqlxMRmfEmFO7u/hiwZoxFV43R14FbzrKu0xLNnQdAemAfLFs1nS8tIjIj5eIbqvHcDgDqB/aN01NEpDXkItyjjoUApD368TAREchNuC8AID2kcBcRgZyEezw/+/5U2nuowZWIiMwMTR3u//jMd/mVf/yf0JGdJ1/v6WlwRSIiM0NTh/s/b/8O3znwefYkRQDSw/pNdxERaPJwX9mRfRH28UP7wJx0QL/pLiICTR7uq895BQBbD+wiSiDVb7qLiABNHu6XLb4AgB2HuogKkA7pN91FRKDJw33p3PmQltndvxsrRLjCXUQEaPJwj6KIJF3I/uGXiAoR6XC10SWJiMwITR3uALOTTg7XuomKscJdRCRo+nBfWDqPWrQfKyakFV1qT0QEchDuS2YtgWiIWinBK7rUnogI5CDcV3YsA6C/EJFWdKk9ERHIQbhfsCC79vbhxEirJ1yqVUSkJTV9uJ8/L/vRsP5CRKohdxERIA/hHn40rC8Br4GnGpoREWn6cO9sn4OnMb0FAwzvO9jokkREGq7pwz2KIiKfTW8hG29P+w40uCIRkcZr+nAHSJhDT5INx6S9CncRkQmFu5n9yMyeMLPHzGxzaFtgZg+Y2bZwPz+0m5ndYWbbzexxM7tiKlcAoGRz6Clk4e59uhqTiMjpHLm/xd0vc/c1Yf5WYJO7rwI2hXmAq4FV4bYeuHOyij2Z9mQevcXsVJm0T1djEhE5m2GZa4ENYXoDcN2o9i945hGgw8wWn8XrjKstnkV/Ift2anpY4S4iMtFwd+CbZrbFzNaHtkXuvgcg3J8b2pcCu0Y9tiu0HcPM1pvZZjPb3N3dfWbVB7MKs+kvhSN3XWpPRIRkgv3e4O67zexc4AEz23qKvjZG2wlfHXX3u4C7ANasWXNWXy2dXZhDbzF7Cu/vO5unEhHJhQkdubv77nC/D/gqcCWwd2S4JdzvC927gOWjHr4M2D1ZBY9lXmk2w4VsOu0/PJUvJSLSFMYNdzObZWZzRqaBdwBPAhuBdaHbOuC+ML0RuDGcNbMW6BkZvpkqc0tzjob70OBUvpSISFOYyLDMIuCrZjbS/2/d/etm9j3gHjO7GdgJvDv0vx+4BtgODAA3TXrVx+koz6Ua1sSHdJFsEZFxw93dnwcuHaN9P3DVGO0O3DIp1U3Qwra5VBTuIiJH5OIbqgvb51GPwM1JK7pItohILsK9c9Y8MCONwYcU7iIiuQj3RbPnAZAm4JVKg6sREWm8XIT7ubOycK8lkA5XG1yNiEjj5SLcy4UinhapxYZXFe4iIrkIdwDzMtUE0orCXUQkN+EeexuVxPCqLqQqIpKbcE+sneEEvFJvdCkiIg2Xm3AvWjvDiZHWFO4iIrkJ90JUYrgAXk0bXYqISMPlJtyLURtDCXhN4S4ikptwL8VlhhJIq2f10/AiIrmQm3AvJ20MFcDrCncRkdyEe1vcxnDipDoTUkQkR+FeaKNSANfJMiIi+Qn39kI71djADR/Wb7qLSGvLTbjPLrQfvWDHoK6jKiKtLT/hXmynFmfT6UBfY4sREWmw3IT7nOKoI/eB3sYWIyLSYLkJ97mlWUcvkj3Y39hiREQaLDfh3lGeTTUMyyjcRaTVTTjczSw2s++b2dfC/Eoze9TMtpnZl82sGNpLYX57WL5iako/1rzy0SP3dEAfqIpIazudI/ePAM+Mmv8kcLu7rwIOAjeH9puBg+7+KuD20G/KdbSNGpYZHpyOlxQRmbEmFO5mtgz4D8BnwrwBbwXuDV02ANeF6WvDPGH5VaH/lJpfnqNhGRGRYKJH7n8G/DYw8pOLC4FD7j7yZf8uYGmYXgrsAgjLe0L/Y5jZejPbbGabu7u7z7D8oxa0zaaaZPsQHxw46+cTEWlm44a7mf0MsM/dt4xuHqOrT2DZ0Qb3u9x9jbuv6ezsnFCxpzKrVKISh3DXsIyItLhkAn3eAPysmV0DlIG5ZEfyHWaWhKPzZcDu0L8LWA50mVkCzAMOTHrlY6hHBaBGOqQjdxFpbeMeubv7x9x9mbuvAN4DfMvd3wc8CNwQuq0D7gvTG8M8Yfm33H1afoe3FhWymof02zIi0trO5jz3/wr8hpltJxtTvzu03w0sDO2/Adx6diVOXD0pAuiHw0Sk5U1kWOYId/828O0w/Txw5Rh9hoB3T0Jtpy2NS1kNw8ONeHkRkRkjN99QBagXygCkOnIXkRaXr3BPsnD3SqXBlYiINFauwj2KS9Qj17CMiLS8XIV7YkVqseHDOnIXkdaWq3AvRCWqCXi12uhSREQaKmfhXqAaQ1pRuItIa8tVuBfjMhUduYuI5Czco2II93qjSxERaahchXspzsbc00pt/M4iIjmWq3AvxiUqMdSrCncRaW25CvdyUqKaGHUNy4hIi8tfuMeQ1tLxO4uI5Fi+wn1kzF3hLiItLlfh3l4oZ19iqivcRaS15Src25Iy1RhcQ+4i0uJyFe6ziuHIvTYtF34SEZmxchXuI8MypiN3EWlxuQr3WcU2KgmgcBeRFpezcC9Ti8FSw2v6IpOItK5chfucYhuVxADwwb4GVyMi0ji5CvfZpexsGQAfPNzYYkREGmjccDezspl918x+YGZPmdkfhPaVZvaomW0zsy+bWTG0l8L89rB8xdSuwlGzi21Uk2za+3XkLiKtayJH7sPAW939UuAy4F1mthb4JHC7u68CDgI3h/43Awfd/VXA7aHftJhXbj8S7qmGZUSkhY0b7p4ZGeMohJsDbwXuDe0bgOvC9LVhnrD8KjOzSav4FOYU244OywwNTMdLiojMSBMaczez2MweA/YBDwDPAYfcfeSUlC5gaZheCuwCCMt7gIVjPOd6M9tsZpu7u7vPbi2CYpJQi8MHqgMacxeR1jWhcHf3urtfBiwDrgQuGqtbuB/rKP2Er4y6+13uvsbd13R2dk603nHV4myVfLB/0p5TRKTZnNbZMu5+CPg2sBboMLMwws0yYHeY7gKWA4Tl84ADk1HsRNTibFzGhwan6yVFRGaciZwt02lmHWG6DXgb8AzwIHBD6LYOuC9MbwzzhOXfcvdp+7GXepTtb1IduYtIC0vG78JiYIOZxWQ7g3vc/Wtm9jTwd2b2CeD7wN2h/93AX5vZdrIj9vdMQd0nVUuyVdIHqiLSysYNd3d/HLh8jPbnycbfj28fAt49KdWdgSPhPjzUqBJERBouV99QBUjjAqAxdxFpbbkL93qhBECqcBeRFpa/cE+KAPhwpcGViIg0Tg7DPTty15i7iLSy/IV7oQyADw83uBIRkcbJXbhHSZnUIK1qWEZEWlfuwr0Ql6jFOnIXkdaWv3CPilQT8Eq10aWIiDRM/sI9LlJRuItIi8tduBejEtUYvKpwF5HWlbtwL4Uj99qwwl1EWlf+wj0pUU2gXq2N31lEJKdyF+7FqEg1hnpN4S4irSt34V4+cuReb3QpIiINk7twb0tKVGPDq2mjSxERaZjchXs5KVNNIK0r3EWkdeUw3MOXmGrTdmU/EZEZJ3fh3l7IznNH4S4iLSyH4Z4Ny1BXuItI68pfuBfL2ZG7TpYRkRY2brib2XIze9DMnjGzp8zsI6F9gZk9YGbbwv380G5mdoeZbTezx83siqleidHakhKVBIW7iLS0iRy514DfdPeLgLXALWZ2MXArsMndVwGbwjzA1cCqcFsP3DnpVZ/C7GKZWgxWB091xoyItKZxw93d97j7v4fpPuAZYClwLbAhdNsAXBemrwW+4JlHgA4zWzzplZ/ErGKZSmIYBsO6SLaItKbTGnM3sxXA5cCjwCJ33wPZDgA4N3RbCuwa9bCu0DYtZhfbsg9UgbS/Z7peVkRkRplwuJvZbOArwEfdvfdUXcdoO+HUFTNbb2abzWxzd3f3RMsY15xS+EAV8KH+SXteEZFmMqFwN7MCWbB/0d3/ITTvHRluCff7QnsXsHzUw5cBu49/Tne/y93XuPuazs7OM63/BLOK5SNH7j7QN2nPKyLSTCZytowBdwPPuPufjlq0EVgXptcB941qvzGcNbMW6BkZvpkOc4plhgvZdNp7aLpeVkRkRkkm0OcNwAeAJ8zssdD2O8BtwD1mdjOwE3h3WHY/cA2wHRgAbprUiscRRRGDxQhISQ/uG7e/iEgejRvu7v6vjD2ODnDVGP0duOUs6zorg8UEqFE/+HIjyxARaZjcfUMVYLCUjcukh/Y3uBIRkcbIabiXAKgfOtDgSkREGiOn4d4GQNqj89xFpDXlMtyrxXbqkVPvO9Xp+CIi+ZXLcE+iMkMlo96nLzGJSGvKZbgXohKDJUgHBhpdiohIQ+Qy3ItRmf4S1PuHGl2KiEhD5DPc4zK97Ua9V+EuIq0pl+Feisp0zzWqvdVGlyIi0hC5DPdy0kb3XKgPGWnfwUaXIyIy7XIZ7m1Jme552XTtuScaW4yISAPkNNzb2D83m64+/3RjixERaYBchnt7oY1987LfOqv88KkGVyMiMv1yGe5zS7OzYZmSM/iUjtxFpPXkMtw72zvAjMriNoZ27G10OSIi0y6X4X7e7IUAvPyKTob316jt3tHgikREplcuw33J3Czcn33NanCj/6t3N7giEZHplctwXz4vC/cnlp1P0u70fvP/NrgiEZHplctwP3fWPNwjDlV7mbv21Rz+4SFqXdsaXZaIyLTJZbhHUYSl7fRVe5n3gQ+BG72f/ZNGlyUiMm1yGe4Asc+iv9ZL+fXvorwo4dAD32l0SSIi02bccDezz5rZPjN7clTbAjN7wMy2hfv5od3M7A4z225mj5vZFVNZ/KkUbTYD9ewye/Pe/lMMd9cZ+n8bG1WOiMi0msiR++eBdx3Xdiuwyd1XAZvCPMDVwKpwWw/cOTllnr6OwnkMenaO+9wP/hZETs/f3NWockREptW44e7uDwEHjmu+FtgQpjcA141q/4JnHgE6zGzxZBV7OpbPWYnHPbzUd5BkyUrmrF5Az6PbSQ/rotkikn9nOua+yN33AIT7c0P7UmDXqH5doW3arV74SgAe3rkVgPnvX0d9yOj51O82ohwRkWk12R+o2hhtPmZHs/VmttnMNnd3d09yGbB22cUAPLzrBwC0X/efaFtcYP9XNuFDuraqiOTbmYb73pHhlnC/L7R3ActH9VsG7B7rCdz9Lndf4+5rOjs7z7CMk3vDK1ZjtQ6+u/dhACyKWPhLv0j1MPR8+g8m/fVERGaSMw33jcC6ML0OuG9U+43hrJm1QM/I8M10i6KIV7Sv4UD6JHvDOPvs936UUmfMy1/cqCs0iUiuTeRUyC8B/wZcaGZdZnYzcBvwdjPbBrw9zAPcDzwPbAf+CvjQlFQ9Qe//seuxqMrtD98DZEfvi379w1R74eWP/1IjSxMRmVLmPuaQ+LRas2aNb968edKfN01TrvjcO0msjc0fPHqO++73vYWef9/Dijv/iLY3/8dJf10RkelgZlvcfc1Yy3L7DVXIhmZ+8txrGI538E/PHt15nPs/PkvSbuz69d+l8tQjDaxQRGRq5DrcAT72UzfiaYnbv3v0C0zJkpWc/78/hddh1wc/qB8VE5HcyX24L+9YyEWz3sFL9Ud4dOfREC/9xNtY/smPUz2csvPnr6Py2EMNrFJEZHLlPtwBfv+nfxU84hPf+ctj2tuvfj/L//Cj1A7X2fGB9Rz87x/Ba7UGVSkiMnlaItx/bNFyzi/+FDuGvs2WF587Ztms63+FlV/+IuXFbbz02W/yo6sup2/DJxXyItLUWiLcAf74rb8JGL+16Y9PWFZY/VrO//oWFn/oWuoDNbr+2+fZ8aZL6fmLj+PDQ9NfrIjIWWqZcL9s8Qoun/tzdPt3uePh+05YblFEx6/dxiv/9fss+XB2euTuT32F5954OQc+8SHSg/tOeIyIyEzVMuEO8KlrfoNCfTl/tfUTPPzC1jH7WKnMvFs+wcqHfsCy37mJZE6RvX/zINt++k3s+/D1VLf/YJqrFhE5fbn+EtNYNndt56Zvvo/EO/j6z9/Dotnzxn3MwDf+lgN3/S/6ns5++XjORQuY/wsfoP36X8ailto/isgM0rJfYhrLmmWv4sOv+X2q8R6uuee9PPnSznEf0/7OX2DZVx7mlfd+ngVvfjUDzx1g58fv4Pk3XMKBP76FeveL01C5iMjEtdyR+4hP/dt9fHrrH2Ie89bzPsDvv/kXmd8+e0KPTQ/30Pe52zhw7z8xtLeKxc7cy5cw/6ZfofyWG3Q0LyLT4lRH7i0b7gAP7XiK//LgxxmMt0O9nfPLa7n6grfxgcuuYl65fULPMbjpHg5t+DQ9W17E60bpnJiOd7yBuR/8bZJlr5ziNRCRVqZwP4U0TfnSEw/xmR98ge7641g0jKcx7b6ClXMu4XWLr+CaC69kdeeyUz5PvftFeu++jUP//C8M7a1C5My5aAEdN/w8s274VaxQnKY1EpFWoXCfoJ6hAf7msU38y85HeP7wEwxFOzGrA2C1BZxTWMXq+T/G65b+OO9cdQXnzZk/5vMMPXw/PRv+kp5Ht1MfMpJZMO+NF9Nx00coXvam6VwlEckxhfsZOjTYz9e3beGhF7aw9eCTvFz9IZ4cAsDdSOqddBZXsarjQl67+GLevPJSXrnwvCOP98F++v72dg599T76n+sDz4Zt5rz+Ncy5fh2l171D4/MicsYU7pPo2e7dPPDcFr63+3Ge79tKT30HHvcc7VCfw2xbxpL2C1i94NWsXXYJb1p5Ce1d2+j960/R953NDHYNAUZhnjH3J17N7Kt/jvJbridqn9Ow9RKR5qNwn2LbXt7DQz96nC17nua5nm28XHmBYduNRdnv04wc5c9JlnBueSmvqbXxxieeYtlj2/AXBsENi522pW20rV5J+dIrKK99G4WLrtSRvYiclMK9ASq1Go/sepbv7HySp17eys7Dz9NX20M16j4S+gCzBo3LdsRcuqvO6q4q577sRKkBUC861Y6YdNEc6FxIvGQp7RdcyPzVr2XBxVcST/CMHhHJJ4X7DFKr19na/SJbdm/jmZef54WeXRwc3s/h2iGG0l68eoBlB3pYuddZudc57yAs2e8s6Dv2G2epQW87HJgDPbONvvaIvvaIgbaE/rYC/e1F+tvK9Le3M1Rup1puh6RMMSljFmEYxbhIEiUkViCJEgpxQiEqhFs2X4wL2S0qUEwKFOOEUlyklGTtpaRAW5LNl+IC5aRIEmeVziq0UYgjZhXLtCVFkjhuzB9dJKdOFe7JdBfT6pI45pLzzueS884HrhqzT61eZ19/Dy/2HmB373629h+i//DLWNc2CrtfoLxvL+0HemjrG2R2b4WOQ3XaXqxRGoLIq8Dg2M8bwWAJ6lG2YxgswVBiVApQSUbdjswbAwU4dJJlx84fXV6PALMTXt89Ao+AGPMYiDBi8BgjJiIGYiIbmU+ILAr3MZElxJYtjy0Jt5gkKoT7JNtJRQUKUZEkirP2OCGxbNpxIjPmlmZTjksU4pgkLlAOO6ZiUiAOO7/IIjpnzWVeeRZtSZFiklBKCpTjIqUk0c5KZjSF+wyUxDFL5i5gydwFwKsm/Div1Ui7u6jteYF694vU9+2mvn8faW8P6UA/6eF+0oEB0uEK9cODpEMVvFIn7a9Tr6Z4zUlrjteAOuAnBvSE6jAnjSFNoJ4Y9QRqiVFLUmqJUU1qVBOjmkTZTqJgDIfp4cQYLhhDSXarRlCJw44jgmrsVEbdqrEzEKdUE6cWp1TjevZ6MWPuYCZTtrOKMU+AsLPysMMiGrWzijASIiLMsp3YyM6qHLVTiIoUoiKxZTun2GLiKKYQFWhL2ignReIooRBl76QKYboQZ++kinExe0c16t1UKQ7vpArZjqgUF2krFCglRcrh3VYx0X//PJuSrWtm7wL+nOxf/Gfc/bapeB05liUJ8eIVxItXTMrz+dAA6eFDeH8vaX8P3t8X7g+TDh7GB/rxwQHSwYHsfmgIHxokHR7Gh4ZJhyt4pYIPV0mrVbxSI63W8YE6aa2OV6tHdiZeB08nOYwjxyKy8awIMCAyiMBjI40Njw0nm6/HRmqhLTbSKKIaQTWCepQtr0dGLdyqsVGLoBplO6FaBLUopRo5tZjw2GxZdWQ+hpo5tcipmlOJalSjlGpUpxY5FXPSKCWNHDey2sI9o+ZTgzQKt/BnG1l2ZPuN8bhjlrmF+2wH5VEdtxS8/ci7KbNsB2WWHLNjGnmnFdnIDisKO7E4vNuKMIvCTiw6pi0+ri2Ksh1hHEUkUUJb0oZhpJ5iZpSTEqU4eycWWUQcnjeJsueIo5jYLNxHR/olUUwUReFdW0QSZ/dxlL1WNh0deUxsMVFkRGZhvYwk3MeRYUQkUTYfkb2emZFEhlm2LMKIoohSnFCMx4/XaApPmJj0cLfsX8NfAG8HuoDvmdlGd396sl9LppaV27MPbc9ZMi2v59VKtiM53IMP9OADh/HKMD48iA8P4UMDeGUIHx7O7ivD2c6jMjxqupI9T7UabrXsvp5CvY6n4b5aJ63V8Fo9S756io/cKmno53gabnXw1MFHdkTgztFkbWo1YHjUfOWkPT3bXRzZURzZgUDYidgJO5OR5aP7Hv/4U+2UxupvgPmxjxm73tB5pESHKIXIs+HDkcel4XbMJ5Cjazr+eU/2ese1n+oTTc/+VLx41SW8/xN/f4qeZ2YqjtyvBLa7+/MAZvZ3wLWAwl1OyQpFrOMcoo5zGl3KafFqJdsBVQahOhx2PoNQrYzaCYWdVLUCtSpeq0I92/Fk9xVwz3YqaR3SFE/rkHq2F0nruIdp92wHVa8dvRxkmh5dBtlzje5/5MQJh9SzkD6uf3Y7GuDHPNY50veYxx55/MjyUa87un3UiRs++jnDc7lD6il1d2oj6xLUPCVNs+dNw2ukgFt41+VZxWGtsvvw3EdL96PveiKjbpb9jd2P7kCOrF/4+x2/nUf/bcZ6zJG/sB9ZtWMefHQLYCN/GpzFS6bmN6imItyXArtGzXcBrzu+k5mtB9YDnH/++VNQhsj0sEIx/HbQ+NcGEJkuUzHgM9YblhPenbj7Xe6+xt3XdHZ2TkEZIiKtayrCvQtYPmp+GbB7Cl5HREROYirC/XvAKjNbaWZF4D3Axil4HREROYlJH3N395qZ/WfgG2SnQn7W3Z+a7NcREZGTm5Lz3N39fuD+qXhuEREZn35yUEQkhxTuIiI5pHAXEcmhGfGTv2bWDbxwhg8/B3h5EstpBlrn1qB1bg1ns86vcPcxvyg0I8L9bJjZ5pP9nnFeaU9avmwAAAQcSURBVJ1bg9a5NUzVOmtYRkQkhxTuIiI5lIdwv6vRBTSA1rk1aJ1bw5Ssc9OPuYuIyInycOQuIiLHaepwN7N3mdmzZrbdzG5tdD2TxcyWm9mDZvaMmT1lZh8J7QvM7AEz2xbu54d2M7M7wt/hcTO7orFrcGbMLDaz75vZ18L8SjN7NKzvl8MP0WFmpTC/PSxf0ci6z5SZdZjZvWa2NWzr17fANv718G/6STP7kpmV87idzeyzZrbPzJ4c1Xba29bM1oX+28xs3enU0LThPupyflcDFwPvNbOLG1vVpKkBv+nuFwFrgVvCut0KbHL3VcCmMA/Z32BVuK0H7pz+kifFR4BnRs1/Erg9rO9B4ObQfjNw0N1fBdwe+jWjPwe+7u6rgUvJ1j2329jMlgK/Bqxx90vIfljwPeRzO38eeNdxbae1bc1sAfB7ZBc7uhL4vZEdwoR4uBxXs92A1wPfGDX/MeBjja5ritb1PrJr0j4LLA5ti4Fnw/SngfeO6n+kX7PcyH73fxPwVuBrZBd9eRlIjt/eZL84+vownYR+1uh1OM31nQvsOL7unG/jkau0LQjb7WvAO/O6nYEVwJNnum2B9wKfHtV+TL/xbk175M7Yl/Nb2qBapkx4K3o58CiwyN33AIT7c0O3PPwt/gz4bbLrFAMsBA65e7hI6DHrdGR9w/Ke0L+ZXAB0A58LQ1GfMbNZ5Hgbu/uLwJ8AO4E9ZNttC/nezqOd7rY9q23ezOE+ocv5NTMzmw18Bfiou/eequsYbU3ztzCznwH2ufuW0c1jdPUJLGsWCXAFcKe7Xw70c/Rt+liafp3DkMK1wEpgCTCLbEjieHnazhNxsvU8q/Vv5nDP9eX8zKxAFuxfdPd/CM17zWxxWL4Y2Bfam/1v8QbgZ83sR8DfkQ3N/BnQYWYj1xwYvU5H1jcsnwccmM6CJ0EX0OXuj4b5e8nCPq/bGOBtwA5373b3KvAPwE+S7+082ulu27Pa5s0c7rm9nJ+ZGXA38Iy7/+moRRuBkU/M15GNxY+03xg+dV8L9Iy8/WsG7v4xd1/m7ivItuO33P19wIPADaHb8es78ne4IfRvqiM6d38J2GVmF4amq4Cnyek2DnYCa82sPfwbH1nn3G7n45zutv0G8A4zmx/e9bwjtE1Moz90OMsPLK4Bfgg8B/xuo+uZxPV6I9nbr8eBx8LtGrLxxk3AtnC/IPQ3sjOHngOeIDsboeHrcYbr/mbga2H6AuC7wHbg74FSaC+H+e1h+QWNrvsM1/UyYHPYzv8HmJ/3bQz8AbAVeBL4a6CUx+0MfInsc4Uq2RH4zWeybYEPhvXfDtx0OjXoG6oiIjnUzMMyIiJyEgp3EZEcUriLiOSQwl1EJIcU7iIiOaRwFxHJIYW7iEgOKdxFRHLo/wN9mjJ3bmrO9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.02025328994949"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['MEDV'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(boston, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((339, 14), (167, 14))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    X = X.copy()\n",
    "    z = np.abs(stats.zscore(X))\n",
    "    X = X[(z < 3).all(axis=1)]\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = wrangle(train)\n",
    "test = wrangle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'LSTAT', 'MEDV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'PTRATIO', 'B', 'LSTAT']\n",
    "target = ['MEDV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 11.128720459573902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test[target]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Test MSE:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangled data set with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 13)                169       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 13)                182       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 365\n",
      "Trainable params: 365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Input ==> Hidden\n",
    "model.add(Dense(13, input_dim=12, activation='relu'))\n",
    "# Hidden\n",
    "model.add(Dense(13, activation='relu'))\n",
    "# Output Layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "                    optimizer='adam', \n",
    "                    metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s 31us/sample - loss: 9.7651 - mean_squared_error: 9.7651\n",
      "mean_squared_error: 9.76507568359375\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=1000, validation_split=.1, verbose=0)\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(f'{model.metrics_names[1]}: {scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_class = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_class)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00392157, 0.        , 0.        , 0.05098039,\n",
       "       0.28627452, 0.        , 0.        , 0.00392157, 0.01568628,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.14117648, 0.53333336, 0.49803922, 0.24313726,\n",
       "       0.21176471, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01176471, 0.01568628, 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "       0.8       , 0.6901961 , 0.5254902 , 0.5647059 , 0.48235294,\n",
       "       0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.04705882, 0.03921569, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.60784316, 0.9254902 , 0.8117647 ,\n",
       "       0.69803923, 0.41960785, 0.6117647 , 0.6313726 , 0.42745098,\n",
       "       0.2509804 , 0.09019608, 0.3019608 , 0.50980395, 0.28235295,\n",
       "       0.05882353, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.        , 0.27058825,\n",
       "       0.8117647 , 0.8745098 , 0.85490197, 0.84705883, 0.84705883,\n",
       "       0.6392157 , 0.49803922, 0.4745098 , 0.47843137, 0.57254905,\n",
       "       0.5529412 , 0.34509805, 0.6745098 , 0.25882354, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00392157, 0.00392157,\n",
       "       0.00392157, 0.        , 0.78431374, 0.9098039 , 0.9098039 ,\n",
       "       0.9137255 , 0.8980392 , 0.8745098 , 0.8745098 , 0.84313726,\n",
       "       0.8352941 , 0.6431373 , 0.49803922, 0.48235294, 0.76862746,\n",
       "       0.8980392 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.7176471 , 0.88235295, 0.84705883, 0.8745098 , 0.89411765,\n",
       "       0.92156863, 0.8901961 , 0.8784314 , 0.87058824, 0.8784314 ,\n",
       "       0.8666667 , 0.8745098 , 0.9607843 , 0.6784314 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.75686276, 0.89411765,\n",
       "       0.85490197, 0.8352941 , 0.7764706 , 0.7058824 , 0.83137256,\n",
       "       0.8235294 , 0.827451  , 0.8352941 , 0.8745098 , 0.8627451 ,\n",
       "       0.9529412 , 0.7921569 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.01176471, 0.        ,\n",
       "       0.04705882, 0.85882354, 0.8627451 , 0.83137256, 0.85490197,\n",
       "       0.7529412 , 0.6627451 , 0.8901961 , 0.8156863 , 0.85490197,\n",
       "       0.8784314 , 0.83137256, 0.8862745 , 0.77254903, 0.81960785,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.02352941, 0.        , 0.3882353 , 0.95686275,\n",
       "       0.87058824, 0.8627451 , 0.85490197, 0.79607844, 0.7764706 ,\n",
       "       0.8666667 , 0.84313726, 0.8352941 , 0.87058824, 0.8627451 ,\n",
       "       0.9607843 , 0.46666667, 0.654902  , 0.21960784, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.01568628, 0.        ,\n",
       "       0.        , 0.21568628, 0.9254902 , 0.89411765, 0.9019608 ,\n",
       "       0.89411765, 0.9411765 , 0.9098039 , 0.8352941 , 0.85490197,\n",
       "       0.8745098 , 0.91764706, 0.8509804 , 0.8509804 , 0.81960785,\n",
       "       0.36078432, 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.01568628, 0.02352941, 0.02745098, 0.00784314, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.92941177,\n",
       "       0.8862745 , 0.8509804 , 0.8745098 , 0.87058824, 0.85882354,\n",
       "       0.87058824, 0.8666667 , 0.84705883, 0.8745098 , 0.8980392 ,\n",
       "       0.84313726, 0.85490197, 1.        , 0.3019608 , 0.        ,\n",
       "       0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.24313726,\n",
       "       0.5686275 , 0.8       , 0.89411765, 0.8117647 , 0.8352941 ,\n",
       "       0.8666667 , 0.85490197, 0.8156863 , 0.827451  , 0.85490197,\n",
       "       0.8784314 , 0.8745098 , 0.85882354, 0.84313726, 0.8784314 ,\n",
       "       0.95686275, 0.62352943, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.17254902, 0.32156864,\n",
       "       0.41960785, 0.7411765 , 0.89411765, 0.8627451 , 0.87058824,\n",
       "       0.8509804 , 0.8862745 , 0.78431374, 0.8039216 , 0.827451  ,\n",
       "       0.9019608 , 0.8784314 , 0.91764706, 0.6901961 , 0.7372549 ,\n",
       "       0.98039216, 0.972549  , 0.9137255 , 0.93333334, 0.84313726,\n",
       "       0.        , 0.        , 0.22352941, 0.73333335, 0.8156863 ,\n",
       "       0.8784314 , 0.8666667 , 0.8784314 , 0.8156863 , 0.8       ,\n",
       "       0.8392157 , 0.8156863 , 0.81960785, 0.78431374, 0.62352943,\n",
       "       0.9607843 , 0.75686276, 0.80784315, 0.8745098 , 1.        ,\n",
       "       1.        , 0.8666667 , 0.91764706, 0.8666667 , 0.827451  ,\n",
       "       0.8627451 , 0.9098039 , 0.9647059 , 0.        , 0.01176471,\n",
       "       0.7921569 , 0.89411765, 0.8784314 , 0.8666667 , 0.827451  ,\n",
       "       0.827451  , 0.8392157 , 0.8039216 , 0.8039216 , 0.8039216 ,\n",
       "       0.8627451 , 0.9411765 , 0.3137255 , 0.5882353 , 1.        ,\n",
       "       0.8980392 , 0.8666667 , 0.7372549 , 0.6039216 , 0.7490196 ,\n",
       "       0.8235294 , 0.8       , 0.81960785, 0.87058824, 0.89411765,\n",
       "       0.88235295, 0.        , 0.38431373, 0.9137255 , 0.7764706 ,\n",
       "       0.8235294 , 0.87058824, 0.8980392 , 0.8980392 , 0.91764706,\n",
       "       0.9764706 , 0.8627451 , 0.7607843 , 0.84313726, 0.8509804 ,\n",
       "       0.94509804, 0.25490198, 0.28627452, 0.41568628, 0.45882353,\n",
       "       0.65882355, 0.85882354, 0.8666667 , 0.84313726, 0.8509804 ,\n",
       "       0.8745098 , 0.8745098 , 0.8784314 , 0.8980392 , 0.11372549,\n",
       "       0.29411766, 0.8       , 0.83137256, 0.8       , 0.75686276,\n",
       "       0.8039216 , 0.827451  , 0.88235295, 0.84705883, 0.7254902 ,\n",
       "       0.77254903, 0.80784315, 0.7764706 , 0.8352941 , 0.9411765 ,\n",
       "       0.7647059 , 0.8901961 , 0.9607843 , 0.9372549 , 0.8745098 ,\n",
       "       0.85490197, 0.83137256, 0.81960785, 0.87058824, 0.8627451 ,\n",
       "       0.8666667 , 0.9019608 , 0.2627451 , 0.1882353 , 0.79607844,\n",
       "       0.7176471 , 0.7607843 , 0.8352941 , 0.77254903, 0.7254902 ,\n",
       "       0.74509805, 0.7607843 , 0.7529412 , 0.7921569 , 0.8392157 ,\n",
       "       0.85882354, 0.8666667 , 0.8627451 , 0.9254902 , 0.88235295,\n",
       "       0.84705883, 0.78039217, 0.80784315, 0.7294118 , 0.70980394,\n",
       "       0.69411767, 0.6745098 , 0.70980394, 0.8039216 , 0.80784315,\n",
       "       0.4509804 , 0.        , 0.47843137, 0.85882354, 0.75686276,\n",
       "       0.7019608 , 0.67058825, 0.7176471 , 0.76862746, 0.8       ,\n",
       "       0.8235294 , 0.8352941 , 0.8117647 , 0.827451  , 0.8235294 ,\n",
       "       0.78431374, 0.76862746, 0.7607843 , 0.7490196 , 0.7647059 ,\n",
       "       0.7490196 , 0.7764706 , 0.7529412 , 0.6901961 , 0.6117647 ,\n",
       "       0.654902  , 0.69411767, 0.8235294 , 0.36078432, 0.        ,\n",
       "       0.        , 0.2901961 , 0.7411765 , 0.83137256, 0.7490196 ,\n",
       "       0.6862745 , 0.6745098 , 0.6862745 , 0.70980394, 0.7254902 ,\n",
       "       0.7372549 , 0.7411765 , 0.7372549 , 0.75686276, 0.7764706 ,\n",
       "       0.8       , 0.81960785, 0.8235294 , 0.8235294 , 0.827451  ,\n",
       "       0.7372549 , 0.7372549 , 0.7607843 , 0.7529412 , 0.84705883,\n",
       "       0.6666667 , 0.        , 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.25882354, 0.78431374, 0.87058824, 0.92941177,\n",
       "       0.9372549 , 0.9490196 , 0.9647059 , 0.9529412 , 0.95686275,\n",
       "       0.8666667 , 0.8627451 , 0.75686276, 0.7490196 , 0.7019608 ,\n",
       "       0.7137255 , 0.7137255 , 0.70980394, 0.6901961 , 0.6509804 ,\n",
       "       0.65882355, 0.3882353 , 0.22745098, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "       0.28235295, 0.16078432, 0.13725491, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_model = Sequential()\n",
    "mnist_model.add(Dense(16, input_dim=784, activation='relu', name='input_layer'))\n",
    "mnist_model.add(Dense(16, activation='relu', name=\"hidden_layer\"))\n",
    "mnist_model.add(Dense(10,activation='softmax',name=\"output_layer\"))\n",
    "mnist_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "mnist_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mnist_model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=.15, verbose=0)\n",
    "scores = mnist_model.evaluate(X_test, y_test)\n",
    "print(f'{mnist_model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape= X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nchib\\Anaconda3\\envs\\U4-S2-NN\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import skopt\n",
    "from skopt import gbrt_minimize, gp_minimize\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_learning_rate = Real(low=1e-4, high=1e-2, prior='log-uniform',\n",
    "                         name='learning_rate')\n",
    "dim_num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
    "dim_num_input_nodes = Integer(low=1, high=512, name='num_input_nodes')\n",
    "dim_num_dense_nodes = Integer(low=1, high=28, name='num_dense_nodes')\n",
    "dim_activation = Categorical(categories=['relu', 'sigmoid'],\n",
    "                             name='activation')\n",
    "dim_batch_size = Integer(low=1, high=128, name='batch_size')\n",
    "dim_adam_decay = Real(low=1e-6,high=1e-2,name=\"adam_decay\")\n",
    "\n",
    "dimensions = [dim_learning_rate,\n",
    "              dim_num_dense_layers,\n",
    "              dim_num_input_nodes,\n",
    "              dim_num_dense_nodes,\n",
    "              dim_activation,\n",
    "              dim_batch_size,\n",
    "              dim_adam_decay\n",
    "             ]\n",
    "default_parameters = [1e-3, 1,512, 13, 'relu',64, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "def create_model(learning_rate, num_dense_layers,num_input_nodes,\n",
    "                 num_dense_nodes, activation, adam_decay):\n",
    "    #start the model making process and create our first layer\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_input_nodes, input_shape= input_shape, activation=activation\n",
    "                   ))\n",
    "    #create a loop making a new dense layer for the amount passed to this model.\n",
    "    #naming the layers helps avoid tensorflow error deep in the stack trace.\n",
    "    for i in range(num_dense_layers):\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "        model.add(Dense(num_dense_nodes,\n",
    "                 activation=activation,\n",
    "                        name=name\n",
    "                 ))\n",
    "    #add our classification layer.\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    \n",
    "    #setup our optimizer and compile\n",
    "    adam = Adam(lr=learning_rate, decay= adam_decay)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(learning_rate, num_dense_layers, num_input_nodes, \n",
    "            num_dense_nodes,activation, batch_size,adam_decay):\n",
    "\n",
    "    model = create_model(learning_rate=learning_rate,\n",
    "                         num_dense_layers=num_dense_layers,\n",
    "                         num_input_nodes=num_input_nodes,\n",
    "                         num_dense_nodes=num_dense_nodes,\n",
    "                         activation=activation,\n",
    "                         adam_decay=adam_decay\n",
    "                        )\n",
    "    \n",
    "\n",
    "    #named blackbox becuase it represents the structure\n",
    "    blackbox = model.fit(x=X_train,\n",
    "                        y=y_train,\n",
    "                        epochs=3,\n",
    "                        batch_size=batch_size,\n",
    "                        validation_split=0.15,\n",
    "                        )\n",
    "    #return the validation accuracy for the last epoch.\n",
    "    accuracy = blackbox.history['val_acc'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
    "    print()\n",
    "\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    tensorflow.reset_default_graph()\n",
    "    \n",
    "    return -accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_result = gp_minimize(func=fitness,\n",
    "                            dimensions=dimensions,\n",
    "                            n_calls=12,\n",
    "                            noise= 0.01,\n",
    "                            n_jobs=-1,\n",
    "                            kappa = 5,\n",
    "                            x0=default_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy was 89.42%.\n"
     ]
    }
   ],
   "source": [
    "print(\"best accuracy was \" + str(round(gp_result.fun *-100,2))+\"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00020355247427124, 5, 259, 26, 'relu', 124, 0.0023861427015795782]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.87655556, -0.8831111 , -0.88888889, -0.89144445, -0.89288889,\n",
       "       -0.892     , -0.89422222, -0.89277777, -0.89266667, -0.89322223,\n",
       "       -0.89333333, -0.8921111 ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_result.func_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning rate</th>\n",
       "      <th>hidden layers</th>\n",
       "      <th>input layer nodes</th>\n",
       "      <th>hidden layer nodes</th>\n",
       "      <th>activation function</th>\n",
       "      <th>batch size</th>\n",
       "      <th>adam learning rate decay</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>1</td>\n",
       "      <td>512</td>\n",
       "      <td>13</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>87.655556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009031</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>relu</td>\n",
       "      <td>90</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>88.311110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000620</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>relu</td>\n",
       "      <td>107</td>\n",
       "      <td>0.009111</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009706</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>28</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>9</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>89.144445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003193</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>relu</td>\n",
       "      <td>88</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>89.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000104</td>\n",
       "      <td>4</td>\n",
       "      <td>301</td>\n",
       "      <td>15</td>\n",
       "      <td>relu</td>\n",
       "      <td>118</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>89.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000204</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>26</td>\n",
       "      <td>relu</td>\n",
       "      <td>124</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>89.422222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002680</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>relu</td>\n",
       "      <td>26</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>89.277777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002563</td>\n",
       "      <td>3</td>\n",
       "      <td>449</td>\n",
       "      <td>17</td>\n",
       "      <td>relu</td>\n",
       "      <td>116</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>89.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000124</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>5</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>113</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>89.322223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>4</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>relu</td>\n",
       "      <td>126</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>89.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007643</td>\n",
       "      <td>1</td>\n",
       "      <td>498</td>\n",
       "      <td>26</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>10</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>89.211110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning rate  hidden layers  input layer nodes  hidden layer nodes  \\\n",
       "0        0.001000              1                512                  13   \n",
       "1        0.009031              4                 35                  20   \n",
       "2        0.000620              3                 13                  20   \n",
       "3        0.009706              2                424                  28   \n",
       "4        0.003193              1                 34                  27   \n",
       "5        0.000104              4                301                  15   \n",
       "6        0.000204              5                259                  26   \n",
       "7        0.002680              1                 28                   3   \n",
       "8        0.002563              3                449                  17   \n",
       "9        0.000124              3                 75                   5   \n",
       "10       0.000135              4                264                   2   \n",
       "11       0.007643              1                498                  26   \n",
       "\n",
       "   activation function  batch size  adam learning rate decay   accuracy  \n",
       "0                 relu          64                  0.001000  87.655556  \n",
       "1                 relu          90                  0.002593  88.311110  \n",
       "2                 relu         107                  0.009111  88.888889  \n",
       "3              sigmoid           9                  0.004085  89.144445  \n",
       "4                 relu          88                  0.005207  89.288889  \n",
       "5                 relu         118                  0.000516  89.200000  \n",
       "6                 relu         124                  0.002386  89.422222  \n",
       "7                 relu          26                  0.002163  89.277777  \n",
       "8                 relu         116                  0.005452  89.266667  \n",
       "9              sigmoid         113                  0.002328  89.322223  \n",
       "10                relu         126                  0.001544  89.333333  \n",
       "11             sigmoid          10                  0.009997  89.211110  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(gp_result.x_iters, columns = [\"learning rate\",\"hidden layers\",\"input layer nodes\",\"hidden layer nodes\",\n",
    "                                           \"activation function\",\"batch size\",\"adam learning rate decay\"]),\n",
    "(pd.Series(gp_result.func_vals*-100, name=\"accuracy\"))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 259)               203315    \n",
      "_________________________________________________________________\n",
      "layer_dense_1 (Dense)        (None, 26)                6760      \n",
      "_________________________________________________________________\n",
      "layer_dense_2 (Dense)        (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "layer_dense_3 (Dense)        (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "layer_dense_4 (Dense)        (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "layer_dense_5 (Dense)        (None, 26)                702       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                270       \n",
      "=================================================================\n",
      "Total params: 213,153\n",
      "Trainable params: 213,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gp_model = create_model(gp_result.x[0],gp_result.x[1],gp_result.x[2],gp_result.x[3],gp_result.x[4],gp_result.x[5])\n",
    "gp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.2023 - acc: 0.9289\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.2014 - acc: 0.9290\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 0.2007 - acc: 0.9293\n",
      "10000/10000 [==============================] - 0s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3079898268163204, 0.89]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_model.fit(X_train,y_train, epochs=3)\n",
    "gp_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXhU5d3/8feXQED2LexLCIsIyBpQsQguVVxR0YIrqIi4PK3to4+1dtXL2l/1qbZPLZSibXBBinWvdSkKqICQsCMCSdhC2Pc123x/f8zBjllggCST5fO6rlzMnPs+M99zOJnPnHPfMzF3R0REJFKNWBcgIiIVj8JBRESKUDiIiEgRCgcRESlC4SAiIkXUjHUBpaF58+aemJgY6zJERCqVtLS0ne6eUFxblQiHxMREUlNTY12GiEilYmYbSmrTZSURESlC4SAiIkUoHEREpAiFg4iIFKFwEBGRIqIKBzMbbmarzSzdzH5cTHtHM5tpZsvMbJaZtQuW9zWzeWa2MmgbFbHORWa2yMxWmFmKmdUMlo8I+i4xs1Qz+05pbayIiETnhOFgZnHA88DlQA/gJjPrUajbM8BUd+8NPA48FSw/DNzu7j2B4cBzZtbYzGoAKcBod+8FbADGBOvMBPq4e1/gTmDK6WygiIicvGjOHAYB6e6e6e65wGvAiEJ9ehB+UQf49Fi7u69x97XB7WxgO5AANANy3H1NsM7HwMig30H/z/eI1wP0neIiIoWEQs4fZq5lZfa+Mnn8aMKhLbAp4n5WsCzSUoIXd+A6oIGZNYvsYGaDgHggA9gJ1DKz5KD5BqB9RN/rzOxr4J+Ezx6KMLPxwWWn1B07dkSxGSIiVcOR3AIemLaI3328hneXbimT54gmHKyYZYXfzT8EDDWzxcBQYDOQ/80DmLUGXgLucPdQcGYwGnjWzBYAByL7u/ub7t4duBZ4orii3H2yuye7e3JCQrGf/hYRqXK27DvCjX+ey79WbOWxK87ikeFnlsnzRPP1GVlEvKsH2gHZkR2CS0bXA5hZfWCku+8L7jckfAbwU3efH7HOPGBI0OdSoFvhJ3b3OWbW2cyau/vOk9kwEZGqZvHGPYx/KY0juQW8MCaZi7q3LLPniubMYSHQ1cw6mVk84Xf870R2MLPmwSAzwKPAi8HyeOBNwoPVMwqt0yL4tzbwCDApuN/FzCy43Z/wpahdp7Z5IiJVw9tLNjNq8nzq1KrBG/cNLtNggCjOHNw938weAD4E4oAX3X2lmT0OpLr7O8Aw4Ckzc2AOcH+w+veAC4BmZjY2WDbW3ZcAD5vZVYQDaqK7fxK0jwRuN7M84AgwKmKAWkSkWgmFnGf/vYb/+ySdQZ2aMunWATStF1/mz2tV4XU3OTnZ9a2sIlLVHM7N50fTl/LByq2MSm7PE9f2Ir5m6X122czS3D25uLYq8ZXdIiJVTfbeI4xLSeXrrfv52VU9uPP8RIIr7uVC4SAiUsEs2riH8VPTyMkr4IWxA7nwzBblXoPCQUSkAnlzcRaP/GM5rRrWYdrd59C1ZYOY1KFwEBGpAEIh5+mPVjNxVgbnJjVl4i0DaFIOA88lUTiIiMTYoZx8Hpy+hI+/2sZNgzrwq2t6lurA86lQOIiIxFDWnsOMS0llzbYD/OLqHowdXL4DzyVROIiIxEjq+t3c81IauQUh/nbHIC7oVnG+CkjhICISA6+nZfGTN5bTpnEdpowZSJcW9WNd0rcoHEREylFByPntB1/z5zmZDO7cjD/d0p/GdWM38FwShYOISDk5mJPPD6YtZubX27n13A784uqe1IqrmH+tWeEgIlIONu0ODzyn7zjIEyN6ctt5ibEu6bgUDiIiZWzBut1MeDmN/IIQKXcM4jtdm8e6pBNSOIiIlKG/L9zEY28tp32TukwZk0xSQsUaeC6JwkFEpAwUhJyn3l/FlM/XMaRrc/54U38a1a0V67KipnAQESllB47m8f1pi/l09Q7GDk7kp1eeRc0KOvBcEoWDiEgp2rjrMHelLGTdzkM8eV0vbjmnY6xLOiUKBxGRUjI/cxf3vpxGyGHqXYMY3LniDzyXROEgIlIKpi3YyM/eWkHHZnV5YcxAEpvXi3VJp0XhICJyGvILQjz5/ir++sV6hnZL4P9u7kfDOpVn4LkkCgcRkVO0/2geD7y6mDlrdnDn+Z34yRXdK93Ac0kUDiIip2D9zkPclbKQDbsO89T1Z3PToA6xLqlUKRxERE7S3PSd3PvKImoYvDzuHM5NahbrkkqdwkFE5CS8PH8Dv3xnJZ2a1+OFMQPp0KxurEsqEwoHEZEo5BeEeOK9r0iZt4ELz0zgDzf1o0EVGHguicJBROQE9h3O4/5XF/F5+k7uHtKJH19+FnE1Yv+nPMuSwkFE5DgydxxkXEoqm/Yc5rcje/O9ge1jXVK5UDiIiJTg87U7ue+VNGrG1eCVcecyqFPTWJdUbhQOIiLFmDpvPb969yu6JNRnyphk2jetmgPPJVE4iIhEyCsI8at3V/Ly/I1cclYLnhvdj/q1q99LZfXbYhGREuw9nMt9ryxibsYu7hmaxP9c1r3KDzyXROEgIgKkbz/IuJSFZO89yjM39uGGAe1iXVJMKRxEpNqbvWYHD7y6iNo1azBt/DkM6Fh9Bp5LonAQkWrL3fnb3PU88d5XdGvZgCljkmnXpHoNPJdE4SAi1VJeQYifv72SaQs2cmmPljw7qi/1quHAc0m0J0Sk2tlzKJd7X0ljfuZu7hvWmYcuPZMa1XTguSQKBxGpVtZuO8BdKals3X+U50b15dp+bWNdUoWkcBCRauPT1dv5/quLqV0rjtfGn0v/Dk1iXVKFpXAQkSrP3Xnh83X8+v1VdG/VkCljkmnT+IxYl1WhKRxEpErLzQ/xs7dWMD11E8N7tuJ3o/pQN14vfScS1R87NbPhZrbazNLN7MfFtHc0s5lmtszMZplZu2B5XzObZ2Yrg7ZREetcZGaLzGyFmaWYWc1g+S1B32VmNtfM+pTWxopI9bLrYA63TvmS6amb+K+LuvCnW/orGKJ0wnAwszjgeeByoAdwk5n1KNTtGWCqu/cGHgeeCpYfBm53957AcOA5M2tsZjWAFGC0u/cCNgBjgnXWAUODx3oCmHw6Gygi1dPqrQcY8fwXLMnay+9H9+W/NSPppERz5jAISHf3THfPBV4DRhTq0wOYGdz+9Fi7u69x97XB7WxgO5AANANy3H1NsM7HwMig31x33xMsnw9U78+wi8hJm7lqG9f/6Qty8kP8/Z7zGNFXM5JOVjTh0BbYFHE/K1gWaSnBiztwHdDAzL71F7fNbBAQD2QAO4FaZpYcNN8AFPcXNO4C/lVcUWY23sxSzSx1x44dUWyGiFR17s7kORmMm5pKp4R6vPPA+fRt3zjWZVVK0YRDcedhXuj+Q8BQM1sMDAU2A/nfPIBZa+Al4A53D7m7A6OBZ81sAXAgsn+wzoWEw+GR4opy98nunuzuyQkJCVFshohUZTn5BTz8+jJ+/f7XXNGrNTPuGUzrRpqRdKqiGZnJ4tvv6tsB2ZEdgktG1wOYWX1gpLvvC+43BP4J/NTd50esMw8YEvS5FOh2rM3MegNTgMvdfdfJb5aIVCc7D+Yw4aU0Ujfs4QcXd+UHF3fV+MJpiiYcFgJdzawT4TOC0cDNkR3MrDmw291DwKPAi8HyeOBNwoPVMwqt08Ldt5tZbcJnB08GyzsAbwC3RYxJiIgUa9WW/YxLSWXnwRz+eHM/rurdJtYlVQknvKzk7vnAA8CHwCrg7+6+0sweN7Nrgm7DgNVmtgZoSfBCD3wPuAAYa2ZLgp++QdvDZrYKWAa86+6fBMt/TnjA+k9B/9TT30wRqYo+WrmVkRPnkh8KMWPCeQqGUmThy/+VW3JysqemKkNEqgt3Z+LsDJ7+cDW92zZi8u3JtGxYJ9ZlVTpmlubuycW16dMgIlKpHM0r4CdvLOeNxZu5uk8bnr6hN3VqxcW6rCpH4SAilcaOAzmMfymVxRv38qPvduO/LuqCmQaey4LCQUQqhZXZ+7g7JZU9h/OYeEt/Lj+7daxLqtIUDiJS4X2wYis/nL6ExnVrMWPCefRq2yjWJVV5CgcRqbDcnT/NCg88923fmMm3DaCFBp7LhcJBRCqko3kFPPKPZby9JJtr+7bhNyM18FyeFA4iUuFs33+Uu19KY+mmvTx82ZncN6yzBp7LmcJBRCqUFZv3cffUVPYdyePPtw3gsp6tYl1StaRwEJEK41/Lt/DDvy+had14Xp8wmB5tGsa6pGpL4SAiMefu/GFmOs/+ew39OzTmz7clk9CgdqzLqtYUDiISU0fzCnhoxlLeW7aF6/u15dfXn62B5wpA4SAiMbNt/1HunprK8s37eGR4dyYMTdLAcwWhcBCRmFiWtZe7p6Zy4Gg+k29L5rs9Wsa6JImgcBCRcvfu0mwemrGU5vVr8497B3NWaw08VzQKBxEpN6GQ89zMtfxh5lqSOzZh0m0DaF5fA88VkcJBRMrFkdwC/nvGEt5fvpUbBrTjyet6UbumBp4rKoWDiJS5LfuOcPfUVFZm7+exK85i3JBOGniu4BQOIlKmFm/cw/iX0jiSW8ALY5K5qLsGnisDhYOIlJm3l2zm4deX0bJhbV4Zdw7dWjaIdUkSJYWDiJS6UMh59t9r+L9P0hnUqSmTbh1A03rxsS5LToLCQURK1eHcfH40fSkfrNzKqOT2PHFtL+Jr1oh1WXKSFA4iUmqy9x5hXEoqX2/dz8+u6sGd5ydq4LmSUjiISKlYtHEP46emkZNXwAtjB3LhmS1iXZKcBoWDiJy2Nxdn8cg/ltO6UR1eG38OXVpo4LmyUziIyCkLhZynP1rNxFkZnJvUlIm3DKCJBp6rBIWDiJySQzn5PDh9CR9/tY2bz+nAr67pSa04DTxXFQoHETlpWXsOMy4llTXbDvDLq3swZrAGnqsahYOInJTU9bu556U0cgtC/O2OQVzQLSHWJUkZUDiISNReT8viJ28sp22TM5gyJpnOCfVjXZKUEYWDiJxQQcj57Qdf8+c5mZzfpRnP39yfxnU18FyVKRxE5LgO5uTzg2mLmfn1dm49twO/uFoDz9WBwkFESrRpd3jgOX3HQZ4Y0ZPbzkuMdUlSThQOIlKsBet2M+HlNPILQqTcMYjvdG0e65KkHCkcRKSIvy/cxGNvLad9k7pMGZNMkgaeqx2Fg4h8oyDkPPX+KqZ8vo4hXZvzx5v606hurViXJTGgcBARAA4czeP70xbz6eodjB2cyE+vPIuaGniuthQOIsLGXYe5K2Uh63Ye4snrenHLOR1jXZLEmMJBpJqbn7mLe19OI+Qw9a5BDO6sgWeBqM4ZzWy4ma02s3Qz+3Ex7R3NbKaZLTOzWWbWLlje18zmmdnKoG1UxDoXmdkiM1thZilmVjNY3j1YJ8fMHiqtDRWRoqYt2MitU76kab143r7/fAWDfOOE4WBmccDzwOVAD+AmM+tRqNszwFR37w08DjwVLD8M3O7uPYHhwHNm1tjMagApwGh37wVsAMYE6+wGvh88poiUgfyCEL96dyWPvrGc87s05837zyexeb1YlyUVSDRnDoOAdHfPdPdc4DVgRKE+PYCZwe1Pj7W7+xp3Xxvczga2AwlAMyDH3dcE63wMjAz6bXf3hUDeKW+ViJRo/9E87kxJ5a9frOfO8zvxwphkGtbRjCT5tmjCoS2wKeJ+VrAs0lKCF3fgOqCBmTWL7GBmg4B4IAPYCdQys+Sg+Qag/ckUbmbjzSzVzFJ37NhxMquKVFvrdx7iuue/YG76Tn5z/dn8/OoempEkxYrmqCjuS9q90P2HgKFmthgYCmwG8r95ALPWwEvAHe4ecncHRgPPmtkC4EBk/2i4+2R3T3b35IQEfWWwyInMTd/JiOe/YPehXF4edw6jB3WIdUlSgUUzWymLb7+rbwdkR3YILhldD2Bm9YGR7r4vuN8Q+CfwU3efH7HOPGBI0OdSoNupb4aIHM/L8zfwy3dW0ql5PV4YM5AOzerGuiSp4KIJh4VAVzPrRPiMYDRwc2QHM2sO7Hb3EPAo8GKwPB54k/Bg9YxC67Rw9+1mVht4BHjydDdGRL4tvyDEE+99Rcq8DVx4ZgJ/uKkfDTS+IFE4YTi4e76ZPQB8CMQBL7r7SjN7HEh193eAYcBTZubAHOD+YPXvARcAzcxsbLBsrLsvAR42s6sIX9qa6O6fAJhZKyAVaAiEzOxBoIe77y+VLRapJvYdzuP+VxfxefpO7h7SiR9ffhZxNfSnPCU6Fr78X7klJyd7ampqrMsQqTAydxxkXEoqm/Yc5snrzuZ7ySc130OqCTNLc/fk4tr0CWmRKubztTu575U0asbV4NW7z2VgYtNYlySVkMJBpAqZOm89v3r3K7ok1GfKmGTaN9XAs5wahYNIFZAXfOL55fkbueSsFjw3uh/1a+vXW06djh6RSm7v4Vzue2URczN2cc/QJP7nsu4aeJbTpnAQqcTStx9kXMpCsvce5Zkb+3DDgHaxLkmqCIWDSCU1e80OHnh1EbVr1mDa+HMY0FEDz1J6FA4ilYy787e563niva/o1rIBU8Yk066JBp6ldCkcRCqRvIIQP397JdMWbOTSHi15dlRf6mngWcqAjiqRSmLPoVzufSWN+Zm7uW9YZx669ExqaOBZyojCQaQSWLvtAHelpLJ1/1GeG9WXa/sV/tZ8kdKlcBCp4D5dvZ3vv7qY2rXieG38ufTv0CTWJUk1oHAQqaDcnRc+X8ev319F91YNmTImmTaNz4h1WVJNKBxEKqDc/BA/e2sF01M3MbxnK343qg914/XrKuVHR5tIBbPrYA73vryIBet38/2LuvDgJd008CzlTuEgUoGs3nqAu1IWsuNADn+4qR/X9GkT65KkmlI4iFQQM1dt4/vTFlOvdk2m33Mefds3jnVJUo0pHERizN35y2eZPPWvr+nVphF/uT2ZVo3qxLosqeYUDiIxlJNfwGNvruD1tCyuPLs1z9zYhzPi42JdlojCQSRWdh7MYcJLaaRu2MODl3TlBxd3xUwDz1IxKBxEYmDVlv2MS0ll16Ecnr+5P1f2bh3rkkS+ReEgUs4+WrmVB6cvoUGdmsy4ZzBnt2sU65JEilA4iJQTd2fi7Aye/nA1vds2YvLtybRsqIFnqZgUDiLl4GheAT95YzlvLN7M1X3a8PQNvalTSwPPUnEpHETK2I4DOYx/KZXFG/fyo+92478u6qKBZ6nwFA4iZWhl9j7uTkllz+E8Jt7Sn8vP1sCzVA4KB5EysHnvEaZ8lsm0BRtpUjeeGRPOo1dbDTxL5aFwEClFa7cdYNLsTN5eshmAa/q24cfDu9NCA89SySgcREpB2oY9TJyVwb9XbeOMWnHcdl5Hxg1Joq3+/oJUUgoHkVPk7sxavYOJszNYsG43jevW4sFLujLmvESa1IuPdXkip0XhIHKS8gtC/HP5FibOyuDrrQdo06gOP7+qB6MHtdcf5JEqQ0eySJSO5BYwI20Tk+dkkrXnCF1b1Od/b+zDNX3bUCuuRqzLEylVCgeRE9h3OI+p89bzt7nr2XUol/4dGvOLq3tycfcW+gttUmUpHERKsHXfUV74PJNXv9zIodwCLjwzgXuHdWFgYhN9iE2qPIWDSCHp2w8yeU4Gby7eTMjh6t6tuWdoZ85q3TDWpYmUG4WDSGDJpr1MmpXBh19tJT6uBjcP6sC4IUm0b1o31qWJlDuFg1Rr7s5na3cycVYG8zJ30bBOTR64sAtjBifSvH7tWJcnEjMKB6mWCkLO+8u3MGl2Biuz99OyYW1+euVZjB7Ugfq19Wshot8CqVaO5hXwj0VZTJ6TyYZdh0lKqMdvR/ZmRL821K6pr9AWOSaqcDCz4cDvgThgirv/plB7R+BFIAHYDdzq7llm1heYCDQECoAn3X16sM5FwDNAPJAG3OXu+RaeBvJ74ArgMDDW3Red9pZKtbb/aB4vz9/Ai5+vZ+fBHPq0b8yjl5/FpT1aajqqSDFOGA5mFgc8D3wXyAIWmtk77v5VRLdngKnunhK86D8F3Eb4xf12d19rZm2ANDP7ENgPpAAXu/saM3scGAO8AFwOdA1+ziEcLueUzuZKdbN9/1Fe/GI9r8zfwIGcfC7olsCEoUmcl9RM01FFjiOaM4dBQLq7ZwKY2WvACCAyHHoAPwxufwq8BeDua451cPdsM9tO+OyiFpAT0f4x8CjhcBhBOGgcmG9mjc2stbtvOcVtlGpo/c5D/HlOJv9IyyI/FOKKs1szYWhnfW22SJSiCYe2wKaI+1kUfSe/FBhJ+HLQdUADM2vm7ruOdTCzQYQvIWUADtQys2R3TwVuANof5/naAgoHOaHlWfuYNDuDf63YQs24GtyY3I7xFyTRsVm9WJcmUqlEEw7FnXt7ofsPAX80s7HAHGAzkP/NA5i1Bl4Cxrh7KFg2GnjWzGoDH0X0j+b5MLPxwHiADh06RLEZUlW5O3MzdjFpdgafrd1Jg9o1mTC0M2PPT6RFA/0dBZFTEU04ZPGfd/UA7YDsyA7ung1cD2Bm9YGR7r4vuN8Q+CfwU3efH7HOPGBI0OdSoFu0zxesPxmYDJCcnFwkPKTqKwg5H63cysTZGSzL2kdCg9r8+PLu3HxOBxrWqRXr8kQqtWjCYSHQ1cw6ET4jGA3cHNnBzJoDu4OzgkcJz1zCzOKBNwmPIcwotE4Ld98enDk8AjwZNL0DPBCMbZwD7NN4g0TKyS/gzUWbmTwnk8ydh0hsVpdfX3c21/dvS51amo4qUhpOGA7B9NIHgA8JT2V90d1XBjOMUt39HWAY8JSZOeHLSvcHq38PuABoFlxygvDU1CXAw2Z2FVADmOjunwTt7xOexppOeLbTHae/mVIVHDiax7QFG5ny2Tq2H8ihV9uGPH9zf4b3akWcpqOKlCoLTwqq3JKTkz01NTXWZUgZ2XEgh7/NXcdL8zaw/2g+53dpxr1Du3B+F01HFTkdZpbm7snFtekT0lJhbdx1mL98lsnfUzeRWxDi8l6tmDC0M73bNY51aSJVnsJBKpyvsvczaXYG7y3LpmaNGlzfvy3jL0giKaF+rEsTqTYUDlIhuDtfrtvNxFkZzF6zg3rxcdw9JIk7v9OJlg01HVWkvCkcJKZCIefjVduYNDuDxRv30rx+PA9fdia3ntORRnU1HVUkVhQOEhO5+SHeXrKZSbMzyNhxiPZNz+CJa3tx44B2mo4qUgEoHKRcHcrJZ9qCjbzw+Tq27DvKWa0b8oeb+nFFr1bUjKsR6/JEJKBwkHKx+1Auf5u7npS569l3JI9zk5ry1PVnM7RbgqajilRACgcpU1l7DjPls3W8tnAjR/NCXNqjJROGdaZ/hyaxLk1EjkPhIGVi9dYD/Hl2Bm8vzcaA6/q15Z6hSXRp0SDWpYlIFBQOUqpS14eno878ejt14+MYOziRu77TiTaNz4h1aSJyEhQOctpCIefT1duZOCuD1A17aFK3Fj/6bjduP68jjevGx7o8ETkFCgc5ZXkFId5bls2kWZms3naAto3P4JdX9+B7A9tTN16Hlkhlpt9gOWlHcguYvnAjf/lsHZv3HuHMlg14dlQfrurdhlqajipSJSgcJGp7D+eSMncDKfPWs/tQLgMTm/DEtT258MwWmo4qUsUoHOSEsvce4YXP1zFtwUYO5xZwcfcWTBjWmYGJTWNdmoiUEYWDlCh9+wEmzc7krcWbcWBEnzbcM7QzZ7bSdFSRqk7hIEUs2riHSbMy+OirbdSpVYNbz+3IuCGdaNekbqxLE5FyonAQIPyV2bPX7GDirAy+XLebRmfU4vsXd2Xs4ESa1tN0VJHqRuFQzeUXhPjn8i1Mmp3Jqi37ad2oDj+7qgejB7anXm0dHiLVlX77q6mjeQXMSMti8pwMNu0+QpcW9Xn6ht6M6NuW+JqajipS3Skcqpl9R/J4ef4G/vrFOnYezKVfh8b87MoeXHJWS2rU0HRUEQlTOFQT2/Yf5YXP1/Hqlxs5mJPPsDMTuHdoZwZ1aqrPKIhIEQqHKi5zx0Emz8nkjUWbyQ+FuKp3GyYM7UyPNg1jXZqIVGAKhypq6aa9TJqdwQcrtxIfV4NRA9tz95AkOjTTdFQROTGFQxXi7nyevpNJszP4In0XDerU5L5hnRk7uBMJDWrHujwRqUQUDlVAQcj5YMVWJs5OZ8Xm/bRoUJufXNGdmwZ1oEGdWrEuT0QqIYVDJXY0r4A3Fm1m8pwM1u86TFLzevy/kWdzbb+21K4ZF+vyRKQSUzhUQvuP5vHqlxt54fN17DiQQ+92jZh4S38u7dmKOE1HFZFSoHCoRLYfOMpfv1jPy/M2cCAnnyFdm/P7UX05r3MzTUcVkVKlcKgE1u88xOTPMnk9LYv8ghCXn92aCRd05ux2jWJdmohUUQqHCmzF5n1Mmp3B+8u3ULNGDUYOaMf4C5Lo1LxerEsTkSpO4VDBuDvzMncxcVYGn63dSYPaNRl/QWfuPD+RFg3rxLo8EakmFA4VRCjkfPTVVibOzmTppr00r1+bR4Z355ZzO9BQ01FFpJwpHGIsJ7+AtxdnM2lOBpk7DtGxWV2evK4XI/u3o04tTUcVkdhQOMTIwZx8pn25kSmfZ7Jtfw492zTkjzf34/JerTUdVURiTuFQznYezOFvX6xn6rz17D+az+DOzXj6hj4M6dpc01FFpMJQOJSTTbsP85fPMpm+cBO5BSEu69GKCcM607d941iXJiJShMKhjK3asp9JszN4b9kWahhc368d44cm0TmhfqxLExEpkcKhDLg7C9fvYeKsdD5dvYN68XHceX4id30niVaNNB1VRCq+qMLBzIYDvwfigCnu/ptC7R2BF4EEYDdwq7tnmVlfYCLQECgAnnT36cE6FwNPAzWAg8BYd08v6bFOe0vLQSjkzPx6OxNnpbNo416a1YvnoUu7cdu5iTSqq+moIlJ5mLsfv4NZHLAG+C6QBSwEbnL3ryL6zADec/cUM7sIuMPdbzOzboC7+1ozawOkAWe5+14zWwOMcPdVZnYfMMjdx5b0WMerMTk52VNTU095J5yuvIIQby/J5s+zM1i7/SDtmpzB+AuSuHFAe86I13RUEamYzCzN3T3hpJMAAAiKSURBVJOLa4vmzGEQkO7umcGDvQaMAL6K6NMD+GFw+1PgLQB3X3Osg7tnm9l2wmcEewEnfEYB0AjIPt5jVUSHc/N5bcEmpnyWSfa+o3Rv1YDfj+7LlWe3pmZcjViXJyJyyqIJh7bApoj7WcA5hfosBUYSvvR0HdDAzJq5+65jHcxsEBAPZASLxgHvm9kRYD9wbrSPFTzeeGA8QIcOHaLYjNKz+1AuKXPXkzJvPXsP5zGoU1OevO5shp2ZoOmoIlIlRBMOxb3aFb4W9RDwRzMbC8wBNgP53zyAWWvgJWCMu4eCxT8ErnD3L83sYeB3hAPjuI/1TQHuk4HJEL6sFMV2nLbNe48w5bNMXluwiSN5BVxyVkvuHZbEgI5Ny+PpRUTKTTThkAW0j7jfjv9cAgLCl4yA6wHMrD4w0t33BfcbAv8Efuru84NlCUAfd/8yeIjpwAcneqxYWbPtAJNmZ/DOkvBmj+jblglDk+jaskEsyxIRKTPRhMNCoKuZdSL8Ln40cHNkBzNrDuwOzgoeJTzbCDOLB94Eprr7jIhV9gCNzKxbMC7xXWDV8R4rFtI27GbirAz+vWo7Z9SK4/bzErlrSCfaNj4jViWJiJSLE4aDu+eb2QPAh4Snsr7o7ivN7HEg1d3fAYYBT5mZE74UdH+w+veAC4BmwWUiCE9ZXWJmdwP/MLMQ4bC4M2gv6bHKhbvz6ertTJqVyYL1u2lStxYPXtKVMecl0qRefHmWIiISMyecyloZlMZU1vyCEO8t28Kk2Rl8vfUAbRrV4e4Lkhg1sD114/VZQRGpek53KmuVdiS3gL+nbuIvn2WStecI3VrW539v7MM1fdtQS9NRRaSaqtbh8MnX23hoxjJ2H8plQMcm/PLqnlzUvQU19JXZIlLNVetwSGxWj77tG3PvsM4MTNR0VBGRY6p1OCQl1OfFsQNjXYaISIWji+oiIlKEwkFERIpQOIiISBEKBxERKULhICIiRSgcRESkCIWDiIgUoXAQEZEiqsQX75nZDmDDKa7eHNhZiuWUlopaF1Tc2lTXyVFdJ6cq1tXR3ROKa6gS4XA6zCy1pG8ljKWKWhdU3NpU18lRXSenutWly0oiIlKEwkFERIpQOMDkWBdQgopaF1Tc2lTXyVFdJ6da1VXtxxxERKQonTmIiEgRCgcRESmiSoeDmQ03s9Vmlm5mPy6mvbaZTQ/avzSzxIi2R4Plq83ssnKu60dm9pWZLTOzmWbWMaKtwMyWBD/vlHNdY81sR8Tzj4toG2Nma4OfMeVc17MRNa0xs70RbWW5v140s+1mtqKEdjOzPwR1LzOz/hFtZbm/TlTXLUE9y8xsrpn1iWhbb2bLg/2VWs51DTOzfRH/Xz+PaDvuMVDGdT0cUdOK4JhqGrSVyf4ys/Zm9qmZrTKzlWb2g2L6lO3x5e5V8geIAzKAJCAeWAr0KNTnPmBScHs0MD243SPoXxvoFDxOXDnWdSFQN7h977G6gvsHY7i/xgJ/LGbdpkBm8G+T4HaT8qqrUP//Al4s6/0VPPYFQH9gRQntVwD/Agw4F/iyrPdXlHUNPvZ8wOXH6grurweax2h/DQPeO91joLTrKtT3auCTst5fQGugf3C7AbCmmN/HMj2+qvKZwyAg3d0z3T0XeA0YUajPCCAluP06cLGZWbD8NXfPcfd1QHrweOVSl7t/6u6Hg7vzgXal9NynVddxXAZ87O673X0P8DEwPEZ13QRMK6XnPi53nwPsPk6XEcBUD5sPNDaz1pTt/jphXe4+N3heKL/jK5r9VZLTOTZLu65yOb7cfYu7LwpuHwBWAW0LdSvT46sqh0NbYFPE/SyK7txv+rh7PrAPaBblumVZV6S7CL87OKaOmaWa2Xwzu7aUajqZukYGp7Cvm1n7k1y3LOsiuPzWCfgkYnFZ7a9olFR7We6vk1X4+HLgIzNLM7PxMajnPDNbamb/MrOewbIKsb/MrC7hF9l/RCwu8/1l4cvd/YAvCzWV6fFV82RXqESsmGWF5+2W1CeadU9V1I9tZrcCycDQiMUd3D3bzJKAT8xsubtnlFNd7wLT3D3HzCYQPuu6KMp1y7KuY0YDr7t7QcSystpf0YjF8RU1M7uQcDh8J2Lx+cH+agF8bGZfB++sy8Miwt/1c9DMrgDeArpSQfYX4UtKX7h75FlGme4vM6tPOIwedPf9hZuLWaXUjq+qfOaQBbSPuN8OyC6pj5nVBBoRPr2MZt2yrAszuwR4DLjG3XOOLXf37ODfTGAW4XcU5VKXu++KqOUvwIBo1y3LuiKMptApfxnur2iUVHtZ7q+omFlvYAowwt13HVsesb+2A29SepdTT8jd97v7weD2+0AtM2tOBdhfgeMdX6W+v8ysFuFgeMXd3yimS9keX6U9kFJRfgifFWUSvsxwbBCrZ6E+9/PtAem/B7d78u0B6UxKb0A6mrr6ER6A61poeROgdnC7ObCWUhqYi7Ku1hG3rwPm+38GwNYF9TUJbjctr7qCfmcSHhy08thfEc+RSMkDrFfy7QHDBWW9v6KsqwPhcbTBhZbXAxpE3J4LDC/Hulod+/8j/CK7Mdh3UR0DZVVX0H7sjWO98thfwXZPBZ47Tp8yPb5KbedWxB/Co/lrCL/QPhYse5zwu3GAOsCM4BdlAZAUse5jwXqrgcvLua5/A9uAJcHPO8HywcDy4JdjOXBXOdf1FLAyeP5Pge4R694Z7Md04I7yrCu4/0vgN4XWK+v9NQ3YAuQRfrd2FzABmBC0G/B8UPdyILmc9teJ6poC7Ik4vlKD5UnBvloa/D8/Vs51PRBxfM0nIryKOwbKq66gz1jCk1Qi1yuz/UX4Up8DyyL+n64oz+NLX58hIiJFVOUxBxEROUUKBxERKULhICIiRSgcRESkCIWDiIgUoXAQEZEiFA4iIlLE/wf+tczVKv3/wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gp_model.history.history['acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tensorflow.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (Dense)          (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "hidden_layer (Dense)         (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "10000/10000 [==============================] - 0s 19us/sample - loss: 0.4008 - acc: 0.8596\n",
      "acc: 85.96000075340271\n"
     ]
    }
   ],
   "source": [
    "mnist_model = Sequential()\n",
    "mnist_model.add(Dense(16, input_dim=784, activation='relu', name='input_layer'))\n",
    "mnist_model.add(Dense(16, activation='relu', name=\"hidden_layer\"))\n",
    "mnist_model.add(Dense(10,activation='softmax',name=\"output_layer\"))\n",
    "mnist_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "mnist_model.summary()\n",
    "\n",
    "history = mnist_model.fit(X_train, y_train, batch_size=128, epochs=10, validation_split=.15, verbose=0)\n",
    "scores = mnist_model.evaluate(X_test, y_test)\n",
    "print(f'{mnist_model.metrics_names[1]}: {scores[1]*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 23.3min\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 45.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 30us/sample - loss: 0.9782 - acc: 0.6718\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.4541 - acc: 0.8388\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.3894 - acc: 0.8604\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.3567 - acc: 0.8719\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.3377 - acc: 0.8788\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.3204 - acc: 0.8842\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.3064 - acc: 0.8895\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2952 - acc: 0.8925\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2840 - acc: 0.8973\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2767 - acc: 0.8989\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2700 - acc: 0.9012\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2594 - acc: 0.9058\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2508 - acc: 0.9080\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2445 - acc: 0.9104\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2368 - acc: 0.9129\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2306 - acc: 0.9156\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2222 - acc: 0.9186\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2185 - acc: 0.9194\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2127 - acc: 0.9213\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.2056 - acc: 0.9246\n",
      "Best: 0.889783 using {'num_input_nodes': 200, 'num_dense_nodes': 100, 'num_dense_layers': 2, 'epochs': 20, 'batch_size': 150, 'activation': 'sigmoid'}\n",
      "0.888733 (0.003753) with: {'num_input_nodes': 200, 'num_dense_nodes': 20, 'num_dense_layers': 5, 'epochs': 100, 'batch_size': 150, 'activation': 'relu'}\n",
      "0.861467 (0.004921) with: {'num_input_nodes': 50, 'num_dense_nodes': 100, 'num_dense_layers': 1, 'epochs': 3, 'batch_size': 150, 'activation': 'relu'}\n",
      "0.830900 (0.013119) with: {'num_input_nodes': 50, 'num_dense_nodes': 70, 'num_dense_layers': 2, 'epochs': 3, 'batch_size': 150, 'activation': 'sigmoid'}\n",
      "0.882183 (0.007087) with: {'num_input_nodes': 150, 'num_dense_nodes': 70, 'num_dense_layers': 3, 'epochs': 100, 'batch_size': 200, 'activation': 'sigmoid'}\n",
      "0.403250 (0.079535) with: {'num_input_nodes': 100, 'num_dense_nodes': 1, 'num_dense_layers': 2, 'epochs': 3, 'batch_size': 1, 'activation': 'sigmoid'}\n",
      "0.888817 (0.003719) with: {'num_input_nodes': 150, 'num_dense_nodes': 20, 'num_dense_layers': 5, 'epochs': 100, 'batch_size': 200, 'activation': 'relu'}\n",
      "0.866217 (0.003557) with: {'num_input_nodes': 50, 'num_dense_nodes': 70, 'num_dense_layers': 1, 'epochs': 3, 'batch_size': 1, 'activation': 'sigmoid'}\n",
      "0.874033 (0.004968) with: {'num_input_nodes': 100, 'num_dense_nodes': 100, 'num_dense_layers': 5, 'epochs': 100, 'batch_size': 200, 'activation': 'sigmoid'}\n",
      "0.860200 (0.006553) with: {'num_input_nodes': 50, 'num_dense_nodes': 50, 'num_dense_layers': 2, 'epochs': 3, 'batch_size': 100, 'activation': 'relu'}\n",
      "0.879883 (0.004842) with: {'num_input_nodes': 100, 'num_dense_nodes': 100, 'num_dense_layers': 3, 'epochs': 100, 'batch_size': 150, 'activation': 'sigmoid'}\n",
      "0.197267 (0.125097) with: {'num_input_nodes': 200, 'num_dense_nodes': 1, 'num_dense_layers': 1, 'epochs': 3, 'batch_size': 100, 'activation': 'relu'}\n",
      "0.187617 (0.175493) with: {'num_input_nodes': 200, 'num_dense_nodes': 1, 'num_dense_layers': 1, 'epochs': 3, 'batch_size': 1, 'activation': 'relu'}\n",
      "0.889783 (0.002854) with: {'num_input_nodes': 200, 'num_dense_nodes': 100, 'num_dense_layers': 2, 'epochs': 20, 'batch_size': 150, 'activation': 'sigmoid'}\n",
      "0.540550 (0.026396) with: {'num_input_nodes': 1, 'num_dense_nodes': 50, 'num_dense_layers': 3, 'epochs': 20, 'batch_size': 50, 'activation': 'sigmoid'}\n",
      "0.864467 (0.004562) with: {'num_input_nodes': 100, 'num_dense_nodes': 70, 'num_dense_layers': 4, 'epochs': 3, 'batch_size': 200, 'activation': 'relu'}\n",
      "0.227983 (0.049811) with: {'num_input_nodes': 50, 'num_dense_nodes': 1, 'num_dense_layers': 3, 'epochs': 20, 'batch_size': 150, 'activation': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "# Create model for KerasClassifier\n",
    "def create_model(num_dense_layers=1,\n",
    "                 num_input_nodes=512,\n",
    "                 num_dense_nodes=13,\n",
    "                 activation='relu',\n",
    "                 batch_size=64,\n",
    "                 epochs=3):\n",
    "    #start the model making process and create our first layer\n",
    "    mmodel = Sequential()\n",
    "    mmodel.add(Dense(num_input_nodes, input_dim=784, activation=activation, name='input_layer'))\n",
    "    for i in range(num_dense_layers):\n",
    "        name = 'layer_dense_{0}'.format(i+1)\n",
    "        mmodel.add(Dense(num_dense_nodes,\n",
    "                 activation=activation,\n",
    "                        name=name\n",
    "                 ))\n",
    "    mmodel.add(Dense(10, activation='softmax',name=\"output_layer\"))\n",
    "    mmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return mmodel\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model) \n",
    "\n",
    "# Specify parameters and distributions to sample from\n",
    "\n",
    "num_dense_layers = [1,2,3,4,5]\n",
    "num_input_nodes = [1,50,100,150,200]\n",
    "num_dense_nodes = [1,20,50,70,100]\n",
    "activation = ['relu', 'sigmoid']\n",
    "batch_size = [1,50,100,150,200]\n",
    "epochs = [3,20,100]\n",
    "\n",
    "# Prepare the Dict for the Search\n",
    "param_dist = dict(num_dense_layers=num_dense_layers,\n",
    "                  num_input_nodes=num_input_nodes,\n",
    "                  num_dense_nodes=num_dense_nodes,\n",
    "                  activation=activation,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs)\n",
    "\n",
    "# Search in action!\n",
    "n_iter_search = 16 # Number of parameter settings that are sampled.\n",
    "random_search = RandomizedSearchCV(estimator=model, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1, cv=5, verbose=2)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "print(\"Best: %f using %s\" % (random_search.best_score_, random_search.best_params_))\n",
    "means = random_search.cv_results_['mean_test_score']\n",
    "stds = random_search.cv_results_['std_test_score']\n",
    "params = random_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NN (Python3)",
   "language": "python",
   "name": "u4-s2-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
