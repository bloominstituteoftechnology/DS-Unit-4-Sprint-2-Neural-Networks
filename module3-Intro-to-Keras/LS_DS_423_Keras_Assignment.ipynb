{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignmnet 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"amesHousePrice.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "0   1          60       RL     8450   Pave      Reg         Lvl    AllPub   \n",
       "1   2          20       RL     9600   Pave      Reg         Lvl    AllPub   \n",
       "2   3          60       RL    11250   Pave      IR1         Lvl    AllPub   \n",
       "3   4          70       RL     9550   Pave      IR1         Lvl    AllPub   \n",
       "4   5          60       RL    14260   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "  LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch PoolArea  \\\n",
       "0    Inside       Gtl  ...             0         0           0        0   \n",
       "1       FR2       Gtl  ...             0         0           0        0   \n",
       "2    Inside       Gtl  ...             0         0           0        0   \n",
       "3    Corner       Gtl  ...           272         0           0        0   \n",
       "4       FR2       Gtl  ...             0         0           0        0   \n",
       "\n",
       "  MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0       0       2    2008        WD         Normal    208500  \n",
       "1       0       5    2007        WD         Normal    181500  \n",
       "2       0       9    2008        WD         Normal    223500  \n",
       "3       0       2    2006        WD        Abnorml    140000  \n",
       "4       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.57142857e-01, 7.50000000e-01, ...,\n",
       "        5.00000000e-01, 1.00000000e+00, 8.00000000e-01],\n",
       "       [6.85400960e-04, 0.00000000e+00, 7.50000000e-01, ...,\n",
       "        2.50000000e-01, 1.00000000e+00, 8.00000000e-01],\n",
       "       [1.37080192e-03, 3.57142857e-01, 7.50000000e-01, ...,\n",
       "        5.00000000e-01, 1.00000000e+00, 8.00000000e-01],\n",
       "       ...,\n",
       "       [9.98629198e-01, 4.28571429e-01, 7.50000000e-01, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 8.00000000e-01],\n",
       "       [9.99314599e-01, 0.00000000e+00, 7.50000000e-01, ...,\n",
       "        1.00000000e+00, 1.00000000e+00, 8.00000000e-01],\n",
       "       [1.00000000e+00, 0.00000000e+00, 7.50000000e-01, ...,\n",
       "        5.00000000e-01, 1.00000000e+00, 8.00000000e-01]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "X = df.drop(columns='SalePrice')\n",
    "y = df['SalePrice']\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "#X = X.fillna('unkown')\n",
    "X = encoder.fit_transform(X)\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "#X.head()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 61)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1460/1460 [==============================] - 0s 247us/sample - loss: -294259.2653 - mean_absolute_error: 180920.3750\n",
      "Epoch 2/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -523360.8346 - mean_absolute_error: 180920.2656\n",
      "Epoch 3/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -752114.8366 - mean_absolute_error: 180920.2188\n",
      "Epoch 4/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -980676.1777 - mean_absolute_error: 180920.1719\n",
      "Epoch 5/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -1209365.6935 - mean_absolute_error: 180920.2031\n",
      "Epoch 6/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -1438197.5955 - mean_absolute_error: 180920.2188\n",
      "Epoch 7/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -1667166.7887 - mean_absolute_error: 180920.2031\n",
      "Epoch 8/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -1895922.4298 - mean_absolute_error: 180920.2031\n",
      "Epoch 9/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -2124485.4801 - mean_absolute_error: 180920.2188\n",
      "Epoch 10/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -2353722.1993 - mean_absolute_error: 180920.1875\n",
      "Epoch 11/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -2582873.8774 - mean_absolute_error: 180920.2344\n",
      "Epoch 12/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -2811773.6493 - mean_absolute_error: 180920.1875\n",
      "Epoch 13/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -3041177.6281 - mean_absolute_error: 180920.1875\n",
      "Epoch 14/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -3270230.6959 - mean_absolute_error: 180920.1719\n",
      "Epoch 15/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -3499077.9616 - mean_absolute_error: 180920.2031\n",
      "Epoch 16/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -3728375.9890 - mean_absolute_error: 180920.2031\n",
      "Epoch 17/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -3957164.9979 - mean_absolute_error: 180920.1719\n",
      "Epoch 18/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -4185957.7699 - mean_absolute_error: 180920.2031\n",
      "Epoch 19/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -4415176.2301 - mean_absolute_error: 180920.2031\n",
      "Epoch 20/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -4643702.2356 - mean_absolute_error: 180920.2031\n",
      "Epoch 21/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -4873074.5452 - mean_absolute_error: 180920.1875\n",
      "Epoch 22/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -5101623.7041 - mean_absolute_error: 180920.2031\n",
      "Epoch 23/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -5330918.8438 - mean_absolute_error: 180920.2031\n",
      "Epoch 24/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -5559992.4548 - mean_absolute_error: 180920.1875\n",
      "Epoch 25/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -5788955.9137 - mean_absolute_error: 180920.2188\n",
      "Epoch 26/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -6017991.2014 - mean_absolute_error: 180920.2031\n",
      "Epoch 27/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -6246621.2082 - mean_absolute_error: 180920.1719\n",
      "Epoch 28/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -6475587.2466 - mean_absolute_error: 180920.2031\n",
      "Epoch 29/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -6705403.3041 - mean_absolute_error: 180920.1719\n",
      "Epoch 30/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -6934022.0384 - mean_absolute_error: 180920.1719\n",
      "Epoch 31/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -7163390.1068 - mean_absolute_error: 180920.2031\n",
      "Epoch 32/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -7392378.5671 - mean_absolute_error: 180920.2031\n",
      "Epoch 33/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -7621020.4822 - mean_absolute_error: 180920.1875\n",
      "Epoch 34/150\n",
      "1460/1460 [==============================] - 0s 53us/sample - loss: -7850082.6137 - mean_absolute_error: 180920.2031\n",
      "Epoch 35/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -8079156.7452 - mean_absolute_error: 180920.1719\n",
      "Epoch 36/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -8308595.3260 - mean_absolute_error: 180920.1875\n",
      "Epoch 37/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -8536704.6630 - mean_absolute_error: 180920.2031\n",
      "Epoch 38/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -8766253.4740 - mean_absolute_error: 180920.1875\n",
      "Epoch 39/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -8995151.5014 - mean_absolute_error: 180920.2031\n",
      "Epoch 40/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -9223885.6548 - mean_absolute_error: 180920.1719\n",
      "Epoch 41/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -9452867.4219 - mean_absolute_error: 180920.2031\n",
      "Epoch 42/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -9681843.5863 - mean_absolute_error: 180920.2031\n",
      "Epoch 43/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -9910208.3384 - mean_absolute_error: 180920.1875\n",
      "Epoch 44/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -10139312.3945 - mean_absolute_error: 180920.2344\n",
      "Epoch 45/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -10368260.3507 - mean_absolute_error: 180920.1875\n",
      "Epoch 46/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -10596765.1014 - mean_absolute_error: 180920.2344\n",
      "Epoch 47/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -10825805.2740 - mean_absolute_error: 180920.2031\n",
      "Epoch 48/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -11054658.8685 - mean_absolute_error: 180920.1875\n",
      "Epoch 49/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -11283602.6247 - mean_absolute_error: 180920.1875\n",
      "Epoch 50/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -11512065.5836 - mean_absolute_error: 180920.2031\n",
      "Epoch 51/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -11740869.0822 - mean_absolute_error: 180920.1875\n",
      "Epoch 52/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -11969250.3671 - mean_absolute_error: 180920.1719\n",
      "Epoch 53/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -12198768.7260 - mean_absolute_error: 180920.2031\n",
      "Epoch 54/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -12426974.2000 - mean_absolute_error: 180920.2031\n",
      "Epoch 55/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -12656354.9808 - mean_absolute_error: 180920.1875\n",
      "Epoch 56/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -12884846.6904 - mean_absolute_error: 180920.2188\n",
      "Epoch 57/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -13114593.3589 - mean_absolute_error: 180920.1719\n",
      "Epoch 58/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -13342606.3890 - mean_absolute_error: 180920.2031\n",
      "Epoch 59/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -13572116.1699 - mean_absolute_error: 180920.1875\n",
      "Epoch 60/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -13800519.6795 - mean_absolute_error: 180920.2031\n",
      "Epoch 61/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -14029142.6849 - mean_absolute_error: 180920.2031\n",
      "Epoch 62/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -14258419.1315 - mean_absolute_error: 180920.2031\n",
      "Epoch 63/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -14486800.1699 - mean_absolute_error: 180920.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -14716094.9589 - mean_absolute_error: 180920.2031\n",
      "Epoch 65/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -14944962.8904 - mean_absolute_error: 180920.2031\n",
      "Epoch 66/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -15173750.8000 - mean_absolute_error: 180920.2031\n",
      "Epoch 67/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -15402349.9589 - mean_absolute_error: 180920.1875\n",
      "Epoch 68/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -15631501.1479 - mean_absolute_error: 180920.2031\n",
      "Epoch 69/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -15859953.8411 - mean_absolute_error: 180920.1719\n",
      "Epoch 70/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -16088606.2466 - mean_absolute_error: 180920.2031\n",
      "Epoch 71/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -16317414.2849 - mean_absolute_error: 180920.2031\n",
      "Epoch 72/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -16545875.9507 - mean_absolute_error: 180920.2031\n",
      "Epoch 73/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -16774902.1205 - mean_absolute_error: 180920.1875\n",
      "Epoch 74/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -17003978.8712 - mean_absolute_error: 180920.2031\n",
      "Epoch 75/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -17232048.8137 - mean_absolute_error: 180920.2031\n",
      "Epoch 76/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -17461260.4164 - mean_absolute_error: 180920.2031\n",
      "Epoch 77/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -17689378.6110 - mean_absolute_error: 180920.1875\n",
      "Epoch 78/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -17918967.7699 - mean_absolute_error: 180920.2031\n",
      "Epoch 79/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -18147392.6247 - mean_absolute_error: 180920.2031\n",
      "Epoch 80/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -18376882.2027 - mean_absolute_error: 180920.2031\n",
      "Epoch 81/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -18605871.0082 - mean_absolute_error: 180920.1875\n",
      "Epoch 82/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -18834807.7918 - mean_absolute_error: 180920.1719\n",
      "Epoch 83/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -19063745.5616 - mean_absolute_error: 180920.2031\n",
      "Epoch 84/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -19292353.3534 - mean_absolute_error: 180920.2031\n",
      "Epoch 85/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -19520780.5644 - mean_absolute_error: 180920.2031\n",
      "Epoch 86/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -19749327.3096 - mean_absolute_error: 180920.1719\n",
      "Epoch 87/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -19978379.9123 - mean_absolute_error: 180920.2031\n",
      "Epoch 88/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -20207327.9342 - mean_absolute_error: 180920.2031\n",
      "Epoch 89/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -20436327.1068 - mean_absolute_error: 180920.2031\n",
      "Epoch 90/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -20665344.7671 - mean_absolute_error: 180920.1719\n",
      "Epoch 91/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -20894034.6795 - mean_absolute_error: 180920.2031\n",
      "Epoch 92/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -21122700.6795 - mean_absolute_error: 180920.1719\n",
      "Epoch 93/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -21352254.4548 - mean_absolute_error: 180920.1562\n",
      "Epoch 94/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -21580126.1808 - mean_absolute_error: 180920.1875\n",
      "Epoch 95/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -21809389.4630 - mean_absolute_error: 180920.1875\n",
      "Epoch 96/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -22038410.6904 - mean_absolute_error: 180920.2031\n",
      "Epoch 97/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -22267462.8384 - mean_absolute_error: 180920.2031\n",
      "Epoch 98/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -22496614.9644 - mean_absolute_error: 180920.2031\n",
      "Epoch 99/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -22725307.3151 - mean_absolute_error: 180920.2188\n",
      "Epoch 100/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -22954143.2548 - mean_absolute_error: 180920.2031\n",
      "Epoch 101/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -23183536.0384 - mean_absolute_error: 180920.2188\n",
      "Epoch 102/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -23411701.6384 - mean_absolute_error: 180920.2031\n",
      "Epoch 103/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -23641344.8658 - mean_absolute_error: 180920.1719\n",
      "Epoch 104/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -23869705.9616 - mean_absolute_error: 180920.2031\n",
      "Epoch 105/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -24098590.4000 - mean_absolute_error: 180920.2188\n",
      "Epoch 106/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -24327168.2027 - mean_absolute_error: 180920.1719\n",
      "Epoch 107/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -24556084.1699 - mean_absolute_error: 180920.2344\n",
      "Epoch 108/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -24784971.8356 - mean_absolute_error: 180920.1875\n",
      "Epoch 109/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -25013398.6904 - mean_absolute_error: 180920.1719\n",
      "Epoch 110/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -25242601.0630 - mean_absolute_error: 180920.2031\n",
      "Epoch 111/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -25471341.5562 - mean_absolute_error: 180920.2031\n",
      "Epoch 112/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -25700067.4192 - mean_absolute_error: 180920.2031\n",
      "Epoch 113/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -25929263.4685 - mean_absolute_error: 180920.1875\n",
      "Epoch 114/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -26157707.4959 - mean_absolute_error: 180920.2188\n",
      "Epoch 115/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -26386887.7534 - mean_absolute_error: 180920.2188\n",
      "Epoch 116/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -26615625.1616 - mean_absolute_error: 180920.2031\n",
      "Epoch 117/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -26844933.2986 - mean_absolute_error: 180920.1719\n",
      "Epoch 118/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -27073475.0301 - mean_absolute_error: 180920.1875\n",
      "Epoch 119/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -27302418.2192 - mean_absolute_error: 180920.2031\n",
      "Epoch 120/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -27531637.9562 - mean_absolute_error: 180920.1875\n",
      "Epoch 121/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -27760186.6521 - mean_absolute_error: 180920.2031\n",
      "Epoch 122/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -27989045.2658 - mean_absolute_error: 180920.1875\n",
      "Epoch 123/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -28217239.0904 - mean_absolute_error: 180920.1719\n",
      "Epoch 124/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -28447243.1233 - mean_absolute_error: 180920.2188\n",
      "Epoch 125/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -28675243.4904 - mean_absolute_error: 180920.2031\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 45us/sample - loss: -28904351.9507 - mean_absolute_error: 180920.2031\n",
      "Epoch 127/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -29133322.6027 - mean_absolute_error: 180920.1719\n",
      "Epoch 128/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -29362097.4027 - mean_absolute_error: 180920.2031\n",
      "Epoch 129/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -29591068.4548 - mean_absolute_error: 180920.2031\n",
      "Epoch 130/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -29820383.5726 - mean_absolute_error: 180920.2031\n",
      "Epoch 131/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -30049103.1123 - mean_absolute_error: 180920.1719\n",
      "Epoch 132/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -30278178.7726 - mean_absolute_error: 180920.1719\n",
      "Epoch 133/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -30506436.6082 - mean_absolute_error: 180920.2031\n",
      "Epoch 134/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -30735286.2027 - mean_absolute_error: 180920.2031\n",
      "Epoch 135/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -30964582.0932 - mean_absolute_error: 180920.2031\n",
      "Epoch 136/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -31192978.1918 - mean_absolute_error: 180920.2031\n",
      "Epoch 137/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -31422205.3479 - mean_absolute_error: 180920.2031\n",
      "Epoch 138/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -31650820.4712 - mean_absolute_error: 180920.2031\n",
      "Epoch 139/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -31879631.7808 - mean_absolute_error: 180920.2031\n",
      "Epoch 140/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -32108338.5479 - mean_absolute_error: 180920.2031\n",
      "Epoch 141/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -32337248.6795 - mean_absolute_error: 180920.1719\n",
      "Epoch 142/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -32565836.4274 - mean_absolute_error: 180920.2031\n",
      "Epoch 143/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -32794366.1589 - mean_absolute_error: 180920.2031\n",
      "Epoch 144/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -33023672.7178 - mean_absolute_error: 180920.2031\n",
      "Epoch 145/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -33252331.0575 - mean_absolute_error: 180920.2031\n",
      "Epoch 146/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -33480917.1726 - mean_absolute_error: 180920.2031\n",
      "Epoch 147/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -33710209.0466 - mean_absolute_error: 180920.2031\n",
      "Epoch 148/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -33938635.3315 - mean_absolute_error: 180920.2188\n",
      "Epoch 149/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -34167905.9726 - mean_absolute_error: 180920.1719\n",
      "Epoch 150/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -34396570.0822 - mean_absolute_error: 180920.2188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8882d5b630>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# This is our perceptron from Monday's by-hand: \n",
    "model = Sequential()\n",
    "model.add(Dense(1,input_dim=61, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['MAE'])\n",
    "model.fit(X,y, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3LayerJunk\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense1 (Dense)               (None, 20)                1240      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,681\n",
      "Trainable params: 1,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_improved = Sequential(name=\"3LayerJunk\")\n",
    "\n",
    "model_improved.add(Dense(20, input_dim=61, activation='relu', name=\"Dense1\"))\n",
    "model_improved.add(Dense(20, activation='relu'))\n",
    "model_improved.add(Dense(1, activation='relu'))\n",
    "\n",
    "model_improved.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "              metrics=['MAE'])\n",
    "\n",
    "# Let's inspect our new architecture\n",
    "model_improved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -68952239.1671 - mean_absolute_error: 180920.2188\n",
      "Epoch 2/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -69180942.8274 - mean_absolute_error: 180920.1719\n",
      "Epoch 3/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -69410179.0466 - mean_absolute_error: 180920.1719\n",
      "Epoch 4/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -69638487.8027 - mean_absolute_error: 180920.1719\n",
      "Epoch 5/150\n",
      "1460/1460 [==============================] - 0s 42us/sample - loss: -69867712.9205 - mean_absolute_error: 180920.1875\n",
      "Epoch 6/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -70096483.8685 - mean_absolute_error: 180920.2031\n",
      "Epoch 7/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -70325540.0548 - mean_absolute_error: 180920.2031\n",
      "Epoch 8/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -70554647.4959 - mean_absolute_error: 180920.1406\n",
      "Epoch 9/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -70782694.1151 - mean_absolute_error: 180920.1875\n",
      "Epoch 10/150\n",
      "1460/1460 [==============================] - 0s 50us/sample - loss: -71011771.0466 - mean_absolute_error: 180920.1875\n",
      "Epoch 11/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -71240759.7589 - mean_absolute_error: 180920.1875\n",
      "Epoch 12/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -71469454.1808 - mean_absolute_error: 180920.2031\n",
      "Epoch 13/150\n",
      "1460/1460 [==============================] - 0s 48us/sample - loss: -71697868.2301 - mean_absolute_error: 180920.1875\n",
      "Epoch 14/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -71926683.8137 - mean_absolute_error: 180920.1719\n",
      "Epoch 15/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -72156228.2959 - mean_absolute_error: 180920.1875\n",
      "Epoch 16/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -72384756.2740 - mean_absolute_error: 180920.2031\n",
      "Epoch 17/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -72613524.8658 - mean_absolute_error: 180920.2031\n",
      "Epoch 18/150\n",
      "1460/1460 [==============================] - 0s 48us/sample - loss: -72842151.7918 - mean_absolute_error: 180920.1875\n",
      "Epoch 19/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -73071045.7096 - mean_absolute_error: 180920.2031\n",
      "Epoch 20/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -73299623.2329 - mean_absolute_error: 180920.1719\n",
      "Epoch 21/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -73528288.6575 - mean_absolute_error: 180920.1875\n",
      "Epoch 22/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -73757257.7753 - mean_absolute_error: 180920.2188\n",
      "Epoch 23/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -73986364.0986 - mean_absolute_error: 180920.1719\n",
      "Epoch 24/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -74214617.4356 - mean_absolute_error: 180920.1875\n",
      "Epoch 25/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -74443325.3041 - mean_absolute_error: 180920.1875\n",
      "Epoch 26/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -74672650.1699 - mean_absolute_error: 180920.2188\n",
      "Epoch 27/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -74901455.7808 - mean_absolute_error: 180920.1875\n",
      "Epoch 28/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -75130346.3014 - mean_absolute_error: 180920.1875\n",
      "Epoch 29/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -75359231.0575 - mean_absolute_error: 180920.2031\n",
      "Epoch 30/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -75588022.5315 - mean_absolute_error: 180920.2031\n",
      "Epoch 31/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -75816978.2575 - mean_absolute_error: 180920.2031\n",
      "Epoch 32/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -76045876.5370 - mean_absolute_error: 180920.2188\n",
      "Epoch 33/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -76274739.7699 - mean_absolute_error: 180920.1719\n",
      "Epoch 34/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -76503820.5151 - mean_absolute_error: 180920.2031\n",
      "Epoch 35/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -76732363.1233 - mean_absolute_error: 180920.1719\n",
      "Epoch 36/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -76961184.6795 - mean_absolute_error: 180920.2031\n",
      "Epoch 37/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -77189379.3753 - mean_absolute_error: 180920.2188\n",
      "Epoch 38/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -77418820.3836 - mean_absolute_error: 180920.2031\n",
      "Epoch 39/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -77647246.4767 - mean_absolute_error: 180920.2188\n",
      "Epoch 40/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -77876211.2000 - mean_absolute_error: 180920.2188\n",
      "Epoch 41/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -78104990.9699 - mean_absolute_error: 180920.2031\n",
      "Epoch 42/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -78333392.1973 - mean_absolute_error: 180920.2188\n",
      "Epoch 43/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -78562403.8137 - mean_absolute_error: 180920.2188\n",
      "Epoch 44/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -78791016.9205 - mean_absolute_error: 180920.2188\n",
      "Epoch 45/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -79020263.8685 - mean_absolute_error: 180920.1875\n",
      "Epoch 46/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -79249266.5425 - mean_absolute_error: 180920.1719\n",
      "Epoch 47/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -79477955.9671 - mean_absolute_error: 180920.2031\n",
      "Epoch 48/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -79706753.1178 - mean_absolute_error: 180920.2344\n",
      "Epoch 49/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -79935545.7315 - mean_absolute_error: 180920.1875\n",
      "Epoch 50/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -80164745.5671 - mean_absolute_error: 180920.1875\n",
      "Epoch 51/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -80392879.3205 - mean_absolute_error: 180920.1719\n",
      "Epoch 52/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -80621823.6493 - mean_absolute_error: 180920.1875\n",
      "Epoch 53/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -80850718.9699 - mean_absolute_error: 180920.1719\n",
      "Epoch 54/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -81079638.5096 - mean_absolute_error: 180920.2031\n",
      "Epoch 55/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -81308541.5890 - mean_absolute_error: 180920.1875\n",
      "Epoch 56/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -81537080.9863 - mean_absolute_error: 180920.1719\n",
      "Epoch 57/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -81766319.6055 - mean_absolute_error: 180920.1875\n",
      "Epoch 58/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -81995185.6438 - mean_absolute_error: 180920.2031\n",
      "Epoch 59/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -82224002.4767 - mean_absolute_error: 180920.2031\n",
      "Epoch 60/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -82453294.2466 - mean_absolute_error: 180920.1719\n",
      "Epoch 61/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -82681739.4192 - mean_absolute_error: 180920.2188\n",
      "Epoch 62/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -82910773.1507 - mean_absolute_error: 180920.2344\n",
      "Epoch 63/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 45us/sample - loss: -83139631.5178 - mean_absolute_error: 180920.1719\n",
      "Epoch 64/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -83368639.1452 - mean_absolute_error: 180920.2031\n",
      "Epoch 65/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -83597222.6849 - mean_absolute_error: 180920.1875\n",
      "Epoch 66/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -83826232.5041 - mean_absolute_error: 180920.1875\n",
      "Epoch 67/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -84054979.5288 - mean_absolute_error: 180920.2031\n",
      "Epoch 68/150\n",
      "1460/1460 [==============================] - 0s 51us/sample - loss: -84283882.2356 - mean_absolute_error: 180920.1719\n",
      "Epoch 69/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -84512360.3288 - mean_absolute_error: 180920.2031\n",
      "Epoch 70/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -84740994.5863 - mean_absolute_error: 180920.1719\n",
      "Epoch 71/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -84970189.7205 - mean_absolute_error: 180920.1719\n",
      "Epoch 72/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -85198938.1041 - mean_absolute_error: 180920.1875\n",
      "Epoch 73/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -85427192.7671 - mean_absolute_error: 180920.2031\n",
      "Epoch 74/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -85657340.8658 - mean_absolute_error: 180920.1719\n",
      "Epoch 75/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -85885323.0027 - mean_absolute_error: 180920.2031\n",
      "Epoch 76/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -86114982.3123 - mean_absolute_error: 180920.2344\n",
      "Epoch 77/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -86343598.0712 - mean_absolute_error: 180920.2031\n",
      "Epoch 78/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -86572136.1096 - mean_absolute_error: 180920.2031\n",
      "Epoch 79/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -86800977.3151 - mean_absolute_error: 180920.2031\n",
      "Epoch 80/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -87029609.2055 - mean_absolute_error: 180920.1875\n",
      "Epoch 81/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -87258766.6411 - mean_absolute_error: 180920.2188\n",
      "Epoch 82/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -87487384.8767 - mean_absolute_error: 180920.2031\n",
      "Epoch 83/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -87716442.4110 - mean_absolute_error: 180920.1875\n",
      "Epoch 84/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -87946017.1836 - mean_absolute_error: 180920.2031\n",
      "Epoch 85/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -88174103.4301 - mean_absolute_error: 180920.2031\n",
      "Epoch 86/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -88403522.1479 - mean_absolute_error: 180920.2344\n",
      "Epoch 87/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -88632009.6000 - mean_absolute_error: 180920.2031\n",
      "Epoch 88/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -88861287.4959 - mean_absolute_error: 180920.2188\n",
      "Epoch 89/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -89090097.0301 - mean_absolute_error: 180920.1875\n",
      "Epoch 90/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -89319724.8877 - mean_absolute_error: 180920.2031\n",
      "Epoch 91/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -89548557.8959 - mean_absolute_error: 180920.2031\n",
      "Epoch 92/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -89777175.6712 - mean_absolute_error: 180920.1719\n",
      "Epoch 93/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -90006486.9479 - mean_absolute_error: 180920.2031\n",
      "Epoch 94/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -90234735.7370 - mean_absolute_error: 180920.1719\n",
      "Epoch 95/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -90464655.7589 - mean_absolute_error: 180920.1719\n",
      "Epoch 96/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -90693160.4822 - mean_absolute_error: 180920.2031\n",
      "Epoch 97/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -90921787.6384 - mean_absolute_error: 180920.2031\n",
      "Epoch 98/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -91150936.3288 - mean_absolute_error: 180920.2031\n",
      "Epoch 99/150\n",
      "1460/1460 [==============================] - 0s 48us/sample - loss: -91379648.3945 - mean_absolute_error: 180920.2031\n",
      "Epoch 100/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -91608270.2466 - mean_absolute_error: 180920.2031\n",
      "Epoch 101/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -91836831.2548 - mean_absolute_error: 180920.2031\n",
      "Epoch 102/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -92065876.6904 - mean_absolute_error: 180920.2031\n",
      "Epoch 103/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -92294961.3370 - mean_absolute_error: 180920.1719\n",
      "Epoch 104/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -92523424.7890 - mean_absolute_error: 180920.2188\n",
      "Epoch 105/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -92752210.6301 - mean_absolute_error: 180920.2031\n",
      "Epoch 106/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -92980980.9753 - mean_absolute_error: 180920.2031\n",
      "Epoch 107/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -93209631.6712 - mean_absolute_error: 180920.2344\n",
      "Epoch 108/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -93438217.1616 - mean_absolute_error: 180920.2031\n",
      "Epoch 109/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -93666920.3068 - mean_absolute_error: 180920.1875\n",
      "Epoch 110/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -93895620.6904 - mean_absolute_error: 180920.2031\n",
      "Epoch 111/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -94124247.1014 - mean_absolute_error: 180920.2188\n",
      "Epoch 112/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -94353285.0630 - mean_absolute_error: 180920.1875\n",
      "Epoch 113/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -94582000.2192 - mean_absolute_error: 180920.2031\n",
      "Epoch 114/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -94811234.7178 - mean_absolute_error: 180920.1719\n",
      "Epoch 115/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -95040280.8548 - mean_absolute_error: 180920.1719\n",
      "Epoch 116/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -95268894.9041 - mean_absolute_error: 180920.1875\n",
      "Epoch 117/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -95497742.1589 - mean_absolute_error: 180920.1875\n",
      "Epoch 118/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -95727156.4274 - mean_absolute_error: 180920.2031\n",
      "Epoch 119/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -95955499.3096 - mean_absolute_error: 180920.1719\n",
      "Epoch 120/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -96184869.0192 - mean_absolute_error: 180920.1719\n",
      "Epoch 121/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -96414013.7644 - mean_absolute_error: 180920.1875\n",
      "Epoch 122/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -96642827.3973 - mean_absolute_error: 180920.1875\n",
      "Epoch 123/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -96872007.5178 - mean_absolute_error: 180920.2188\n",
      "Epoch 124/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -97100393.2274 - mean_absolute_error: 180920.2188\n",
      "Epoch 125/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 44us/sample - loss: -97329632.4384 - mean_absolute_error: 180920.1719\n",
      "Epoch 126/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -97557984.3945 - mean_absolute_error: 180920.2188\n",
      "Epoch 127/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -97787588.3836 - mean_absolute_error: 180920.2031\n",
      "Epoch 128/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -98016301.7644 - mean_absolute_error: 180920.2031\n",
      "Epoch 129/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -98245196.0110 - mean_absolute_error: 180920.2031\n",
      "Epoch 130/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -98473979.0466 - mean_absolute_error: 180920.1719\n",
      "Epoch 131/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -98702755.9233 - mean_absolute_error: 180920.2188\n",
      "Epoch 132/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -98931554.7178 - mean_absolute_error: 180920.1875\n",
      "Epoch 133/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -99160488.8767 - mean_absolute_error: 180920.1875\n",
      "Epoch 134/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -99389333.5014 - mean_absolute_error: 180920.2188\n",
      "Epoch 135/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -99618039.0137 - mean_absolute_error: 180920.2031\n",
      "Epoch 136/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -99846978.7836 - mean_absolute_error: 180920.2031\n",
      "Epoch 137/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -100075937.6000 - mean_absolute_error: 180920.2188\n",
      "Epoch 138/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -100304751.0137 - mean_absolute_error: 180920.1875\n",
      "Epoch 139/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -100533473.1178 - mean_absolute_error: 180920.1719\n",
      "Epoch 140/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -100762486.0274 - mean_absolute_error: 180920.2188\n",
      "Epoch 141/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -100991720.3507 - mean_absolute_error: 180920.1875\n",
      "Epoch 142/150\n",
      "1460/1460 [==============================] - 0s 51us/sample - loss: -101220672.1096 - mean_absolute_error: 180920.2031\n",
      "Epoch 143/150\n",
      "1460/1460 [==============================] - 0s 47us/sample - loss: -101449710.6192 - mean_absolute_error: 180920.2031\n",
      "Epoch 144/150\n",
      "1460/1460 [==============================] - 0s 43us/sample - loss: -101678538.7178 - mean_absolute_error: 180920.2188\n",
      "Epoch 145/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -101907584.2411 - mean_absolute_error: 180920.2031\n",
      "Epoch 146/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -102136779.9671 - mean_absolute_error: 180920.2188\n",
      "Epoch 147/150\n",
      "1460/1460 [==============================] - 0s 44us/sample - loss: -102366577.4466 - mean_absolute_error: 180920.2031\n",
      "Epoch 148/150\n",
      "1460/1460 [==============================] - 0s 46us/sample - loss: -102595458.9370 - mean_absolute_error: 180920.2031\n",
      "Epoch 149/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -102825015.7151 - mean_absolute_error: 180920.1875\n",
      "Epoch 150/150\n",
      "1460/1460 [==============================] - 0s 45us/sample - loss: -103054124.1425 - mean_absolute_error: 180920.2031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f888299abe0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 120us/sample - loss: 1145033.8623 - mean_absolute_error: 180921.1250\n",
      "mean_absolute_error: 180921.125\n"
     ]
    }
   ],
   "source": [
    "scores = model_improved.evaluate(X,y)\n",
    "print(f\"{model_improved.metrics_names[1]}: {scores[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8459578047231604"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19684.598211785884"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred = reg.predict(X)\n",
    "\n",
    "mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- Make sure to have your final layer have as many nodes as the number of classes that you want to predict.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows * img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows * img_cols)\n",
    "\n",
    "# Normalize Our Data\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 412,778\n",
      "Trainable params: 412,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (60000, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-a782e661ef22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m          \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m          epochs=10)\n\u001b[0m\u001b[1;32m      5\u001b[0m          \u001b[0;31m#validation_data=(x_valid, y_valid),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0;31m#callbacks=[checkpointer])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    374\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_input to have 4 dimensions, but got array with shape (60000, 784)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=10,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "> 91.033\n",
      "> 91.367\n",
      "> 90.850\n",
      "> 91.208\n",
      "> 91.367\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-b1567a72068d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# entry point, run the test harness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mrun_test_harness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-96-b1567a72068d>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;31m# summarize estimated performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0msummarize_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-b1567a72068d>\u001b[0m in \u001b[0;36msummarize_diagnostics\u001b[0;34m(histories)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m212\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classification Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcXGWd7/HPN52lIQkJWQiQrQOEhCBCYg+LiOwSAwIjKARRdHC4zogzijLicgVxFEdGRa9wJYNcEUcTQGECqKgsAko0HQhggEAnZCVAIDH72v27fzyn6OpOL5XeqlP1fb9e59V11nrqdPf51vM8Z1FEYGZm5atXsQtgZmbF5SAwMytzDgIzszLnIDAzK3MOAjOzMucgMDMrcw4CM7My5yCwTifpIkk1kjZKWiXp15LeVcTy/FjS9qw8ueHpAte9RtJPu7qMhZK0RNJpxS6HlRYHgXUqSVcANwDfAEYAY4CbgHNaWL53NxXtWxExIG84sjM2qsT/R7ZH8x+wdRpJg4BrgU9GxC8jYlNE7IiIeyPiymyZayTdJemnktYDH5XUT9INkl7Jhhsk9cuWHybpPkl/k7RG0mO5A6+kz0taKWmDpIWSTm1HmaskhaRLJC2T9IakL2XzpgJfBC7Ir0VIekTS1yX9EdgMHCTpQEmzszLWSvrHvPfIfeZZWVmflHRkNu9KSb9oUqbvS/peOz7LP2bvvSYry4HZdEn6rqTXJa2X9Kykt2Xzpkl6LivXSkmf2933tRIQER48dMoATAV2Ar1bWeYaYAdwLumLyF6k8JgD7AcMB/4EfC1b/jrgh0CfbDgBEDABWA4cmC1XBRzcwnv+GPj3FuZVAQH8V1aWI4FtwGF55f1pk3UeAZYBhwO9s3I9Sqr5VAJHAauBU5p85vOzZT8HvJy9PgDYBAzOlu0NvA68o4XyLgFOa2b6KcAbwBSgH/B/gEezeWcA84DB2b47DDggm7cKOCF7vS8wpdh/Rx66f3CNwDrTUOCNiNjZxnJPRMQ9EVEfEVuADwHXRsTrEbEa+Crw4WzZHaSD5dhItYvHIiKAOtIBb5KkPhGxJCIWtfKen8tqFbnhtibzvxoRWyLiaeBpUiC05scRsSD7rPsDxwOfj4itETEfuAX4SN7y8yLirojYAXyHFBjHRsQqUoh8IFtuKmkfzmvj/Zv6EHBrRDwZEduALwDHSaoi7cOBwERAEfF89r5k8yZJ2ici1kbEk7v5vlYCHATWmd4EhhXQ7r+8yfiBwNK88aXZNIDrgVrgt5IWS7oKICJqgU+Tvm2/LmlmrimkBf8ZEYPzhkuazH817/VmYMBufIYDgTURsaHJZxjZ3PIRUQ+syPuMtwEXZ68vBm5v472b02gfRsRG0u9jZEQ8BPwAuJG0r2ZI2idb9DxgGrBU0h8kHdeO97Y9nIPAOtMTpGaVc9tYruktb18BxuaNj8mmEREbIuKzEXEQcDZwRa4vICJ+FhHvytYN4D86/hHaLGtz018BhkgamDdtDLAyb3x07kXWxzEqWw/gHuDtWbv9WcB/t6OcjfahpP6kGtpKgIj4fkS8A5gEHApcmU2fGxHnkJrl7gHuaMd72x7OQWCdJiLWAV8BbpR0rqS9JfWR9F5J32pl1Z8DX5Y0XNKwbBs/BZB0lqRDJAlYR2oSqpc0QdIpWafyVmALUN8FH+s1oKq1M4MiYjmpX+M6SZWS3g5cmvsMmXdIen9WW/o0KTDnZOtvBe4Cfgb8JSKWtVGmPtn75IbepH34MUlHZfvkG8CfI2KJpL+TdIykPqT+iK2kfdhX0ockDcqarNbTNfvQejgHgXWqiPg2cAXwZVKH6XLgctK3zZb8O1ADPAM8CzyZTQMYD/we2EiqcdwUEQ+T+ge+SeogfZX0jfYLrbzHv6nxdQRvFPiR7sx+vimptfbz6aSO51eAu4GrI+L3efP/B7gAWEvq/3h/dvDNuQ04gsKahX5FCr7ccE32Xv8b+AWpA/hg4MJs+X1IneFrSc1Hb5Ka3MjKsiQ7g+sTpL4GKzNK/W5m1lUkXQMcEhEXt7LMGOAFYP+IWN9dZTMD1wjMii5rdroCmOkQsGLorqs6zawZWafua6Qmm6lFLo6VKTcNmZmVOTcNmZmVuR7XNDRs2LCoqqoqdjHMzPYo8+bNeyMihrdn3R4XBFVVVdTU1BS7GGZmexRJS9teqnluGjIzK3MlFQSbNhW7BGZme56SCYJFi2DiRPj5z4tdEjOzPUvJBMHo0TBuHFx6KTz1VLFLY2a25yiZIOjbF+68E4YOhXPPhdWri10iM7M9Q8kEAcCIEXD33fDaa3DBBbBjR9vrmJmVu5IKAoDqapgxAx5+GK68stilMTPr+XrcdQSd4SMfgSefhO99D6ZMSeNmZta8kqsR5Fx/PZx8Mlx2Gfj6NDOzlpVsEPTpA7Nmwf77w9//feo3MDOzXZVsEAAMH546j998E84/H7ZvL3aJzMx6npIOAoDJk+FHP4LHH4fPfKbYpTEz63lKsrO4qenT00Vm11+fOo8vvbTYJTIz6zlKvkaQc911cPrp8M//DHPmFLs0ZmY9R9kEQUUFzJwJo0bB+98Pq1YVu0RmZj1Dh4JA0lRJCyXVSrqqleXOkxSSqjvyfh01ZAjccw+sWwfnnQfbthWzNGZmPUO7g0BSBXAj8F5gEjBd0qRmlhsI/Cvw5/a+V2c64gi47TZ44gm4/HLwI5vNrNx1pEZwNFAbEYsjYjswEzinmeW+BvwHsLUD79Wpzj8fvvhFuOUWuPnmYpfGzKy4OhIEI4HleeMrsmlvkTQFGB0R97e2IUmXSaqRVLO6m24beu21MG0afOpT6dRSM7Ny1WWdxZJ6Ad8BPtvWshExIyKqI6J6+PB2PXt5t1VUwH//d3qGwfnnw4oV3fK2ZmY9TkeCYCUwOm98VDYtZyDwNuARSUuAY4HZxe4wzjd4cOo83rQpnUm0tcc0XpmZdZ+OBMFcYLykcZL6AhcCs3MzI2JdRAyLiKqIqALmAGdHRI+6BdykSXD77TB3LnziE+48NrPy0+4giIidwOXAA8DzwB0RsUDStZLO7qwCdodzz4Wrr05nE/3gB8UujZlZ91L0sK/A1dXVUVOE+0bX16e7lN5/P/z+93DSSd1eBDOzdpM0LyLa1fReNlcWt6VXr9RENH48fOADsHRpsUtkZtY9HAR59tkndR5v355qB5s3F7tEZmZdz0HQxIQJ8LOfwfz56elmPazlzMys0zkImnHmmfC1r6XrDL773WKXxsysa5VOEETAgutg07JO2dwXv5huTHfllanz2MysVJVOEGx4CZ79Ktw3AZ7+EuzY0KHNSfDjH6frDC64ABYv7pximpn1NKUTBPscCu97EUafBwu+AfceAi/dDPU7273JAQNS53F9fbrWYNOmTiyvmVkPUTpBANB/DLzzp3DGX2DgBJj7Cfj1kfDKr9vd63vwwemBNgsWwD/8gzuPzaz0lFYQ5Az9OzjtD3DCL6BuOzwyDR4+A9Y+067NnXFGetTlHXfAt77VyWU1Myuy0gwCSI38o98PZy6AKTfAmhr4zWT488dhy+4/p/LKK1NfwRe+AL/5TReU18ysSEo3CHIq+sLEf4WzF8GET8PLP4F7x8Oz18LOwhv9JfjRj+Dtb4fp0+Gll7qwzGZm3aj0gyCn774w5dtw5vNwwFR49mq491BYfBtEfUGb6N8/dR5XVKTO4w0dOzHJzKxHKJ8gyBl4MJxwF5z2GOw9CuZ8FH5TDa89XNDqVVUwaxa88AJcckk6o8jMbE9WfkGQs9+74D1PwDt/BtvXwIOnwB/OhnUvtLnqqafCf/4n3H03fOMb3VBWM7MuVL5BAKBeUDUdznoBjvomvP4H+NXbYO7lsLX1Zyd/+tNw8cXwla/Avfd2U3nNzLpAeQdBTkUlTPo8vK8WDvlfUPvDdEHac9+CuuafXynBjBkweXIKhBfarkiYmfVIDoJ8lcPh726Eac/C8HfD/M/DfRNhycxmryTba6/UPNSvX+o8XreuCGU2M+sgB0FzBh0GJ90Lp/we+gyGP02H3x4Hq/+0y6JjxsCdd8KiRalm4M5jM9vTdCgIJE2VtFBSraSrmpn/CUnPSpov6XFJkzryft1u/1Nh6jw45lbYvAx+dzw89gHYsKjRYieemG5Xfd99cM01xSmqmVl7tTsIJFUANwLvBSYB05s50P8sIo6IiKOAbwHfaXdJi6VXBRz8MXjfS3DENfDKr+D+w+DJz8L2tW8t9slPwsc+lp5jcPfdxSuumdnu6kiN4GigNiIWR8R2YCZwTv4CEbE+b7Q/sOfesq13fzji6hQIVR+GF74Lsw+BF74HdduR4Kab4Oij4cMfhn/7N5g3zzepM7OeryNBMBJYnje+IpvWiKRPSlpEqhH8S3MbknSZpBpJNatXt37aZtHtfSAc+yN471MwZAo8+el0yunye6jsF9x9N5x0Umoqqq6G8ePTQ27mz3comFnPpGjn0UnS+cDUiPh4Nv5h4JiIuLyF5S8CzoiIS1rbbnV1ddTU1LSrTN0uIt3i+qnPwfrnYb93w+Rvw9Bq1qxJTUR33AEPPgh1dXDoofDBD6ab1x1+eDoFdRf1dVC3JZ22Wr81/Xxr2NLwurV5ufkRUDkC9jqg8VA5Anr16fbdZWZdR9K8iKhu17odCILjgGsi4oxs/AsAEXFdC8v3AtZGxKDWtrtHBUFO/U5YdAs88xXYthpGnw97HZgOxju3sHXLVl5buZXVr21l84atVPbZyuCBWxg6eCv79N9Kn155B/Bo/4N0gHSA71WZro0gYNub7NoiJ+g3LC8Y9m8SFHmve+/dsfKYWbfoSBD07sD7zgXGSxoHrAQuBC5qUrDxEZG7T+eZQGnes7NXbxj/Cai6CBZ8E176v0BAxV5QUUllRSVjh1cydkQl2+v3YtXrw1i6opKa2kq2bq+k/z6VjD1oL8ZPrGTo8Owg/tawV+PxXi1Mz83rVdG4bPU7YOvr6dbbW1bB1lUNr3PDugWw5dXmQ6jPPruGQ6PxLET6DG6hitPFIlK567ZB/basNrQtjTd93Xdf2GcC9G31u4iVi4h0wseml2HbGug9APoMTEPvAdB7YLp7cRlod40AQNI04AagArg1Ir4u6VqgJiJmS/oecBqwA1gLXB4RC1rb5h5ZI2inVavgrrtS89Hjj6dpRx2Vmo8++MH0dLRuE/Wp9tBSYOSP123Zdf2KysY1i/zg6DMw70Dd5ABdv7XlabkDe2sH+fptBd899i2VI1IgDJyQfu4zAfaZCP2rUqhb6dixHjYuSQf7t36+DJuWpJ8727iFcK++DQHROy8kWhpva9lefbvsC1NRmoa6SjkFQb4VK1IozJoFc+akae94R+pP+MAH0l1Pe4SI9M/VNBy2vrprTWPH39re3ltNWf2yWk2/9Do3rVc2fbem5W8rb9q21bB+YRo2ZD+3vdG4LAMOaQiH/KDoN7Tr9qm1385NsGlp44N7/s/taxov37s/9B+XQn/AuDT0r0q/352bYMcG2Lkx+7lh1/GW5hXapKveecEwIC8wstAYNAkO3+WSrMI27SAoLUuXpquV77gD5s5N0445JtUSPvABGD26uOUr2M4tKSB2bmxycM697ptu/FdM297cNRzWL4SNtalZLaffsF3DYeCEdFtzd7x3nbpt6UDf3EF+08up2TNfr34woCod7AfkHfD7Z9P6De38b+QRqWa6Y2NeQGzYdTwXGrkAyc3LHx/0NjjpvnYVw0FQwl5+OQXCHXfAk0+mae98Z6opnH8+HHhgcctXsup3poPN+oWw/oXGQbH1tYbl1BsGHNRCLWJ4cfpNWlJf19CcVreddBKB8sqovPG8n7l5b423c15z+6J+B2xe0fxBfuPL2WNl845R6g39xzZ/kB9QlZr9iv3lokgcBGXipZdSTWHWLHjmmfR/9a53pVA47zzYf/9il7BMbP8brH8xBUR+LWLDS+kgm9N33yb9EBNg4KGpNtRS/8hbrztpWv57dPSMtE6TBYK0a/+OesHeo5s/yPcfl87Ga3pChAEOgrL0wgsNNYUFC6BXr3TPow9+MIXC8OHFLmEZqq9L96Rqrhax5ZWObVu9mulLadrUthvTcp2Wb/3/R/Y6mrzuwLxmpzeZp97Qf3TDwX7v0W5qaycHQZlbsCAFwqxZsHBheqbyySenpqPTT4eDDip2CY0dG2DDi7D+pfTNfJdO7bYO3D6byVrnIDAgfcl69tmGUKitTdOrquCUU9Jw8snuVzArRQ4C20VEaj566KE0PPwwrM1uljpxYgqFU09N90UaMqSoRTWzTuAgsDbV1cHTTzcEw6OPwqZNqZn4qKMaagwnnAADBxa7tGa2uxwEttt27IC//KUhGP70J9i+HXr3TrfSzgXDccdBZWWxS2tmbXEQWIdt2ZLC4MEHUzDMnZseu1lZCccf3xAM1dUpLMysZ3EQWKdbtw4eeyyFwoMPpusWIDUbvfvdDX0MRxyRTl01s+Iq1t1HrYQNGgRnnZUGgNWr4ZFHGpqS7r8/TR86NJ2JlKsxHHpoz7qY1sza5hqBtcvy5elMpFyNYcWKNH3kyIZQOOUUGDOmuOU0KxduGrKiioBFixr6Fx56CN7Ibup58MGpKWnKFJg8GY48EgYMKG55zUqRg8B6lPr6dLVzrrbwxBMNwSCl5qPJkxsPw4YVt8xmezoHgfVoEbByJTz1VBqefDL9XLasYZnRoxsHw5QpMGqU+xvMCuXOYuvRpHRQHzUK3ve+hulvvgnz5zcOh3vvbbgP2tChu4bD+PE+S8mss7lGYD3Kpk3pVNX8cPjrX9PFbgD9+6d+hlwwTJ4Mhx8Ofcvj0bJmLSpa05CkqcD3SM8sviUivtlk/hXAx4GdwGrgHyJiaWvbdBBYU9u3w/PPNw6H+fNh48Y0v0+fFAa5YHCntJWjogSBpArgReB0YAUwF5geEc/lLXMy8OeI2Czpn4CTIuKC1rbrILBC1NenM5VywZAbVq9O86XUjJQfDm9/O+y3n/sdrDQVq4/gaKA2IhZnhZgJnAO8FQQR8XDe8nOAizvwfmZv6dUrHejHj09PaIPUt/DKK43D4YknYObMhvUGD4YJE9IdWPOHgw9ONQuzctSRIBgJLM8bXwEc08rylwK/bm6GpMuAywDG+AokaycpXdA2cmTjTuk1a1IoPPdcujX3Cy/A734Ht93WsEzv3ukBPk0DYuJE2Hff7v8sZt2pW84aknQxUA2c2Nz8iJgBzIDUNNQdZbLyMWRIui/Sqac2nr5+Pbz4YkM45Ibf/KahcxpSc1JztYixY9PT4Mz2dB0JgpXA6LzxUdm0RiSdBnwJODEitjWdb1Ys++yT7qZa3aRVdedOWLIkPfYzPyDuvrvhwjiAfv3SxXFNQ2LCBHdU256lI0EwFxgvaRwpAC4ELspfQNJk4GZgakS83oH3Mus2vXvDIYek4cwzG897442GgMj9fPpp+OUvUwd2zqhRDaGQHxIjR7qz2nqedgdBROyUdDnwAOn00VsjYoGka4GaiJgNXA8MAO5U+utfFhFnd0K5zYpi2LA0HH984+nbtqWzmPJrEAsXwu23pyaonAEDUsf0IYekn/nD6NFuarLi8AVlZl0oAl59tXFA1Nam0Hj55cZ9EX36wLhxjcMhFxjjxvlJcdY632LCrIeS4IAD0nDyyY3n1dWl23cvWtR4qK2Fxx+HDRsab2fkyJZrE4MHd+/nstLiIDArkoqKdObR2LHp2Q35IlJ/RH445F7fdx+89lrj5YcObb4mcfDBsP/+7pew1jkIzHogCYYPT8Oxx+46f+PGXWsSixbBnDkwa1bjjuu9907XSDQNiDFjUr9E//7d97msZ3IQmO2BBgxI91M68shd523fDkuX7trc9NJL8MADsHVr4+WHDEmBkAuG3JAbHznSV12XOgeBWYnp27fh9htN1dfDqlUpHJYtS48czQ1Ll6a+ibVrG68jpeal/KBoGhojRvj24HsyB4FZGenVq+E2HC3ZuLFxQCxf3hAazz4Lv/oVbN7ceJ0+fdK1E63VLAYPdl9FT+UgMLNGBgyAww5LQ3Mi0v2bmoZEbnjssfREup07G6/Xv3/zITF2LFRVpSDxcyWKw0FgZrtFSmcpDR0KRx3V/DJ1denMpuaCYtmy9PChV1/ddbsjRzYEQ9OfY8b4Woqu4iAws05XUQEHHpiGY1q4J/H27ek6iqVL072d8n/+8Y/p9uF1dY3X2X//loNi7FifAdVeDgIzK4q+fdNprQcd1Pz8nTvT8yWaBsWSJTBvXrq/044djdcZNqz1oBg0qCs/0Z7LQWBmPVLv3qk5aMwYOOGEXefX16fmpaa1iSVLYMECuP/+XU+VHTy4+YAYMyZd/b3ffuV5qqyDwMz2SL16NTQ/vfOdu86PSI8ubS4oFi2CBx9seO51vmHDUhNUW8OQIaVzFpSDwMxKkpS+4e+3Hxx99K7zI9I1E0uWpE7s115LNYzcsGpVuq7i1Vd3rVlAqjmMGNFyUBxwQPo5YkTP77twEJhZWZLSt/ohQ2DKlJaXi0i3Es8PiabDihVQUwOvv9749h45AwcWVsvYb7/UJNbdHARmZq2QUifzoEHpQUOtqatLNwtsLTSefTY9M/tvf9t1/SlTUkd4d3MQmJl1koqK1BQ0YkTz94HKt3Vr4+aoVauK94hTB4GZWRFUVjbchrzYfJsoM7My5yAwMytzPe6ZxZJWA0s7sIlhwBudVJw9nfdFY94fjXl/NCiFfTE2Ioa3Z8UeFwQdJammvQ9wLjXeF415fzTm/dGg3PeFm4bMzMqcg8DMrMyVYhDMKHYBehDvi8a8Pxrz/mhQ1vui5PoIrPtIugY4JCIu7qLtLwA+GRGPSBJwK3Au8BLwWeCWiGjjWs/dfs8xwHPAoIioa2t5s1JQijUC60SSLpJUI2mjpFWSfi3pXd3x3hFxeEQ8ko2+CzgdGBURR0fEY50RApKWSDot7z2XRcSArgoBJYslPdcV2zdrDweBtUjSFcANwDeAEcAY4CbgnCIUZyywJCI2FeG9O9O7gf2AgyT9XXe+sSTfScCaVTJBIGmqpIWSaiVdVezyFJOk0ZIelvScpAWS/rUd2xgEXEtqmvllRGyKiB0RcW9EXNnCOndKelXSOkmPSjo8b960rDwbJK2U9Lls+jBJ90n6m6Q1kh6T1Cubt0TSaZIuBW4BjstqJl+VdJKkFU0+8y8lrZb0pqQfZNMPlvRQNm2npBWSBmfzbieF273Zdv9NUpWkyB00JR0oaXZWtlpJ/5j3ntdIukPST7LPtUBSW6cgXgL8D/Cr7HX+/hsi6f9JekXSWkn35M07R9J8SeslLZI0NX8fNSnTT7PXuc9yqaRlwEPZ9HskbZVUJ2mzpIvy1t9L0rclLc1+j49n0+6X9Kkm5X1G0t+38Xl7PEmfyX53f5X0c0nl92TkiNjjB6ACWAQcBPQFngYmFbtcRdwfBwBTstcDgRd3d38AU4GdQO9WlrkG+Gne+D9k79ePVJOYnzdvFXBC9nrfvPJdB/wQ6JMNJ9DQd7UEOC17/VHg8bztnQSsyPv9Pw18F+gPVALvyuYdQmpSuhL4BfAmcEPedt56j2y8Cojc5wYeJdWCKoGjgNXAKXmffyswLSvDdcCcVvbX3sD6bPnzSBcw9c2bfz8wK9s/fYATs+lHA+uyz9ELGAlMbKH8b/1O8j7LT7L9slc2/Y/AJ7Pf0/eBZ/PWvxF4JHuPCuCd2XIfBP6ct9yR2b7s29Ln3ROG7HO+nLdv7gA+WuxydfdQKlXFo4HaiFgMIGkmqfmiLNthI2IV6cBLRGyQ9DzpD3539sdQ4I2I2Lkb73tr7nXWkbxW0qCIWAfsACZJejoi1gJrs0V3kIJrbETUAo/tRhlzjgYOBK7MK+/jWZlqJW0FrgK+TqoBnFjIRiWNBo4HzoyIrcB8SbcAHyH7dk0Kp19ly98OfLqVTb4f2Ab8lnTDxz7AmcDdkg4A3gsMzfYPwB+yn5cCt0bE77LxlYWUP881kTWpZTW9A4GbIiIkfYXs9wRsIIX5sRGRe48/ZevNBm6WND4iXgI+DMyKiO27WZaeqDewl6QdpLB+pcjl6Xal0jQ0ElieN74im1b2JFUBk4E/7+aqbwLDCm1XllQh6ZtZs8V60jdVSJfuQ/oGPA1YKukPko7Lpl8P1AK/VepEbU+z3mhgaXOhJWkE8ARwBHAvaV8Ma7pcCw4E1kTEhrxpS2n8t/Vq3uvNQGUr++wS4I6I2JkFyy9oaB4anb3X2mbWG02q8bZX/v/GwaRv+Osk1QGvZdOHZUNlc++VlXcWcHHWdDcduL0DZeoRssD7T2AZ6cvTuoj4bXFL1f1KJQisGZIGkA42n46I9bu5+hOkb6/nFrj8RaRa2GnAIFKzBIAAImJuRJxD6ii9h1QFJyI2RMRnI+Ig4GzgCkmn7mZZlwNjWjgA305qvplI+vb9VK5MmdbOn34FGCJpYN60Mez+N3IkjQJOIR1IX5X0KnA+ME3SsOwzDMn1XzSxnHQAb84m0rfYnP2bWSb/M55FqoF9hPRNOFeLE6mpamsr73Ub8CHgVGBzRDzRwnJ7DEn7kv5ux5GCv7+kLjkduicrlSBYSfrWlDOKdvyzlhJJfUgh8N8R8cvdXT9rzvkKcKOkcyXtLamPpPdK+lYzqwwkBcebpAPTN/LK0lfSh7Jmoh2kdvL6bN5Zkg6RJFI7eF1u3m74C+nb3Dcl9ZdUKen4bN5o0oHvSVL4TCG1wee8Rupbam4fLCc1jVyXbfPtpGaan+5m+SA1pbwITCD1NRwFHEqqvU7PmvN+Ddwkad9sX787W/dHwMcknSqpl6SRkiZm8+YDF2bLV5PCpTXbSc1xD5F+T28FR0TUk4LhO1kneYWk4yT1y+Y/QfrdfJsSqA1kTgNejojV2d/mL0n9ImWlVIJgLjBe0jhJfYELgdlFLlPRZAfVHwHPR8R32rudiPg2cAXwZVIn6XLgctI3+qZ+Qmo2WUnqi5jTZP6HgSVZs9EnSN8sAcYDvwc2kmohN0XEw7tZzjrgfaSO4WWkg+sF2ezzgYWkZo/12ev85pfrgC8rnbX0uWY2P51Uu3kFuBsYeiaPAAAMEUlEQVS4OiJ+vzvly1xC+myv5g+kjvJc89CHSQfpF4DXyfobIuIvwMdIneHrSH0HuceZ/G/SN/i1wFeBn7VRjh+Q+gJeofk+o88Bz5L+p9YA/0Hj48RPSM1s7QnDnmgZcGz2RUek2s7zRS5TtyuZK4slTSOdqVJB6lj7epGLVDRKF3w9RvqHzn27/mKuU7NcSToJ+FxEnFXsshSTpKNIp+P2BRYDH2uhb6K5dT8CXBYR3XJRYXeQ9FXSF4edpKbDj0fEtuKWqnuVTBCYWdeStDepSemmiPhJsctjnafNpiFJt0p6XdJfW5gvSd9XutjmGUlT8uZdIumlbLikufXNrOeTdAapefA12m5+sj1MmzWCrMNqI/CTiHhbM/OnAZ8inRp4DPC9iDhG0hCgBqgmnbUwD3hHoVVQMzPrHm3WCCLiUVKnUUvOIYVERMQcYHB2ccwZwO8iIndu9O9IV6uamVkP0hlXFrd0MVfBF3lJugy4DKB///7vmDhxYnOLmZlZC+bNm/dGtPOZxT3iFhMRMYPswRDV1dVRU1NT5BKZme1ZJC1t77qdcR1BSxdz+SIvM7M9QGcEwWzgI9nZQ8eS7tWxCngAeE92leS+wHuyaWZm1oO02TQk6eekW/4OU7r/+9WkuyYSET8k3Vd9GunGYZtJV0ASEWskfY10hSLAtRHRWqezmZkVQZtBEBHT25gfpHubNzfvVhpuamVmZj1QqdxryMzM2slBYGZW5hwEZmZlzkFgZlbmHARmZmXOQWBmVuYcBGZmZc5BYGZW5hwEZmZlzkFgZlbmHARmZmXOQWBmVuYcBGZmZc5BYGZW5hwEZmZlzkFgZlbmCgoCSVMlLZRUK+mqZuZ/V9L8bHhR0t/y5tXlzZvdmYU3M7OOK+RRlRXAjcDpwApgrqTZEfFcbpmI+Eze8p8CJudtYktEHNV5RTYzs85USI3gaKA2IhZHxHZgJnBOK8tPB37eGYUzM7OuV0gQjASW542vyKbtQtJYYBzwUN7kSkk1kuZIOreF9S7LlqlZvXp1gUU3M7PO0NmdxRcCd0VEXd60sRFRDVwE3CDp4KYrRcSMiKiOiOrhw4d3cpHMzKw1hQTBSmB03viobFpzLqRJs1BErMx+LgYeoXH/gZmZFVkhQTAXGC9pnKS+pIP9Lmf/SJoI7As8kTdtX0n9stfDgOOB55qua2ZmxdPmWUMRsVPS5cADQAVwa0QskHQtUBMRuVC4EJgZEZG3+mHAzZLqSaHzzfyzjczMrPjU+LhdfNXV1VFTU1PsYpiZ7VEkzcv6Y3ebryw2MytzDgIzszLnIDAzK3MOAjOzMucgMDMrcw4CM7My5yAwMytzDgIzszLnIDAzK3MOAjOzMucgMDMrcw4CM7My5yAwMytzDgIzszLnIDAzK3MFBYGkqZIWSqqVdFUz8z8qabWk+dnw8bx5l0h6KRsu6czCm5lZx7X5hDJJFcCNwOnACmCupNnNPGlsVkRc3mTdIcDVQDUQwLxs3bWdUnozM+uwQmoERwO1EbE4IrYDM4FzCtz+GcDvImJNdvD/HTC1fUU1M7OuUEgQjASW542vyKY1dZ6kZyTdJWn07qwr6TJJNZJqVq9eXWDRzcysM3RWZ/G9QFVEvJ30rf+23Vk5ImZERHVEVA8fPryTimRmZoUoJAhWAqPzxkdl094SEW9GxLZs9BbgHYWua2ZmxVVIEMwFxksaJ6kvcCEwO38BSQfkjZ4NPJ+9fgB4j6R9Je0LvCebZmZmPUSbZw1FxE5Jl5MO4BXArRGxQNK1QE1EzAb+RdLZwE5gDfDRbN01kr5GChOAayNiTRd8DjMzaydFRLHL0Eh1dXXU1NQUuxhmZnsUSfMioro96/rKYjOzMucgMDMrcw4CM7My5yAwMytzDgIzszLnIDAzK3MOAjOzMucgMDMrcw4CM7My5yAwMytzDgIzszLnIDAzK3MOAjOzMucgMDMrcw4CM7My5yAwMytzBQWBpKmSFkqqlXRVM/OvkPScpGckPShpbN68Oknzs2F203XNzKy42nxUpaQK4EbgdGAFMFfS7Ih4Lm+xp4DqiNgs6Z+AbwEXZPO2RMRRnVxuMzPrJIXUCI4GaiNicURsB2YC5+QvEBEPR8TmbHQOMKpzi2lmZl2lkCAYCSzPG1+RTWvJpcCv88YrJdVImiPp3OZWkHRZtkzN6tWrCyiSmZl1ljabhnaHpIuBauDEvMljI2KlpIOAhyQ9GxGL8teLiBnADEgPr+/MMpmZWesKqRGsBEbnjY/KpjUi6TTgS8DZEbEtNz0iVmY/FwOPAJM7UF4zM+tkhQTBXGC8pHGS+gIXAo3O/pE0GbiZFAKv503fV1K/7PUw4Hggv5PZzMyKrM2moYjYKely4AGgArg1IhZIuhaoiYjZwPXAAOBOSQDLIuJs4DDgZkn1pND5ZpOzjczMrMgU0bOa5Kurq6OmpqbYxTAz26NImhcR1e1Z11cWm5mVOQeBmVmZcxCYmZU5B4GZWZlzEJiZlTkHgZlZmXMQmJmVOQeBmVmZcxCYmZU5B4GZWZlzEJiZlTkHgZlZmXMQmJmVOQeBmVmZcxCYmZU5B4GZWZkrKAgkTZW0UFKtpKuamd9P0qxs/p8lVeXN+0I2faGkMzqv6GZm1hnaDAJJFcCNwHuBScB0SZOaLHYpsDYiDgG+C/xHtu4k0jOODwemAjdl2zMzsx6ikBrB0UBtRCyOiO3ATOCcJsucA9yWvb4LOFXp4cXnADMjYltEvAzUZtszM7Meos2H1wMjgeV54yuAY1paJnvY/TpgaDZ9TpN1RzZ9A0mXAZdlo9sk/bWg0pe+YcAbxS5ED+F90cD7ooH3RYMJ7V2xkCDochExA5gBIKmmvQ9gLjXeFw28Lxp4XzTwvmggqaa96xbSNLQSGJ03Piqb1uwyknoDg4A3C1zXzMyKqJAgmAuMlzROUl9S5+/sJsvMBi7JXp8PPBQRkU2/MDuraBwwHvhL5xTdzMw6Q5tNQ1mb/+XAA0AFcGtELJB0LVATEbOBHwG3S6oF1pDCgmy5O4DngJ3AJyOiro23nNH+j1NyvC8aeF808L5o4H3RoN37QumLu5mZlStfWWxmVuYcBGZmZa5oQdCR21aUmgL2xRWSnpP0jKQHJY0tRjm7Q1v7Im+58ySFpJI9dbCQfSHpg9nfxgJJP+vuMnaXAv5Hxkh6WNJT2f/JtGKUs6tJulXS6y1da6Xk+9l+ekbSlII2HBHdPpA6nRcBBwF9gaeBSU2W+Wfgh9nrC4FZxShrD9kXJwN7Z6//qZz3RbbcQOBR0sWK1cUudxH/LsYDTwH7ZuP7FbvcRdwXM4B/yl5PApYUu9xdtC/eDUwB/trC/GnArwEBxwJ/LmS7xaoRdOS2FaWmzX0REQ9HxOZsdA7peoxSVMjfBcDXSPez2tqdhetmheyLfwRujIi1ABHxejeXsbsUsi8C2Cd7PQh4pRvL120i4lHSmZktOQf4SSRzgMGSDmhru8UKguZuW9H01hONblsB5G5bUWoK2Rf5LiUlfilqc19kVd3REXF/dxasCAr5uzgUOFTSHyXNkTS120rXvQrZF9cAF0taAfwK+FT3FK3H2d3jCdBDbjFhhZF0MVANnFjsshSDpF7Ad4CPFrkoPUVvUvPQSaRa4qOSjoiIvxW1VMUxHfhxRHxb0nGk65reFhH1xS7YnqBYNYKO3Lai1BR0Gw5JpwFfAs6OiG3dVLbu1ta+GAi8DXhE0hJSG+jsEu0wLuTvYgUwOyJ2RLq774ukYCg1heyLS4E7ACLiCaCSdEO6ctOu2/oUKwg6ctuKUtPmvpA0GbiZFAKl2g4MbeyLiFgXEcMioioiqkj9JWdHRLtvttWDFfI/cg+pNoCkYaSmosXdWchuUsi+WAacCiDpMFIQrO7WUvYMs4GPZGcPHQusi4hVba1UlKah6MBtK0pNgfviemAAcGfWX74sIs4uWqG7SIH7oiwUuC8eAN4j6TmgDrgyIkqu1lzgvvgs8F+SPkPqOP5oKX5xlPRzUvgPy/pDrgb6AETED0n9I9NIz37ZDHysoO2W4L4yM7Pd4CuLzczKnIPAzKzMOQjMzMqcg8DMrMw5CMzMypyDwMyszDkIzMzK3P8HxaOF+ktWTlkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# baseline cnn model for fashion mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# append scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(211)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(212)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 90.950\n",
      "> 91.133\n",
      "> 91.500\n",
      "> 91.067\n",
      "> 91.392\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-b1567a72068d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m# entry point, run the test harness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mrun_test_harness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-b1567a72068d>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;31m# summarize estimated performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0msummarize_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-b1567a72068d>\u001b[0m in \u001b[0;36msummarize_diagnostics\u001b[0;34m(histories)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m212\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Classification Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# baseline cnn model for fashion mnist\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "\t# load dataset\n",
    "\t(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\t# reshape dataset to have a single channel\n",
    "\ttrainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "\ttestX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\t# one hot encode target values\n",
    "\ttrainY = to_categorical(trainY)\n",
    "\ttestY = to_categorical(testY)\n",
    "\treturn trainX, trainY, testX, testY\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "\t# convert from integers to floats\n",
    "\ttrain_norm = train.astype('float32')\n",
    "\ttest_norm = test.astype('float32')\n",
    "\t# normalize to range 0-1\n",
    "\ttrain_norm = train_norm / 255.0\n",
    "\ttest_norm = test_norm / 255.0\n",
    "\t# return normalized images\n",
    "\treturn train_norm, test_norm\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(10, activation='softmax'))\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.01, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    "\n",
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(dataX, dataY, n_folds=5):\n",
    "\tscores, histories = list(), list()\n",
    "\t# prepare cross validation\n",
    "\tkfold = KFold(n_folds, shuffle=True, random_state=1)\n",
    "\t# enumerate splits\n",
    "\tfor train_ix, test_ix in kfold.split(dataX):\n",
    "\t\t# define model\n",
    "\t\tmodel = define_model()\n",
    "\t\t# select rows for train and test\n",
    "\t\ttrainX, trainY, testX, testY = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]\n",
    "\t\t# fit model\n",
    "\t\thistory = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=0)\n",
    "\t\t# evaluate model\n",
    "\t\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
    "\t\tprint('> %.3f' % (acc * 100.0))\n",
    "\t\t# append scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(histories):\n",
    "\tfor i in range(len(histories)):\n",
    "\t\t# plot loss\n",
    "\t\tpyplot.subplot(211)\n",
    "\t\tpyplot.title('Cross Entropy Loss')\n",
    "\t\tpyplot.plot(histories[i].history['loss'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_loss'], color='orange', label='test')\n",
    "\t\t# plot accuracy\n",
    "\t\tpyplot.subplot(212)\n",
    "\t\tpyplot.title('Classification Accuracy')\n",
    "\t\tpyplot.plot(histories[i].history['accuracy'], color='blue', label='train')\n",
    "\t\tpyplot.plot(histories[i].history['val_accuracy'], color='orange', label='test')\n",
    "\tpyplot.show()\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_performance(scores):\n",
    "\t# print summary\n",
    "\tprint('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))\n",
    "\t# box and whisker plots of results\n",
    "\tpyplot.boxplot(scores)\n",
    "\tpyplot.show()\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "\t# load dataset\n",
    "\ttrainX, trainY, testX, testY = load_dataset()\n",
    "\t# prepare pixel data\n",
    "\ttrainX, testX = prep_pixels(trainX, testX)\n",
    "\t# evaluate model\n",
    "\tscores, histories = evaluate_model(trainX, trainY)\n",
    "\t# learning curves\n",
    "\tsummarize_diagnostics(histories)\n",
    "\t# summarize estimated performance\n",
    "\tsummarize_performance(scores)\n",
    "\n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
