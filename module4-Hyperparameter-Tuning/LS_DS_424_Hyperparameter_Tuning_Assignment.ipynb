{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ryp-TVm4njD"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 4*\n",
    "\n",
    "## Your Mission, should you choose to accept it...\n",
    "\n",
    "To hyperparameter tune and extract every ounce of accuracy out of this telecom customer churn dataset: [Available Here](https://lambdaschool-data-science.s3.amazonaws.com/telco-churn/WA_Fn-UseC_-Telco-Customer-Churn+(1).csv)\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Load the data\n",
    "- Clean the data if necessary (it will be)\n",
    "- Create and fit a baseline Keras MLP model to the data.\n",
    "- Hyperparameter tune (at least) the following parameters:\n",
    " - batch_size\n",
    " - training epochs\n",
    " - optimizer\n",
    " - learning rate (if applicable to optimizer)\n",
    " - momentum (if applicable to optimizer)\n",
    " - activation functions\n",
    " - network weight initialization\n",
    " - dropout regularization\n",
    " - number of neurons in the hidden layer\n",
    " \n",
    " You must use Grid Search and Cross Validation for your initial pass of the above hyperparameters\n",
    " \n",
    " Try and get the maximum accuracy possible out of this data! You'll save big telecoms millions! Doesn't that sound great?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNJ-tOBs4jM1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install category_encoders==2.*\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7043, 21)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = './WA_Fn-UseC_-Telco-Customer-Churn+.csv'\n",
    "df = pd.read_csv(data)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           0\n",
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "MultipleLines        0\n",
       "InternetService      0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "PaperlessBilling     0\n",
       "PaymentMethod        0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop null values\n",
    "df = df.dropna()\n",
    "\n",
    "# convert TotalCharges to float\n",
    "df['TotalCharges'] = df['TotalCharges'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = df.drop(['Churn', 'customerID'], axis=1)\n",
    "y_labels = df['Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "      <td>7032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3549</td>\n",
       "      <td>3639</td>\n",
       "      <td>4933</td>\n",
       "      <td>6352</td>\n",
       "      <td>3385</td>\n",
       "      <td>3096</td>\n",
       "      <td>3497</td>\n",
       "      <td>3087</td>\n",
       "      <td>3094</td>\n",
       "      <td>3472</td>\n",
       "      <td>2809</td>\n",
       "      <td>2781</td>\n",
       "      <td>3875</td>\n",
       "      <td>4168</td>\n",
       "      <td>2365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender Partner Dependents PhoneService MultipleLines InternetService  \\\n",
       "count    7032    7032       7032         7032          7032            7032   \n",
       "unique      2       2          2            2             3               3   \n",
       "top      Male      No         No          Yes            No     Fiber optic   \n",
       "freq     3549    3639       4933         6352          3385            3096   \n",
       "\n",
       "       OnlineSecurity OnlineBackup DeviceProtection TechSupport StreamingTV  \\\n",
       "count            7032         7032             7032        7032        7032   \n",
       "unique              3            3                3           3           3   \n",
       "top                No           No               No          No          No   \n",
       "freq             3497         3087             3094        3472        2809   \n",
       "\n",
       "       StreamingMovies        Contract PaperlessBilling     PaymentMethod  \n",
       "count             7032            7032             7032              7032  \n",
       "unique               3               3                2                 4  \n",
       "top                 No  Month-to-month              Yes  Electronic check  \n",
       "freq              2781            3875             4168              2365  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.describe(exclude='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_to_numpy(dataframe):\n",
    "    # create copy of dataframe\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # one hot encode and convert to numpy array\n",
    "#     categorical_features = ['gender', 'SeniorCitizen', 'Partner',\n",
    "#                         'Dependents', 'PhoneService', 'MultipleLines',\n",
    "#                         'InternetService', 'OnlineSecurity', 'OnlineBackup',\n",
    "#                         'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "#                         'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "#                         'PaymentMethod']\n",
    "    \n",
    "    encoder = ce.OneHotEncoder(use_cat_names=True)\n",
    "    df = encoder.fit_transform(df)\n",
    "    df_to_array = df.to_numpy()\n",
    "    \n",
    "    return df_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_features, y_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_df_to_numpy(X_train)\n",
    "X_test = clean_df_to_numpy(X_test)\n",
    "\n",
    "y_train = y_train.replace({'Yes': 1, 'No': 0})\n",
    "y_test = y_test.replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train) == len(y_train))\n",
    "print(len(X_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5625, 45)\n",
      "(1407, 45)\n",
      "(5625,)\n",
      "(1407,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Correct Encoding on Y\n",
    "# num_classes = 2\n",
    "# labels = keras.utils.to_categorical(telecom_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline with average and baseline MLP Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.734215\n",
       "Yes    0.265785\n",
       "Name: Churn, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the baseline\n",
    "df['Churn'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 2\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625\n"
     ]
    }
   ],
   "source": [
    "X_train.shape[1]\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 12.6467 - accuracy: 0.6752 - val_loss: 4.1478 - val_accuracy: 0.3824\n",
      "Epoch 2/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 8.8397 - accuracy: 0.6987 - val_loss: 5.5845 - val_accuracy: 0.7470\n",
      "Epoch 3/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 4.5757 - accuracy: 0.7212 - val_loss: 3.1002 - val_accuracy: 0.3653\n",
      "Epoch 4/15\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 3.4749 - accuracy: 0.7179 - val_loss: 0.8735 - val_accuracy: 0.7520\n",
      "Epoch 5/15\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 2.6918 - accuracy: 0.7275 - val_loss: 1.7637 - val_accuracy: 0.7534\n",
      "Epoch 6/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1.1733 - accuracy: 0.7548 - val_loss: 0.6168 - val_accuracy: 0.7441\n",
      "Epoch 7/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1.1887 - accuracy: 0.7499 - val_loss: 0.6960 - val_accuracy: 0.7484\n",
      "Epoch 8/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.9643 - accuracy: 0.7573 - val_loss: 0.9018 - val_accuracy: 0.7278\n",
      "Epoch 9/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1.6009 - accuracy: 0.7522 - val_loss: 1.3952 - val_accuracy: 0.7434\n",
      "Epoch 10/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 1.5315 - accuracy: 0.7484 - val_loss: 1.2026 - val_accuracy: 0.7477\n",
      "Epoch 11/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.7592 - accuracy: 0.7607 - val_loss: 0.6643 - val_accuracy: 0.7385\n",
      "Epoch 12/15\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.6491 - accuracy: 0.7778 - val_loss: 0.8351 - val_accuracy: 0.7477\n",
      "Epoch 13/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.6022 - accuracy: 0.7737 - val_loss: 1.5432 - val_accuracy: 0.7427\n",
      "Epoch 14/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.6966 - accuracy: 0.7751 - val_loss: 0.8650 - val_accuracy: 0.5096\n",
      "Epoch 15/15\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5724 - accuracy: 0.7806 - val_loss: 0.6182 - val_accuracy: 0.7306\n"
     ]
    }
   ],
   "source": [
    "# Instantiate sequential model with layers\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')]\n",
    ")\n",
    "\n",
    "# complie the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "fitted = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train, \n",
    "    epochs=15, \n",
    "    validation_data=(X_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuning batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7978666663169861 using {'batch_size': 8, 'epochs': 15}\n",
      "Means: 0.7281777620315552, Stdev: 0.0668652417303076 with: {'batch_size': 8, 'epochs': 10}\n",
      "Means: 0.7978666663169861, Stdev: 0.010793320718694606 with: {'batch_size': 8, 'epochs': 15}\n",
      "Means: 0.7788444280624389, Stdev: 0.02155000370213255 with: {'batch_size': 8, 'epochs': 20}\n",
      "Means: 0.7968000054359436, Stdev: 0.013766030185446008 with: {'batch_size': 8, 'epochs': 25}\n",
      "Means: 0.7941333293914795, Stdev: 0.006424652935831748 with: {'batch_size': 16, 'epochs': 10}\n",
      "Means: 0.785955548286438, Stdev: 0.012922857346024686 with: {'batch_size': 16, 'epochs': 15}\n",
      "Means: 0.7475555539131165, Stdev: 0.07848037751971952 with: {'batch_size': 16, 'epochs': 20}\n",
      "Means: 0.7354666709899902, Stdev: 0.11502456113252678 with: {'batch_size': 16, 'epochs': 25}\n",
      "Means: 0.7624889016151428, Stdev: 0.04685851779827585 with: {'batch_size': 32, 'epochs': 10}\n",
      "Means: 0.7343999981880188, Stdev: 0.08066764458758681 with: {'batch_size': 32, 'epochs': 15}\n",
      "Means: 0.7767111182212829, Stdev: 0.02755497982135071 with: {'batch_size': 32, 'epochs': 20}\n",
      "Means: 0.7354666709899902, Stdev: 0.07981133154988088 with: {'batch_size': 32, 'epochs': 25}\n",
      "Means: 0.7328000068664551, Stdev: 0.07774521420151008 with: {'batch_size': 64, 'epochs': 10}\n",
      "Means: 0.711644446849823, Stdev: 0.14742120460064798 with: {'batch_size': 64, 'epochs': 15}\n",
      "Means: 0.7807999968528747, Stdev: 0.016143563124699167 with: {'batch_size': 64, 'epochs': 20}\n",
      "Means: 0.7882666707038879, Stdev: 0.007675390452594549 with: {'batch_size': 64, 'epochs': 25}\n",
      "Means: 0.6696888864040375, Stdev: 0.13722164328774594 with: {'batch_size': 128, 'epochs': 10}\n",
      "Means: 0.7861333370208741, Stdev: 0.016720561971394314 with: {'batch_size': 128, 'epochs': 15}\n",
      "Means: 0.6805333375930787, Stdev: 0.13976838730607713 with: {'batch_size': 128, 'epochs': 20}\n",
      "Means: 0.7818666577339173, Stdev: 0.018548633392098012 with: {'batch_size': 128, 'epochs': 25}\n"
     ]
    }
   ],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential([\n",
    "    \n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')]\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "param_grid = {'batch_size': [8, 16, 32, 64, 128],\n",
    "              'epochs': [10, 15, 20, 25]}\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the Batch_size at 8 and epochs at 15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FfZRtJ7MCN3x"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Try to implement Random Search Hyperparameter Tuning on this dataset\n",
    "- Try to implement Bayesian Optimiation tuning on this dataset using hyperas or hyperopt (if you're brave)\n",
    "- Practice hyperparameter tuning other datasets that we have looked at. How high can you get MNIST? Above 99%?\n",
    "- Study for the Sprint Challenge\n",
    " - Can you implement both perceptron and MLP models from scratch with forward and backpropagation?\n",
    " - Can you implement both perceptron and MLP models in keras and tune their hyperparameters with cross validation?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_434_Hyperparameter_Tuning_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
