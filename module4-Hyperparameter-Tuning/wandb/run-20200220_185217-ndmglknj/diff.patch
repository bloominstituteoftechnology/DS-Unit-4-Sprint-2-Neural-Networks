diff --git a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
index e676535..08f1be2 100644
--- a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
+++ b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Assignment.ipynb
@@ -361,7 +361,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.2"
+   "version": "3.7.6"
   }
  },
  "nbformat": 4,
diff --git a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Lecture.ipynb b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Lecture.ipynb
index 013bb56..afee7ac 100644
--- a/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Lecture.ipynb
+++ b/module1-Intro-to-Neural-Networks/LS_DS_421_Intro_to_NN_Lecture.ipynb
@@ -1764,7 +1764,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.2"
+   "version": "3.7.6"
   },
   "toc-autonumbering": false,
   "toc-showcode": false,
diff --git a/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb b/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
index 597c0be..4ed4d2a 100644
--- a/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
+++ b/module2-backpropagation/LS_DS_422_Gradient_Descent_Backprop_Lecture.ipynb
@@ -1582,7 +1582,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.2"
+   "version": "3.7.6"
   }
  },
  "nbformat": 4,
diff --git a/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb b/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
index 2457723..fbbc81d 100644
--- a/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
+++ b/module3-Intro-to-Keras/LS_DS_423_Keras_Assignment.ipynb
@@ -32,7 +32,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -40,7 +40,10 @@
    },
    "outputs": [],
    "source": [
-    "##### Your Code Here #####"
+    "##### Your Code Here #####\n",
+    "\n",
+    "from sklearn.datasets import load_boston\n",
+    "boston_dataset = load_boston()"
    ]
   },
   {
@@ -96,9 +99,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NN",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nn"
   },
   "language_info": {
    "codemirror_mode": {
@@ -110,9 +113,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.7.3"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb b/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
index abc92b5..ddd75dc 100644
--- a/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
+++ b/module3-Intro-to-Keras/LS_DS_423_Keras_Lecture.ipynb
@@ -110,21 +110,21 @@
      "text": [
       "Train on 4 samples\n",
       "Epoch 1/5\n",
-      "4/4 [==============================] - 1s 184ms/sample - loss: 0.7531 - accuracy: 0.2500\n",
+      "4/4 [==============================] - 1s 168ms/sample - loss: 0.7570 - accuracy: 0.2500\n",
       "Epoch 2/5\n",
-      "4/4 [==============================] - 0s 1ms/sample - loss: 0.7527 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 747us/sample - loss: 0.7566 - accuracy: 0.5000\n",
       "Epoch 3/5\n",
-      "4/4 [==============================] - 0s 833us/sample - loss: 0.7524 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 500us/sample - loss: 0.7563 - accuracy: 0.5000\n",
       "Epoch 4/5\n",
-      "4/4 [==============================] - 0s 760us/sample - loss: 0.7520 - accuracy: 0.5000\n",
+      "4/4 [==============================] - 0s 750us/sample - loss: 0.7560 - accuracy: 0.5000\n",
       "Epoch 5/5\n",
-      "4/4 [==============================] - 0s 805us/sample - loss: 0.7517 - accuracy: 0.5000\n"
+      "4/4 [==============================] - 0s 750us/sample - loss: 0.7557 - accuracy: 0.5000\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fb4cc4cdeb8>"
+       "<tensorflow.python.keras.callbacks.History at 0x1f224033be0>"
       ]
      },
      "execution_count": 2,
@@ -160,7 +160,7 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "4/1 [========================================================================================================================] - 0s 21ms/sample - loss: 0.7514 - accuracy: 0.5000\n",
+      "4/1 [========================================================================================================================] - 0s 17ms/sample - loss: 0.7553 - accuracy: 0.5000\n",
       "accuracy: 50.0\n"
      ]
     }
@@ -277,7 +277,7 @@
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
-       "      <td>0</td>\n",
+       "      <th>0</th>\n",
        "      <td>6</td>\n",
        "      <td>148</td>\n",
        "      <td>72</td>\n",
@@ -289,7 +289,7 @@
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <td>1</td>\n",
+       "      <th>1</th>\n",
        "      <td>1</td>\n",
        "      <td>85</td>\n",
        "      <td>66</td>\n",
@@ -301,7 +301,7 @@
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <td>2</td>\n",
+       "      <th>2</th>\n",
        "      <td>8</td>\n",
        "      <td>183</td>\n",
        "      <td>64</td>\n",
@@ -313,7 +313,7 @@
        "      <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <td>3</td>\n",
+       "      <th>3</th>\n",
        "      <td>1</td>\n",
        "      <td>89</td>\n",
        "      <td>66</td>\n",
@@ -325,7 +325,7 @@
        "      <td>0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
-       "      <td>4</td>\n",
+       "      <th>4</th>\n",
        "      <td>0</td>\n",
        "      <td>137</td>\n",
        "      <td>40</td>\n",
@@ -511,7 +511,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 10,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -545,7 +545,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 18,
+   "execution_count": 11,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -571,7 +571,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 19,
+   "execution_count": 12,
    "metadata": {},
    "outputs": [
     {
@@ -580,314 +580,314 @@
      "text": [
       "Train on 768 samples\n",
       "Epoch 1/150\n",
-      "768/768 [==============================] - 0s 441us/sample - loss: 0.6796 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 380us/sample - loss: 57.3837 - accuracy: 0.6510\n",
       "Epoch 2/150\n",
-      "768/768 [==============================] - 0s 65us/sample - loss: 0.6693 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 54.1238 - accuracy: 0.6510\n",
       "Epoch 3/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6572 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 35us/sample - loss: 50.8225 - accuracy: 0.6510\n",
       "Epoch 4/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6538 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 47.5200 - accuracy: 0.6510\n",
       "Epoch 5/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6517 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 44.2244 - accuracy: 0.6510\n",
       "Epoch 6/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6509 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 40.9090 - accuracy: 0.6510\n",
       "Epoch 7/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6493 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 38us/sample - loss: 37.6054 - accuracy: 0.6510\n",
       "Epoch 8/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6486 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 34.2639 - accuracy: 0.6510\n",
       "Epoch 9/150\n",
-      "768/768 [==============================] - 0s 58us/sample - loss: 0.6482 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 30.9895 - accuracy: 0.6523\n",
       "Epoch 10/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6473 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 27.7513 - accuracy: 0.6523\n",
       "Epoch 11/150\n",
-      "768/768 [==============================] - 0s 57us/sample - loss: 0.6468 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 24.4761 - accuracy: 0.6510\n",
       "Epoch 12/150\n",
-      "768/768 [==============================] - 0s 59us/sample - loss: 0.6469 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 27us/sample - loss: 21.2083 - accuracy: 0.6536\n",
       "Epoch 13/150\n",
-      "768/768 [==============================] - 0s 58us/sample - loss: 0.6461 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 18.1693 - accuracy: 0.6523\n",
       "Epoch 14/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6472 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 15.3539 - accuracy: 0.6302\n",
       "Epoch 15/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6459 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 12.9648 - accuracy: 0.6081\n",
       "Epoch 16/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6457 - accuracy: 0.6576\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 11.1331 - accuracy: 0.5924\n",
       "Epoch 17/150\n",
-      "768/768 [==============================] - 0s 59us/sample - loss: 0.6455 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 9.6704 - accuracy: 0.5755\n",
       "Epoch 18/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6455 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 35us/sample - loss: 8.6484 - accuracy: 0.5495\n",
       "Epoch 19/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6453 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 7.8604 - accuracy: 0.5417\n",
       "Epoch 20/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6453 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 7.3052 - accuracy: 0.5326\n",
       "Epoch 21/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6452 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 6.9354 - accuracy: 0.5169\n",
       "Epoch 22/150\n",
-      "768/768 [==============================] - 0s 59us/sample - loss: 0.6452 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 6.5929 - accuracy: 0.5091\n",
       "Epoch 23/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6453 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 6.3147 - accuracy: 0.5143\n",
       "Epoch 24/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6450 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 6.0452 - accuracy: 0.5117\n",
       "Epoch 25/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6450 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 5.7987 - accuracy: 0.5091\n",
       "Epoch 26/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6450 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 5.5536 - accuracy: 0.5156\n",
       "Epoch 27/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6449 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 5.3301 - accuracy: 0.5104\n",
       "Epoch 28/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6448 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 5.1123 - accuracy: 0.5156\n",
       "Epoch 29/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6448 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 4.9039 - accuracy: 0.5208\n",
       "Epoch 30/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6447 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 4.7105 - accuracy: 0.5182\n",
       "Epoch 31/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6451 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 36us/sample - loss: 4.5324 - accuracy: 0.5143\n",
       "Epoch 32/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6446 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 4.3495 - accuracy: 0.5247\n",
       "Epoch 33/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6446 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 4.1997 - accuracy: 0.5339\n",
       "Epoch 34/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6445 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 4.0505 - accuracy: 0.5391\n",
       "Epoch 35/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6447 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 27us/sample - loss: 3.9162 - accuracy: 0.5443\n",
       "Epoch 36/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6446 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 3.7956 - accuracy: 0.5495\n",
       "Epoch 37/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6446 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 3.6760 - accuracy: 0.5482\n",
       "Epoch 38/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6447 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 3.5736 - accuracy: 0.5521\n",
       "Epoch 39/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6442 - accuracy: 0.6562\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 3.4710 - accuracy: 0.5495\n",
       "Epoch 40/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6445 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 3.3770 - accuracy: 0.5521\n",
       "Epoch 41/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6443 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 3.2860 - accuracy: 0.5638\n",
       "Epoch 42/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6448 - accuracy: 0.6497\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 3.1969 - accuracy: 0.5638\n",
       "Epoch 43/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6440 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 3.1190 - accuracy: 0.5638\n",
       "Epoch 44/150\n",
-      "768/768 [==============================] - 0s 65us/sample - loss: 0.6430 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 3.0240 - accuracy: 0.5755\n",
       "Epoch 45/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6432 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 2.9418 - accuracy: 0.5716\n",
       "Epoch 46/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6420 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 2.8643 - accuracy: 0.5781\n",
       "Epoch 47/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6407 - accuracy: 0.6471\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 2.7806 - accuracy: 0.5807\n",
       "Epoch 48/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6421 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 2.7080 - accuracy: 0.5742\n",
       "Epoch 49/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6390 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 2.6293 - accuracy: 0.5859\n",
       "Epoch 50/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6410 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 2.5525 - accuracy: 0.5820\n",
       "Epoch 51/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6394 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 2.4908 - accuracy: 0.5794\n",
       "Epoch 52/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6390 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 2.4075 - accuracy: 0.5794\n",
       "Epoch 53/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6369 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 2.3375 - accuracy: 0.5911\n",
       "Epoch 54/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6365 - accuracy: 0.6576\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 2.2697 - accuracy: 0.5977\n",
       "Epoch 55/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6361 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 2.2085 - accuracy: 0.6016\n",
       "Epoch 56/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6357 - accuracy: 0.6589\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 2.1371 - accuracy: 0.6042\n",
       "Epoch 57/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6354 - accuracy: 0.6562\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 2.0749 - accuracy: 0.6094\n",
       "Epoch 58/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6350 - accuracy: 0.6523\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 2.0125 - accuracy: 0.6068\n",
       "Epoch 59/150\n",
-      "768/768 [==============================] - 0s 59us/sample - loss: 0.6345 - accuracy: 0.6562\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.9657 - accuracy: 0.6146\n",
       "Epoch 60/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6366 - accuracy: 0.6497\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 1.8924 - accuracy: 0.6107\n",
       "Epoch 61/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6357 - accuracy: 0.6562\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.8399 - accuracy: 0.6185\n",
       "Epoch 62/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6338 - accuracy: 0.6549\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 1.7905 - accuracy: 0.6133\n",
       "Epoch 63/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6338 - accuracy: 0.6589\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 1.7405 - accuracy: 0.6198\n",
       "Epoch 64/150\n",
-      "768/768 [==============================] - 0s 66us/sample - loss: 0.6328 - accuracy: 0.6536\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 1.6765 - accuracy: 0.6211\n",
       "Epoch 65/150\n",
-      "768/768 [==============================] - 0s 66us/sample - loss: 0.6326 - accuracy: 0.6589\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.6289 - accuracy: 0.6224\n",
       "Epoch 66/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6320 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 1.5859 - accuracy: 0.6289\n",
       "Epoch 67/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6315 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.5375 - accuracy: 0.6237\n",
       "Epoch 68/150\n",
-      "768/768 [==============================] - 0s 65us/sample - loss: 0.6314 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 27us/sample - loss: 1.4842 - accuracy: 0.6380\n",
       "Epoch 69/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6306 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.4501 - accuracy: 0.6237\n",
       "Epoch 70/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.6303 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.3984 - accuracy: 0.6341\n",
       "Epoch 71/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6299 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 1.3583 - accuracy: 0.6315\n",
       "Epoch 72/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6296 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.3179 - accuracy: 0.6406\n",
       "Epoch 73/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6299 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 1.2803 - accuracy: 0.6328\n",
       "Epoch 74/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6290 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 1.2434 - accuracy: 0.6367\n",
       "Epoch 75/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6291 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.2037 - accuracy: 0.6406\n",
       "Epoch 76/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6286 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 1.1703 - accuracy: 0.6419\n",
       "Epoch 77/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6283 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 1.1342 - accuracy: 0.6484\n",
       "Epoch 78/150\n",
-      "768/768 [==============================] - 0s 65us/sample - loss: 0.6275 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 1.1064 - accuracy: 0.6445\n",
       "Epoch 79/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6249 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 1.0707 - accuracy: 0.6497\n",
       "Epoch 80/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6207 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 1.0502 - accuracy: 0.6471\n",
       "Epoch 81/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.6146 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 1.0092 - accuracy: 0.6471\n",
       "Epoch 82/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6101 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.9842 - accuracy: 0.6536\n",
       "Epoch 83/150\n",
-      "768/768 [==============================] - 0s 69us/sample - loss: 0.6076 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.9545 - accuracy: 0.6549\n",
       "Epoch 84/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6070 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.9326 - accuracy: 0.6562\n",
       "Epoch 85/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6037 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.9030 - accuracy: 0.6536\n",
       "Epoch 86/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6058 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.8844 - accuracy: 0.6471\n",
       "Epoch 87/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6026 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.8566 - accuracy: 0.6667\n",
       "Epoch 88/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.6050 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.8425 - accuracy: 0.6471\n",
       "Epoch 89/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6014 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.8383 - accuracy: 0.6615\n",
       "Epoch 90/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6011 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.8013 - accuracy: 0.6693\n",
       "Epoch 91/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5990 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.7827 - accuracy: 0.6706\n",
       "Epoch 92/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.6027 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.7655 - accuracy: 0.6628\n",
       "Epoch 93/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5987 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.7512 - accuracy: 0.6667\n",
       "Epoch 94/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.6013 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.7434 - accuracy: 0.6680\n",
       "Epoch 95/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5984 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.7255 - accuracy: 0.6693\n",
       "Epoch 96/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5979 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.7157 - accuracy: 0.6693\n",
       "Epoch 97/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5977 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.7098 - accuracy: 0.6680\n",
       "Epoch 98/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5968 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.7024 - accuracy: 0.6732\n",
       "Epoch 99/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5957 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6883 - accuracy: 0.6615\n",
       "Epoch 100/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5955 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6794 - accuracy: 0.6719\n",
       "Epoch 101/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5963 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 0.6704 - accuracy: 0.6784\n",
       "Epoch 102/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5923 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 0.6768 - accuracy: 0.6667\n",
       "Epoch 103/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5957 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6674 - accuracy: 0.6693\n",
       "Epoch 104/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5941 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6553 - accuracy: 0.6758\n",
       "Epoch 105/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.5925 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 0.6500 - accuracy: 0.6758\n",
       "Epoch 106/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5923 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6491 - accuracy: 0.6706\n",
       "Epoch 107/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5916 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6483 - accuracy: 0.6797\n",
       "Epoch 108/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5925 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 35us/sample - loss: 0.6461 - accuracy: 0.6732\n",
       "Epoch 109/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5914 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6426 - accuracy: 0.6693\n",
       "Epoch 110/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5904 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6291 - accuracy: 0.6901\n",
       "Epoch 111/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5901 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6286 - accuracy: 0.6914\n",
       "Epoch 112/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5949 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6266 - accuracy: 0.7031\n",
       "Epoch 113/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5920 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6277 - accuracy: 0.6745\n",
       "Epoch 114/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5904 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 0.6246 - accuracy: 0.6862\n",
       "Epoch 115/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5902 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 0.6218 - accuracy: 0.6992\n",
       "Epoch 116/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5893 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6203 - accuracy: 0.6901\n",
       "Epoch 117/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5892 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6168 - accuracy: 0.6940\n",
       "Epoch 118/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.5889 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6196 - accuracy: 0.6914\n",
       "Epoch 119/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5877 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6168 - accuracy: 0.6979\n",
       "Epoch 120/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.5878 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6135 - accuracy: 0.6927\n",
       "Epoch 121/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5880 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 0.6153 - accuracy: 0.6927\n",
       "Epoch 122/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5869 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6139 - accuracy: 0.6901\n",
       "Epoch 123/150\n",
-      "768/768 [==============================] - 0s 60us/sample - loss: 0.5872 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6122 - accuracy: 0.7044\n",
       "Epoch 124/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5874 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 0.6161 - accuracy: 0.7005\n",
       "Epoch 125/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5902 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6094 - accuracy: 0.7096\n",
       "Epoch 126/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5862 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6154 - accuracy: 0.6992\n",
       "Epoch 127/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5864 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6104 - accuracy: 0.6914\n",
       "Epoch 128/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5858 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6120 - accuracy: 0.6966\n",
       "Epoch 129/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5851 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6070 - accuracy: 0.6836\n",
       "Epoch 130/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5868 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6057 - accuracy: 0.7031\n",
       "Epoch 131/150\n",
-      "768/768 [==============================] - 0s 70us/sample - loss: 0.5855 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6091 - accuracy: 0.6901\n",
       "Epoch 132/150\n",
-      "768/768 [==============================] - 0s 66us/sample - loss: 0.5862 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 29us/sample - loss: 0.6025 - accuracy: 0.7109\n",
       "Epoch 133/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5842 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6043 - accuracy: 0.6914\n",
       "Epoch 134/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5866 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6057 - accuracy: 0.7018\n",
       "Epoch 135/150\n",
-      "768/768 [==============================] - 0s 59us/sample - loss: 0.5841 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6053 - accuracy: 0.6966\n",
       "Epoch 136/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5836 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 0.6060 - accuracy: 0.6888\n",
       "Epoch 137/150\n",
-      "768/768 [==============================] - 0s 61us/sample - loss: 0.5852 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6015 - accuracy: 0.7083\n",
       "Epoch 138/150\n",
-      "768/768 [==============================] - 0s 62us/sample - loss: 0.5845 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6051 - accuracy: 0.6927\n",
       "Epoch 139/150\n",
-      "768/768 [==============================] - 0s 75us/sample - loss: 0.5840 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6031 - accuracy: 0.7083\n",
       "Epoch 140/150\n",
-      "768/768 [==============================] - 0s 65us/sample - loss: 0.5836 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6059 - accuracy: 0.6719\n",
       "Epoch 141/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5843 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6040 - accuracy: 0.6901\n",
       "Epoch 142/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5828 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6100 - accuracy: 0.6953\n",
       "Epoch 143/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5829 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 34us/sample - loss: 0.6027 - accuracy: 0.6940\n",
       "Epoch 144/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5829 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6034 - accuracy: 0.6914\n",
       "Epoch 145/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5818 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6058 - accuracy: 0.7018\n",
       "Epoch 146/150\n",
-      "768/768 [==============================] - 0s 63us/sample - loss: 0.5832 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6109 - accuracy: 0.6875\n",
       "Epoch 147/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5813 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 33us/sample - loss: 0.6012 - accuracy: 0.6992\n",
       "Epoch 148/150\n",
-      "768/768 [==============================] - 0s 65us/sample - loss: 0.5832 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6154 - accuracy: 0.6927\n",
       "Epoch 149/150\n",
-      "768/768 [==============================] - 0s 66us/sample - loss: 0.5808 - accuracy: 0.6510\n",
+      "768/768 [==============================] - 0s 30us/sample - loss: 0.6057 - accuracy: 0.6914\n",
       "Epoch 150/150\n",
-      "768/768 [==============================] - 0s 64us/sample - loss: 0.5806 - accuracy: 0.6510\n"
+      "768/768 [==============================] - 0s 31us/sample - loss: 0.6008 - accuracy: 0.7005\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fb4cc230668>"
+       "<tensorflow.python.keras.callbacks.History at 0x1f225754080>"
       ]
      },
-     "execution_count": 19,
+     "execution_count": 12,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -898,7 +898,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 14,
    "metadata": {},
    "outputs": [
     {
@@ -907,7 +907,7 @@
        "(768,)"
       ]
      },
-     "execution_count": 13,
+     "execution_count": 14,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -925,42 +925,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
-       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
-       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.])"
-      ]
-     },
-     "execution_count": 14,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "y[:50]"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 15,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "0.3489583333333333"
-      ]
-     },
-     "execution_count": 15,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Predicting never diabetes\n",
     "sum(y) / len(y) "
@@ -968,18 +944,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 20,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "768/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 142us/sample - loss: 0.6205 - accuracy: 0.6510\n",
-      "accuracy: 65.10416865348816\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "scores = model.evaluate(X,y)\n",
     "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
@@ -1036,34 +1003,13 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 22,
+   "execution_count": null,
    "metadata": {
     "colab": {},
     "colab_type": "code",
     "id": "6W2Sc7-LzQo_"
    },
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Model: \"3LayerJunk\"\n",
-      "_________________________________________________________________\n",
-      "Layer (type)                 Output Shape              Param #   \n",
-      "=================================================================\n",
-      "Dense1 (Dense)               (None, 4)                 36        \n",
-      "_________________________________________________________________\n",
-      "dense_6 (Dense)              (None, 3)                 15        \n",
-      "_________________________________________________________________\n",
-      "dense_7 (Dense)              (None, 1)                 4         \n",
-      "=================================================================\n",
-      "Total params: 55\n",
-      "Trainable params: 55\n",
-      "Non-trainable params: 0\n",
-      "_________________________________________________________________\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Tell me your ideas\n",
     "\n",
@@ -1082,38 +1028,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 24,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fb4306ce2e8>"
-      ]
-     },
-     "execution_count": 24,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "model_improved.fit(X, y, epochs=150, verbose=False) # What parameters can I specify here?"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 28,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "768/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 68us/sample - loss: 0.5155 - accuracy: 0.7578\n",
-      "accuracy: 75.78125\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "scores = model_improved.evaluate(X,y)\n",
     "print(f\"{model_improved.metrics_names[1]}: {scores[1]*100}\")"
@@ -1128,32 +1054,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 29,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Model: \"4LayerJunk\"\n",
-      "_________________________________________________________________\n",
-      "Layer (type)                 Output Shape              Param #   \n",
-      "=================================================================\n",
-      "Dense1 (Dense)               (None, 4)                 36        \n",
-      "_________________________________________________________________\n",
-      "dense_8 (Dense)              (None, 3)                 15        \n",
-      "_________________________________________________________________\n",
-      "dense_9 (Dense)              (None, 3)                 12        \n",
-      "_________________________________________________________________\n",
-      "dense_10 (Dense)             (None, 1)                 4         \n",
-      "=================================================================\n",
-      "Total params: 67\n",
-      "Trainable params: 67\n",
-      "Non-trainable params: 0\n",
-      "_________________________________________________________________\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Tell me your ideas\n",
     "\n",
@@ -1173,47 +1076,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 30,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fb430342ac8>"
-      ]
-     },
-     "execution_count": 30,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "model_improved.fit(X,y, epochs=250, verbose=False)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 31,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "768/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 169us/sample - loss: 0.6716 - accuracy: 0.6510\n"
-     ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "[0.639621468881766, 0.6510417]"
-      ]
-     },
-     "execution_count": 31,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "model_improved.evaluate(X,y)\n",
     "#print(f\"{model_improved.metrics_names[1]}: {scores[1]*100}\")"
@@ -1228,32 +1102,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 32,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Model: \"EvenNuerons4LayerJunk\"\n",
-      "_________________________________________________________________\n",
-      "Layer (type)                 Output Shape              Param #   \n",
-      "=================================================================\n",
-      "Dense1 (Dense)               (None, 8)                 72        \n",
-      "_________________________________________________________________\n",
-      "dense_11 (Dense)             (None, 8)                 72        \n",
-      "_________________________________________________________________\n",
-      "dense_12 (Dense)             (None, 8)                 72        \n",
-      "_________________________________________________________________\n",
-      "dense_13 (Dense)             (None, 1)                 9         \n",
-      "=================================================================\n",
-      "Total params: 225\n",
-      "Trainable params: 225\n",
-      "Non-trainable params: 0\n",
-      "_________________________________________________________________\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Tell me your ideas\n",
     "\n",
@@ -1273,554 +1124,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 37,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Train on 691 samples, validate on 77 samples\n",
-      "Epoch 1/250\n",
-      "691/691 [==============================] - 0s 132us/sample - loss: 0.4450 - accuracy: 0.7844 - val_loss: 0.5430 - val_accuracy: 0.7532\n",
-      "Epoch 2/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4350 - accuracy: 0.7931 - val_loss: 0.5368 - val_accuracy: 0.7662\n",
-      "Epoch 3/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4341 - accuracy: 0.8003 - val_loss: 0.5612 - val_accuracy: 0.7403\n",
-      "Epoch 4/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4432 - accuracy: 0.7786 - val_loss: 0.5810 - val_accuracy: 0.7273\n",
-      "Epoch 5/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4378 - accuracy: 0.7858 - val_loss: 0.5426 - val_accuracy: 0.7922\n",
-      "Epoch 6/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4341 - accuracy: 0.7815 - val_loss: 0.5429 - val_accuracy: 0.7403\n",
-      "Epoch 7/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4304 - accuracy: 0.8075 - val_loss: 0.5942 - val_accuracy: 0.6883\n",
-      "Epoch 8/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4388 - accuracy: 0.7829 - val_loss: 0.5631 - val_accuracy: 0.7143\n",
-      "Epoch 9/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4377 - accuracy: 0.7728 - val_loss: 0.5333 - val_accuracy: 0.8052\n",
-      "Epoch 10/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4476 - accuracy: 0.7815 - val_loss: 0.5622 - val_accuracy: 0.7273\n",
-      "Epoch 11/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4351 - accuracy: 0.7945 - val_loss: 0.6104 - val_accuracy: 0.6623\n",
-      "Epoch 12/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4468 - accuracy: 0.7902 - val_loss: 0.5943 - val_accuracy: 0.6883\n",
-      "Epoch 13/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4304 - accuracy: 0.7873 - val_loss: 0.5597 - val_accuracy: 0.7273\n",
-      "Epoch 14/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4454 - accuracy: 0.7800 - val_loss: 0.5892 - val_accuracy: 0.6883\n",
-      "Epoch 15/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4544 - accuracy: 0.7670 - val_loss: 0.5805 - val_accuracy: 0.7662\n",
-      "Epoch 16/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4406 - accuracy: 0.7829 - val_loss: 0.5796 - val_accuracy: 0.7273\n",
-      "Epoch 17/250\n",
-      "691/691 [==============================] - 0s 116us/sample - loss: 0.4325 - accuracy: 0.7887 - val_loss: 0.5502 - val_accuracy: 0.7662\n",
-      "Epoch 18/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4376 - accuracy: 0.7800 - val_loss: 0.5716 - val_accuracy: 0.7403\n",
-      "Epoch 19/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4293 - accuracy: 0.7844 - val_loss: 0.5916 - val_accuracy: 0.7013\n",
-      "Epoch 20/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4372 - accuracy: 0.7902 - val_loss: 0.5735 - val_accuracy: 0.7403\n",
-      "Epoch 21/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4367 - accuracy: 0.7844 - val_loss: 0.5870 - val_accuracy: 0.7013\n",
-      "Epoch 22/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4360 - accuracy: 0.7916 - val_loss: 0.5698 - val_accuracy: 0.7273\n",
-      "Epoch 23/250\n",
-      "691/691 [==============================] - 0s 101us/sample - loss: 0.4375 - accuracy: 0.7873 - val_loss: 0.5782 - val_accuracy: 0.7013\n",
-      "Epoch 24/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4428 - accuracy: 0.7887 - val_loss: 0.5882 - val_accuracy: 0.6883\n",
-      "Epoch 25/250\n",
-      "691/691 [==============================] - 0s 101us/sample - loss: 0.4320 - accuracy: 0.7916 - val_loss: 0.5487 - val_accuracy: 0.7922\n",
-      "Epoch 26/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4361 - accuracy: 0.7959 - val_loss: 0.6589 - val_accuracy: 0.6623\n",
-      "Epoch 27/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4681 - accuracy: 0.7902 - val_loss: 0.5854 - val_accuracy: 0.7143\n",
-      "Epoch 28/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4400 - accuracy: 0.7800 - val_loss: 0.5625 - val_accuracy: 0.7662\n",
-      "Epoch 29/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4297 - accuracy: 0.7858 - val_loss: 0.5486 - val_accuracy: 0.7792\n",
-      "Epoch 30/250\n",
-      "691/691 [==============================] - 0s 101us/sample - loss: 0.4304 - accuracy: 0.7931 - val_loss: 0.5471 - val_accuracy: 0.7922\n",
-      "Epoch 31/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4308 - accuracy: 0.7916 - val_loss: 0.5568 - val_accuracy: 0.7662\n",
-      "Epoch 32/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4303 - accuracy: 0.8017 - val_loss: 0.5375 - val_accuracy: 0.7792\n",
-      "Epoch 33/250\n",
-      "691/691 [==============================] - 0s 102us/sample - loss: 0.4359 - accuracy: 0.7800 - val_loss: 0.5793 - val_accuracy: 0.7013\n",
-      "Epoch 34/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4341 - accuracy: 0.7873 - val_loss: 0.5466 - val_accuracy: 0.7273\n",
-      "Epoch 35/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4293 - accuracy: 0.7858 - val_loss: 0.5446 - val_accuracy: 0.7792\n",
-      "Epoch 36/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4400 - accuracy: 0.7887 - val_loss: 0.5486 - val_accuracy: 0.7273\n",
-      "Epoch 37/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4373 - accuracy: 0.7815 - val_loss: 0.5552 - val_accuracy: 0.7532\n",
-      "Epoch 38/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4380 - accuracy: 0.7916 - val_loss: 0.5937 - val_accuracy: 0.6753\n",
-      "Epoch 39/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4321 - accuracy: 0.7902 - val_loss: 0.5762 - val_accuracy: 0.7013\n",
-      "Epoch 40/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4344 - accuracy: 0.7844 - val_loss: 0.5833 - val_accuracy: 0.7143\n",
-      "Epoch 41/250\n",
-      "691/691 [==============================] - 0s 122us/sample - loss: 0.4319 - accuracy: 0.7945 - val_loss: 0.5713 - val_accuracy: 0.7403\n",
-      "Epoch 42/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4466 - accuracy: 0.7713 - val_loss: 0.5554 - val_accuracy: 0.7273\n",
-      "Epoch 43/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4512 - accuracy: 0.7699 - val_loss: 0.5515 - val_accuracy: 0.7662\n",
-      "Epoch 44/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4295 - accuracy: 0.7916 - val_loss: 0.5527 - val_accuracy: 0.7532\n",
-      "Epoch 45/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4415 - accuracy: 0.7858 - val_loss: 0.5779 - val_accuracy: 0.7143\n",
-      "Epoch 46/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4273 - accuracy: 0.7988 - val_loss: 0.5882 - val_accuracy: 0.7013\n",
-      "Epoch 47/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4365 - accuracy: 0.7916 - val_loss: 0.5730 - val_accuracy: 0.7143\n",
-      "Epoch 48/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4475 - accuracy: 0.7771 - val_loss: 0.6129 - val_accuracy: 0.7143\n",
-      "Epoch 49/250\n",
-      "691/691 [==============================] - 0s 101us/sample - loss: 0.4330 - accuracy: 0.7844 - val_loss: 0.5698 - val_accuracy: 0.7013\n",
-      "Epoch 50/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4265 - accuracy: 0.7786 - val_loss: 0.6032 - val_accuracy: 0.6753\n",
-      "Epoch 51/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4355 - accuracy: 0.7873 - val_loss: 0.6040 - val_accuracy: 0.6623\n",
-      "Epoch 52/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4307 - accuracy: 0.7829 - val_loss: 0.5508 - val_accuracy: 0.7662\n",
-      "Epoch 53/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4514 - accuracy: 0.7786 - val_loss: 0.5587 - val_accuracy: 0.7403\n",
-      "Epoch 54/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4318 - accuracy: 0.7902 - val_loss: 0.5885 - val_accuracy: 0.7143\n",
-      "Epoch 55/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4512 - accuracy: 0.7815 - val_loss: 0.5813 - val_accuracy: 0.7143\n",
-      "Epoch 56/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4363 - accuracy: 0.7844 - val_loss: 0.5499 - val_accuracy: 0.7662\n",
-      "Epoch 57/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4327 - accuracy: 0.7902 - val_loss: 0.5899 - val_accuracy: 0.7013\n",
-      "Epoch 58/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4376 - accuracy: 0.7945 - val_loss: 0.5644 - val_accuracy: 0.7143\n",
-      "Epoch 59/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4308 - accuracy: 0.7902 - val_loss: 0.5926 - val_accuracy: 0.6623\n",
-      "Epoch 60/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4364 - accuracy: 0.7844 - val_loss: 0.5701 - val_accuracy: 0.7143\n",
-      "Epoch 61/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4334 - accuracy: 0.7945 - val_loss: 0.5964 - val_accuracy: 0.6753\n",
-      "Epoch 62/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4349 - accuracy: 0.7829 - val_loss: 0.5404 - val_accuracy: 0.7532\n",
-      "Epoch 63/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4290 - accuracy: 0.7959 - val_loss: 0.5447 - val_accuracy: 0.7922\n",
-      "Epoch 64/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4327 - accuracy: 0.7959 - val_loss: 0.5909 - val_accuracy: 0.7013\n",
-      "Epoch 65/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4352 - accuracy: 0.7916 - val_loss: 0.5384 - val_accuracy: 0.7662\n",
-      "Epoch 66/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4386 - accuracy: 0.7800 - val_loss: 0.5673 - val_accuracy: 0.7532\n",
-      "Epoch 67/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4465 - accuracy: 0.7800 - val_loss: 0.5630 - val_accuracy: 0.7403\n",
-      "Epoch 68/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4288 - accuracy: 0.7887 - val_loss: 0.5608 - val_accuracy: 0.7403\n",
-      "Epoch 69/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4379 - accuracy: 0.7771 - val_loss: 0.5875 - val_accuracy: 0.7143\n",
-      "Epoch 70/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4208 - accuracy: 0.7931 - val_loss: 0.5458 - val_accuracy: 0.7532\n",
-      "Epoch 71/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4375 - accuracy: 0.7858 - val_loss: 0.5575 - val_accuracy: 0.7403\n",
-      "Epoch 72/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4269 - accuracy: 0.7902 - val_loss: 0.5839 - val_accuracy: 0.7143\n",
-      "Epoch 73/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4352 - accuracy: 0.7887 - val_loss: 0.5685 - val_accuracy: 0.7273\n",
-      "Epoch 74/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4353 - accuracy: 0.7800 - val_loss: 0.5833 - val_accuracy: 0.7013\n",
-      "Epoch 75/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4339 - accuracy: 0.7873 - val_loss: 0.6230 - val_accuracy: 0.6623\n",
-      "Epoch 76/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4517 - accuracy: 0.7844 - val_loss: 0.5550 - val_accuracy: 0.7662\n",
-      "Epoch 77/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4286 - accuracy: 0.7916 - val_loss: 0.5464 - val_accuracy: 0.7792\n",
-      "Epoch 78/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4311 - accuracy: 0.7829 - val_loss: 0.5428 - val_accuracy: 0.7792\n",
-      "Epoch 79/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4317 - accuracy: 0.7873 - val_loss: 0.5425 - val_accuracy: 0.7403\n",
-      "Epoch 80/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4291 - accuracy: 0.7844 - val_loss: 0.5598 - val_accuracy: 0.7532\n",
-      "Epoch 81/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4272 - accuracy: 0.7931 - val_loss: 0.5490 - val_accuracy: 0.7273\n",
-      "Epoch 82/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4406 - accuracy: 0.7786 - val_loss: 0.5553 - val_accuracy: 0.7143\n",
-      "Epoch 83/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4359 - accuracy: 0.7902 - val_loss: 0.5498 - val_accuracy: 0.7143\n",
-      "Epoch 84/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4296 - accuracy: 0.7887 - val_loss: 0.5613 - val_accuracy: 0.7403\n",
-      "Epoch 85/250\n",
-      "691/691 [==============================] - 0s 102us/sample - loss: 0.4312 - accuracy: 0.7829 - val_loss: 0.5609 - val_accuracy: 0.7273\n",
-      "Epoch 86/250\n",
-      "691/691 [==============================] - 0s 103us/sample - loss: 0.4378 - accuracy: 0.7829 - val_loss: 0.5826 - val_accuracy: 0.6883\n",
-      "Epoch 87/250\n",
-      "691/691 [==============================] - 0s 102us/sample - loss: 0.4405 - accuracy: 0.7815 - val_loss: 0.5750 - val_accuracy: 0.7143\n",
-      "Epoch 88/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4417 - accuracy: 0.7916 - val_loss: 0.5690 - val_accuracy: 0.7403\n",
-      "Epoch 89/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4369 - accuracy: 0.7815 - val_loss: 0.5858 - val_accuracy: 0.7143\n",
-      "Epoch 90/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4374 - accuracy: 0.7800 - val_loss: 0.5682 - val_accuracy: 0.7532\n",
-      "Epoch 91/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4356 - accuracy: 0.7844 - val_loss: 0.5611 - val_accuracy: 0.7013\n",
-      "Epoch 92/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4474 - accuracy: 0.7815 - val_loss: 0.6017 - val_accuracy: 0.7013\n",
-      "Epoch 93/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4294 - accuracy: 0.7945 - val_loss: 0.5852 - val_accuracy: 0.6883\n",
-      "Epoch 94/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4310 - accuracy: 0.7844 - val_loss: 0.5812 - val_accuracy: 0.7013\n",
-      "Epoch 95/250\n",
-      "691/691 [==============================] - 0s 101us/sample - loss: 0.4336 - accuracy: 0.7902 - val_loss: 0.5876 - val_accuracy: 0.7013\n",
-      "Epoch 96/250\n",
-      "691/691 [==============================] - 0s 100us/sample - loss: 0.4403 - accuracy: 0.7713 - val_loss: 0.6064 - val_accuracy: 0.6883\n",
-      "Epoch 97/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4504 - accuracy: 0.7800 - val_loss: 0.5883 - val_accuracy: 0.6883\n",
-      "Epoch 98/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4353 - accuracy: 0.7988 - val_loss: 0.5885 - val_accuracy: 0.6883\n",
-      "Epoch 99/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4357 - accuracy: 0.7757 - val_loss: 0.5428 - val_accuracy: 0.7922\n",
-      "Epoch 100/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4440 - accuracy: 0.7728 - val_loss: 0.5738 - val_accuracy: 0.7143\n",
-      "Epoch 101/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4327 - accuracy: 0.7829 - val_loss: 0.5985 - val_accuracy: 0.7013\n",
-      "Epoch 102/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4354 - accuracy: 0.7887 - val_loss: 0.5707 - val_accuracy: 0.7273\n",
-      "Epoch 103/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4529 - accuracy: 0.7829 - val_loss: 0.6645 - val_accuracy: 0.6364\n",
-      "Epoch 104/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4368 - accuracy: 0.7829 - val_loss: 0.5762 - val_accuracy: 0.7143\n",
-      "Epoch 105/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4291 - accuracy: 0.7887 - val_loss: 0.5867 - val_accuracy: 0.7143\n",
-      "Epoch 106/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4273 - accuracy: 0.7959 - val_loss: 0.6049 - val_accuracy: 0.6753\n",
-      "Epoch 107/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4344 - accuracy: 0.7945 - val_loss: 0.5747 - val_accuracy: 0.6883\n",
-      "Epoch 108/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4319 - accuracy: 0.7959 - val_loss: 0.6106 - val_accuracy: 0.6753\n",
-      "Epoch 109/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4308 - accuracy: 0.7887 - val_loss: 0.5425 - val_accuracy: 0.7662\n",
-      "Epoch 110/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4328 - accuracy: 0.7945 - val_loss: 0.5476 - val_accuracy: 0.7662\n",
-      "Epoch 111/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4234 - accuracy: 0.7959 - val_loss: 0.7005 - val_accuracy: 0.6234\n",
-      "Epoch 112/250\n",
-      "691/691 [==============================] - 0s 116us/sample - loss: 0.4554 - accuracy: 0.7728 - val_loss: 0.6428 - val_accuracy: 0.6623\n",
-      "Epoch 113/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4315 - accuracy: 0.7945 - val_loss: 0.5558 - val_accuracy: 0.7403\n",
-      "Epoch 114/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4346 - accuracy: 0.7916 - val_loss: 0.5521 - val_accuracy: 0.7273\n",
-      "Epoch 115/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4328 - accuracy: 0.8003 - val_loss: 0.5748 - val_accuracy: 0.7143\n",
-      "Epoch 116/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4331 - accuracy: 0.7988 - val_loss: 0.5338 - val_accuracy: 0.7792\n",
-      "Epoch 117/250\n",
-      "691/691 [==============================] - 0s 116us/sample - loss: 0.4311 - accuracy: 0.7959 - val_loss: 0.6022 - val_accuracy: 0.7143\n",
-      "Epoch 118/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4380 - accuracy: 0.7771 - val_loss: 0.5797 - val_accuracy: 0.7013\n",
-      "Epoch 119/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4304 - accuracy: 0.7858 - val_loss: 0.5868 - val_accuracy: 0.6753\n",
-      "Epoch 120/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4309 - accuracy: 0.7786 - val_loss: 0.5755 - val_accuracy: 0.7143\n",
-      "Epoch 121/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4284 - accuracy: 0.7887 - val_loss: 0.5662 - val_accuracy: 0.7403\n",
-      "Epoch 122/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4307 - accuracy: 0.7902 - val_loss: 0.5881 - val_accuracy: 0.7532\n",
-      "Epoch 123/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4381 - accuracy: 0.7873 - val_loss: 0.6287 - val_accuracy: 0.6623\n",
-      "Epoch 124/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4290 - accuracy: 0.7829 - val_loss: 0.5570 - val_accuracy: 0.7273\n",
-      "Epoch 125/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4253 - accuracy: 0.7873 - val_loss: 0.5644 - val_accuracy: 0.7273\n",
-      "Epoch 126/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4249 - accuracy: 0.7931 - val_loss: 0.5739 - val_accuracy: 0.7273\n",
-      "Epoch 127/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4247 - accuracy: 0.7959 - val_loss: 0.5544 - val_accuracy: 0.7273\n",
-      "Epoch 128/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4322 - accuracy: 0.7844 - val_loss: 0.5472 - val_accuracy: 0.7792\n",
-      "Epoch 129/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4285 - accuracy: 0.7916 - val_loss: 0.5964 - val_accuracy: 0.7143\n",
-      "Epoch 130/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4282 - accuracy: 0.7959 - val_loss: 0.5719 - val_accuracy: 0.7143\n",
-      "Epoch 131/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4262 - accuracy: 0.7873 - val_loss: 0.5588 - val_accuracy: 0.7273\n",
-      "Epoch 132/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4320 - accuracy: 0.7959 - val_loss: 0.5484 - val_accuracy: 0.7792\n",
-      "Epoch 133/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4397 - accuracy: 0.7844 - val_loss: 0.5603 - val_accuracy: 0.7662\n",
-      "Epoch 134/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4287 - accuracy: 0.7858 - val_loss: 0.5460 - val_accuracy: 0.7792\n",
-      "Epoch 135/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4373 - accuracy: 0.7916 - val_loss: 0.5439 - val_accuracy: 0.7403\n",
-      "Epoch 136/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4378 - accuracy: 0.7902 - val_loss: 0.5814 - val_accuracy: 0.7273\n",
-      "Epoch 137/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4412 - accuracy: 0.7858 - val_loss: 0.5689 - val_accuracy: 0.6883\n",
-      "Epoch 138/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4304 - accuracy: 0.7916 - val_loss: 0.5558 - val_accuracy: 0.7273\n",
-      "Epoch 139/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4278 - accuracy: 0.7974 - val_loss: 0.5501 - val_accuracy: 0.7792\n",
-      "Epoch 140/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4295 - accuracy: 0.7844 - val_loss: 0.5862 - val_accuracy: 0.6883\n",
-      "Epoch 141/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4348 - accuracy: 0.8003 - val_loss: 0.6358 - val_accuracy: 0.6753\n",
-      "Epoch 142/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4422 - accuracy: 0.7800 - val_loss: 0.5796 - val_accuracy: 0.7013\n",
-      "Epoch 143/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4374 - accuracy: 0.7988 - val_loss: 0.5926 - val_accuracy: 0.6883\n",
-      "Epoch 144/250\n",
-      "691/691 [==============================] - 0s 115us/sample - loss: 0.4365 - accuracy: 0.7844 - val_loss: 0.5565 - val_accuracy: 0.7403\n",
-      "Epoch 145/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4276 - accuracy: 0.7959 - val_loss: 0.5469 - val_accuracy: 0.7273\n",
-      "Epoch 146/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4273 - accuracy: 0.7945 - val_loss: 0.5813 - val_accuracy: 0.7273\n",
-      "Epoch 147/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4271 - accuracy: 0.7844 - val_loss: 0.5794 - val_accuracy: 0.7143\n",
-      "Epoch 148/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4253 - accuracy: 0.7974 - val_loss: 0.5377 - val_accuracy: 0.7662\n",
-      "Epoch 149/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4295 - accuracy: 0.7959 - val_loss: 0.5592 - val_accuracy: 0.7532\n",
-      "Epoch 150/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4446 - accuracy: 0.7873 - val_loss: 0.5472 - val_accuracy: 0.7922\n",
-      "Epoch 151/250\n",
-      "691/691 [==============================] - 0s 103us/sample - loss: 0.4275 - accuracy: 0.7959 - val_loss: 0.5726 - val_accuracy: 0.7273\n",
-      "Epoch 152/250\n",
-      "691/691 [==============================] - 0s 101us/sample - loss: 0.4350 - accuracy: 0.7887 - val_loss: 0.5549 - val_accuracy: 0.7273\n",
-      "Epoch 153/250\n",
-      "691/691 [==============================] - 0s 103us/sample - loss: 0.4352 - accuracy: 0.7887 - val_loss: 0.5623 - val_accuracy: 0.7532\n",
-      "Epoch 154/250\n",
-      "691/691 [==============================] - 0s 103us/sample - loss: 0.4381 - accuracy: 0.7873 - val_loss: 0.6157 - val_accuracy: 0.7143\n",
-      "Epoch 155/250\n",
-      "691/691 [==============================] - 0s 100us/sample - loss: 0.4451 - accuracy: 0.7786 - val_loss: 0.5586 - val_accuracy: 0.7143\n",
-      "Epoch 156/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4294 - accuracy: 0.7902 - val_loss: 0.5669 - val_accuracy: 0.7662\n",
-      "Epoch 157/250\n",
-      "691/691 [==============================] - 0s 104us/sample - loss: 0.4446 - accuracy: 0.7728 - val_loss: 0.5718 - val_accuracy: 0.7273\n",
-      "Epoch 158/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4357 - accuracy: 0.7945 - val_loss: 0.5919 - val_accuracy: 0.7273\n",
-      "Epoch 159/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4244 - accuracy: 0.7959 - val_loss: 0.6961 - val_accuracy: 0.5974\n",
-      "Epoch 160/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4460 - accuracy: 0.7815 - val_loss: 0.6046 - val_accuracy: 0.6753\n",
-      "Epoch 161/250\n",
-      "691/691 [==============================] - 0s 119us/sample - loss: 0.4392 - accuracy: 0.7800 - val_loss: 0.6032 - val_accuracy: 0.6753\n",
-      "Epoch 162/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4257 - accuracy: 0.7844 - val_loss: 0.6199 - val_accuracy: 0.7143\n",
-      "Epoch 163/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4304 - accuracy: 0.7916 - val_loss: 0.6495 - val_accuracy: 0.6364\n",
-      "Epoch 164/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4354 - accuracy: 0.7988 - val_loss: 0.5772 - val_accuracy: 0.7013\n",
-      "Epoch 165/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4322 - accuracy: 0.7757 - val_loss: 0.5907 - val_accuracy: 0.7403\n",
-      "Epoch 166/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4383 - accuracy: 0.7844 - val_loss: 0.5795 - val_accuracy: 0.7273\n",
-      "Epoch 167/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4323 - accuracy: 0.7931 - val_loss: 0.6260 - val_accuracy: 0.6623\n",
-      "Epoch 168/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4343 - accuracy: 0.7945 - val_loss: 0.5615 - val_accuracy: 0.7273\n",
-      "Epoch 169/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4289 - accuracy: 0.7974 - val_loss: 0.5703 - val_accuracy: 0.7273\n",
-      "Epoch 170/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4280 - accuracy: 0.7902 - val_loss: 0.5718 - val_accuracy: 0.7143\n",
-      "Epoch 171/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4257 - accuracy: 0.7873 - val_loss: 0.5567 - val_accuracy: 0.7662\n",
-      "Epoch 172/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4307 - accuracy: 0.7945 - val_loss: 0.5513 - val_accuracy: 0.7662\n",
-      "Epoch 173/250\n",
-      "691/691 [==============================] - 0s 125us/sample - loss: 0.4239 - accuracy: 0.8017 - val_loss: 0.5830 - val_accuracy: 0.7013\n",
-      "Epoch 174/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4255 - accuracy: 0.7974 - val_loss: 0.5419 - val_accuracy: 0.7532\n",
-      "Epoch 175/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4613 - accuracy: 0.7713 - val_loss: 0.5484 - val_accuracy: 0.7662\n",
-      "Epoch 176/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4456 - accuracy: 0.7916 - val_loss: 0.5627 - val_accuracy: 0.7273\n",
-      "Epoch 177/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4381 - accuracy: 0.7916 - val_loss: 0.5449 - val_accuracy: 0.7532\n",
-      "Epoch 178/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4512 - accuracy: 0.7771 - val_loss: 0.5280 - val_accuracy: 0.7922\n",
-      "Epoch 179/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4309 - accuracy: 0.7988 - val_loss: 0.5866 - val_accuracy: 0.7013\n",
-      "Epoch 180/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4230 - accuracy: 0.7873 - val_loss: 0.5618 - val_accuracy: 0.7532\n",
-      "Epoch 181/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4261 - accuracy: 0.7931 - val_loss: 0.5515 - val_accuracy: 0.7143\n",
-      "Epoch 182/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4267 - accuracy: 0.7974 - val_loss: 0.5404 - val_accuracy: 0.7792\n",
-      "Epoch 183/250\n",
-      "691/691 [==============================] - 0s 115us/sample - loss: 0.4336 - accuracy: 0.7974 - val_loss: 0.5765 - val_accuracy: 0.7013\n",
-      "Epoch 184/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4317 - accuracy: 0.7858 - val_loss: 0.5615 - val_accuracy: 0.7403\n",
-      "Epoch 185/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4294 - accuracy: 0.7916 - val_loss: 0.5702 - val_accuracy: 0.7403\n",
-      "Epoch 186/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4235 - accuracy: 0.7959 - val_loss: 0.5582 - val_accuracy: 0.7662\n",
-      "Epoch 187/250\n",
-      "691/691 [==============================] - 0s 102us/sample - loss: 0.4248 - accuracy: 0.7959 - val_loss: 0.5515 - val_accuracy: 0.7792\n",
-      "Epoch 188/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4296 - accuracy: 0.7916 - val_loss: 0.6143 - val_accuracy: 0.6753\n",
-      "Epoch 189/250\n",
-      "691/691 [==============================] - 0s 115us/sample - loss: 0.4264 - accuracy: 0.7887 - val_loss: 0.5686 - val_accuracy: 0.7403\n",
-      "Epoch 190/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4224 - accuracy: 0.8003 - val_loss: 0.5524 - val_accuracy: 0.7273\n",
-      "Epoch 191/250\n",
-      "691/691 [==============================] - 0s 103us/sample - loss: 0.4298 - accuracy: 0.7945 - val_loss: 0.5425 - val_accuracy: 0.7273\n",
-      "Epoch 192/250\n",
-      "691/691 [==============================] - 0s 105us/sample - loss: 0.4248 - accuracy: 0.7974 - val_loss: 0.5546 - val_accuracy: 0.7792\n",
-      "Epoch 193/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4309 - accuracy: 0.7916 - val_loss: 0.6047 - val_accuracy: 0.6883\n",
-      "Epoch 194/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4375 - accuracy: 0.8003 - val_loss: 0.5604 - val_accuracy: 0.7273\n",
-      "Epoch 195/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4221 - accuracy: 0.7959 - val_loss: 0.5587 - val_accuracy: 0.7532\n",
-      "Epoch 196/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4223 - accuracy: 0.7902 - val_loss: 0.5423 - val_accuracy: 0.7532\n",
-      "Epoch 197/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4304 - accuracy: 0.7916 - val_loss: 0.6116 - val_accuracy: 0.6623\n",
-      "Epoch 198/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4300 - accuracy: 0.7815 - val_loss: 0.5754 - val_accuracy: 0.6883\n",
-      "Epoch 199/250\n",
-      "691/691 [==============================] - 0s 116us/sample - loss: 0.4248 - accuracy: 0.7959 - val_loss: 0.5608 - val_accuracy: 0.7403\n",
-      "Epoch 200/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4347 - accuracy: 0.7815 - val_loss: 0.5849 - val_accuracy: 0.6883\n",
-      "Epoch 201/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4316 - accuracy: 0.7858 - val_loss: 0.6119 - val_accuracy: 0.7143\n",
-      "Epoch 202/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4332 - accuracy: 0.7902 - val_loss: 0.5676 - val_accuracy: 0.7532\n",
-      "Epoch 203/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4353 - accuracy: 0.7742 - val_loss: 0.5462 - val_accuracy: 0.7662\n",
-      "Epoch 204/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4218 - accuracy: 0.7959 - val_loss: 0.5536 - val_accuracy: 0.7013\n",
-      "Epoch 205/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4249 - accuracy: 0.7974 - val_loss: 0.5566 - val_accuracy: 0.7532\n",
-      "Epoch 206/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4309 - accuracy: 0.7988 - val_loss: 0.6227 - val_accuracy: 0.6753\n",
-      "Epoch 207/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4426 - accuracy: 0.8017 - val_loss: 0.5527 - val_accuracy: 0.7403\n",
-      "Epoch 208/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4240 - accuracy: 0.7945 - val_loss: 0.5741 - val_accuracy: 0.7013\n",
-      "Epoch 209/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4220 - accuracy: 0.8003 - val_loss: 0.5496 - val_accuracy: 0.7013\n",
-      "Epoch 210/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4335 - accuracy: 0.7858 - val_loss: 0.5671 - val_accuracy: 0.7273\n",
-      "Epoch 211/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4296 - accuracy: 0.7931 - val_loss: 0.5924 - val_accuracy: 0.6883\n",
-      "Epoch 212/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4445 - accuracy: 0.7771 - val_loss: 0.5769 - val_accuracy: 0.7013\n",
-      "Epoch 213/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4326 - accuracy: 0.7945 - val_loss: 0.5796 - val_accuracy: 0.7143\n",
-      "Epoch 214/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4225 - accuracy: 0.7974 - val_loss: 0.5894 - val_accuracy: 0.6883\n",
-      "Epoch 215/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4219 - accuracy: 0.7988 - val_loss: 0.5632 - val_accuracy: 0.7532\n",
-      "Epoch 216/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4329 - accuracy: 0.7844 - val_loss: 0.5483 - val_accuracy: 0.7403\n",
-      "Epoch 217/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4232 - accuracy: 0.8032 - val_loss: 0.5585 - val_accuracy: 0.7403\n",
-      "Epoch 218/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4485 - accuracy: 0.7728 - val_loss: 0.5537 - val_accuracy: 0.8052\n",
-      "Epoch 219/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4373 - accuracy: 0.7988 - val_loss: 0.5409 - val_accuracy: 0.7273\n",
-      "Epoch 220/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4216 - accuracy: 0.8003 - val_loss: 0.5648 - val_accuracy: 0.7273\n",
-      "Epoch 221/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4290 - accuracy: 0.7988 - val_loss: 0.5723 - val_accuracy: 0.7403\n",
-      "Epoch 222/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4247 - accuracy: 0.7916 - val_loss: 0.5825 - val_accuracy: 0.6883\n",
-      "Epoch 223/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4257 - accuracy: 0.7931 - val_loss: 0.5462 - val_accuracy: 0.7532\n",
-      "Epoch 224/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4377 - accuracy: 0.7931 - val_loss: 0.5473 - val_accuracy: 0.7403\n",
-      "Epoch 225/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4260 - accuracy: 0.7988 - val_loss: 0.5481 - val_accuracy: 0.7403\n",
-      "Epoch 226/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5611 - val_accuracy: 0.7403\n",
-      "Epoch 227/250\n",
-      "691/691 [==============================] - 0s 112us/sample - loss: 0.4325 - accuracy: 0.7988 - val_loss: 0.5663 - val_accuracy: 0.7532\n",
-      "Epoch 228/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4480 - accuracy: 0.7873 - val_loss: 0.5549 - val_accuracy: 0.7273\n",
-      "Epoch 229/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4264 - accuracy: 0.7931 - val_loss: 0.5778 - val_accuracy: 0.7403\n",
-      "Epoch 230/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4295 - accuracy: 0.7931 - val_loss: 0.5351 - val_accuracy: 0.7662\n",
-      "Epoch 231/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4355 - accuracy: 0.7873 - val_loss: 0.5499 - val_accuracy: 0.7662\n",
-      "Epoch 232/250\n",
-      "691/691 [==============================] - 0s 122us/sample - loss: 0.4338 - accuracy: 0.7945 - val_loss: 0.5842 - val_accuracy: 0.7273\n",
-      "Epoch 233/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4278 - accuracy: 0.7945 - val_loss: 0.5997 - val_accuracy: 0.6753\n",
-      "Epoch 234/250\n",
-      "691/691 [==============================] - 0s 111us/sample - loss: 0.4360 - accuracy: 0.7800 - val_loss: 0.5947 - val_accuracy: 0.6753\n",
-      "Epoch 235/250\n",
-      "691/691 [==============================] - 0s 113us/sample - loss: 0.4275 - accuracy: 0.7988 - val_loss: 0.5561 - val_accuracy: 0.7532\n",
-      "Epoch 236/250\n",
-      "691/691 [==============================] - 0s 114us/sample - loss: 0.4229 - accuracy: 0.7902 - val_loss: 0.5543 - val_accuracy: 0.7143\n",
-      "Epoch 237/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4232 - accuracy: 0.7887 - val_loss: 0.5724 - val_accuracy: 0.7273\n",
-      "Epoch 238/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5673 - val_accuracy: 0.7273\n",
-      "Epoch 239/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4350 - accuracy: 0.8017 - val_loss: 0.5767 - val_accuracy: 0.7273\n",
-      "Epoch 240/250\n",
-      "691/691 [==============================] - 0s 109us/sample - loss: 0.4240 - accuracy: 0.7844 - val_loss: 0.5844 - val_accuracy: 0.6883\n",
-      "Epoch 241/250\n",
-      "691/691 [==============================] - 0s 115us/sample - loss: 0.4246 - accuracy: 0.7988 - val_loss: 0.5608 - val_accuracy: 0.7532\n",
-      "Epoch 242/250\n",
-      "691/691 [==============================] - 0s 107us/sample - loss: 0.4225 - accuracy: 0.8017 - val_loss: 0.5395 - val_accuracy: 0.7403\n",
-      "Epoch 243/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4318 - accuracy: 0.7974 - val_loss: 0.5513 - val_accuracy: 0.7403\n",
-      "Epoch 244/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4237 - accuracy: 0.7974 - val_loss: 0.5530 - val_accuracy: 0.7143\n",
-      "Epoch 245/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4369 - accuracy: 0.7887 - val_loss: 0.5769 - val_accuracy: 0.7532\n",
-      "Epoch 246/250\n",
-      "691/691 [==============================] - 0s 110us/sample - loss: 0.4223 - accuracy: 0.7858 - val_loss: 0.5797 - val_accuracy: 0.7143\n",
-      "Epoch 247/250\n",
-      "691/691 [==============================] - 0s 108us/sample - loss: 0.4224 - accuracy: 0.7945 - val_loss: 0.5757 - val_accuracy: 0.7013\n",
-      "Epoch 248/250\n",
-      "691/691 [==============================] - 0s 119us/sample - loss: 0.4231 - accuracy: 0.7988 - val_loss: 0.5811 - val_accuracy: 0.7143\n",
-      "Epoch 249/250\n",
-      "691/691 [==============================] - 0s 115us/sample - loss: 0.4202 - accuracy: 0.7988 - val_loss: 0.5648 - val_accuracy: 0.7273\n",
-      "Epoch 250/250\n",
-      "691/691 [==============================] - 0s 106us/sample - loss: 0.4216 - accuracy: 0.7988 - val_loss: 0.5674 - val_accuracy: 0.7013\n"
-     ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7fafff74d048>"
-      ]
-     },
-     "execution_count": 37,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "model_improved.fit(X,y, epochs=250, validation_split=.10)"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 34,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "768/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 161us/sample - loss: 0.4706 - accuracy: 0.7630\n"
-     ]
-    },
-    {
-     "data": {
-      "text/plain": [
-       "[0.4735589859386285, 0.7630208]"
-      ]
-     },
-     "execution_count": 34,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "model_improved.evaluate(X,y)\n",
     "#print(f\"{model_improved.metrics_names[1]}: {scores[1]*100}\")"
@@ -2003,7 +1318,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 38,
+   "execution_count": null,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -2024,7 +1339,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 39,
+   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -2036,18 +1351,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 40,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
-      "11493376/11490434 [==============================] - 0s 0us/step\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "# Load the Data\n",
     "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
@@ -2055,20 +1361,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 41,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "(28, 28)"
-      ]
-     },
-     "execution_count": 41,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "X_train[0].shape"
    ]
@@ -2093,7 +1388,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 42,
+   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -2104,7 +1399,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 43,
+   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -2115,47 +1410,25 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 44,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "4"
-      ]
-     },
-     "execution_count": 44,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "y_train[2] "
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 45,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "4"
-      ]
-     },
-     "execution_count": 45,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "y_train[2]"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 47,
+   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -2168,54 +1441,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 48,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
-      ]
-     },
-     "execution_count": 48,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "y_train[2]"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 49,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Model: \"sequential_3\"\n",
-      "_________________________________________________________________\n",
-      "Layer (type)                 Output Shape              Param #   \n",
-      "=================================================================\n",
-      "dense_14 (Dense)             (None, 16)                12560     \n",
-      "_________________________________________________________________\n",
-      "dense_15 (Dense)             (None, 16)                272       \n",
-      "_________________________________________________________________\n",
-      "dense_16 (Dense)             (None, 16)                272       \n",
-      "_________________________________________________________________\n",
-      "dense_17 (Dense)             (None, 16)                272       \n",
-      "_________________________________________________________________\n",
-      "dense_18 (Dense)             (None, 10)                170       \n",
-      "=================================================================\n",
-      "Total params: 13,546\n",
-      "Trainable params: 13,546\n",
-      "Non-trainable params: 0\n",
-      "_________________________________________________________________\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "mnist_model = Sequential()\n",
     "\n",
@@ -2273,32 +1510,9 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 50,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "ename": "KeyboardInterrupt",
-     "evalue": "",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-50-fd0808510929>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(f'{mnist_model.metrics_names[1]}: {scores[1]*100}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
-      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "history = mnist_model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=False)\n",
     "scores = mnist_model.evaluate(X_test, y_test)\n",
@@ -2376,9 +1590,9 @@
    "version": "0.3.2"
   },
   "kernelspec": {
-   "display_name": "Python 3",
+   "display_name": "U4-S2-NN",
    "language": "python",
-   "name": "python3"
+   "name": "u4-s2-nn"
   },
   "language_info": {
    "codemirror_mode": {
@@ -2390,7 +1604,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.8"
+   "version": "3.7.0"
   },
   "toc-autonumbering": false,
   "toc-showmarkdowntxt": false
diff --git a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
index 4bb18e9..ef88a71 100644
--- a/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
+++ b/module4-Hyperparameter-Tuning/LS_DS_424_Hyperparameter_Tuning_Lecture.ipynb
@@ -81,9 +81,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
+   "execution_count": 2,
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
+      "57344/57026 [==============================] - 0s 1us/step\n"
+     ]
+    }
+   ],
    "source": [
     "from tensorflow.keras.datasets import boston_housing\n",
     "\n",
@@ -106,7 +115,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [
     {
@@ -151,7 +160,7 @@
     "\n",
     "scaler = StandardScaler()\n",
     "\n",
-    "x_train = scaler.fit_transform(x_train)\n",
+    "x_train = scaler.fit_transform(x_train) # normalize data \n",
     "x_test = scaler.transform(x_test)\n",
     "print(x_train[:10])"
    ]
@@ -170,7 +179,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 4,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -187,164 +196,164 @@
      "text": [
       "Train on 404 samples, validate on 102 samples\n",
       "Epoch 1/75\n",
-      "404/404 [==============================] - 2s 4ms/sample - loss: 498.2045 - mse: 498.2046 - mae: 20.2543 - val_loss: 421.5039 - val_mse: 421.5038 - val_mae: 18.3349\n",
+      "404/404 [==============================] - 1s 2ms/sample - loss: 511.2849 - mse: 511.2849 - mae: 20.6975 - val_loss: 433.5900 - val_mse: 433.5900 - val_mae: 18.9370\n",
       "Epoch 2/75\n",
-      "404/404 [==============================] - 0s 347us/sample - loss: 249.6985 - mse: 249.6985 - mae: 13.2672 - val_loss: 111.3743 - val_mse: 111.3743 - val_mae: 8.6210\n",
+      "404/404 [==============================] - 0s 168us/sample - loss: 257.4652 - mse: 257.4651 - mae: 13.7766 - val_loss: 111.8824 - val_mse: 111.8824 - val_mae: 9.0262\n",
       "Epoch 3/75\n",
-      "404/404 [==============================] - 0s 344us/sample - loss: 56.6755 - mse: 56.6755 - mae: 5.4817 - val_loss: 39.1997 - val_mse: 39.1997 - val_mae: 4.9872\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 58.0117 - mse: 58.0117 - mae: 5.6583 - val_loss: 40.8721 - val_mse: 40.8721 - val_mae: 5.0403\n",
       "Epoch 4/75\n",
-      "404/404 [==============================] - 0s 364us/sample - loss: 28.3243 - mse: 28.3243 - mae: 3.7054 - val_loss: 26.9866 - val_mse: 26.9866 - val_mae: 4.0796\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 33.4187 - mse: 33.4187 - mae: 4.2348 - val_loss: 31.5134 - val_mse: 31.5134 - val_mae: 4.5026\n",
       "Epoch 5/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 20.5281 - mse: 20.5281 - mae: 3.1209 - val_loss: 24.6172 - val_mse: 24.6172 - val_mae: 3.8052\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 25.2484 - mse: 25.2484 - mae: 3.5794 - val_loss: 28.5282 - val_mse: 28.5282 - val_mae: 4.2342\n",
       "Epoch 6/75\n",
-      "404/404 [==============================] - 0s 393us/sample - loss: 17.9283 - mse: 17.9283 - mae: 2.8665 - val_loss: 23.6524 - val_mse: 23.6524 - val_mae: 3.6746\n",
+      "404/404 [==============================] - 0s 168us/sample - loss: 22.1856 - mse: 22.1856 - mae: 3.3728 - val_loss: 26.3869 - val_mse: 26.3869 - val_mae: 4.0785\n",
       "Epoch 7/75\n",
-      "404/404 [==============================] - 0s 440us/sample - loss: 16.9179 - mse: 16.9179 - mae: 2.8781 - val_loss: 23.4620 - val_mse: 23.4620 - val_mae: 3.5778\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 19.7718 - mse: 19.7718 - mae: 3.1486 - val_loss: 25.3762 - val_mse: 25.3762 - val_mae: 3.8659\n",
       "Epoch 8/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 15.1579 - mse: 15.1579 - mae: 2.6440 - val_loss: 24.1374 - val_mse: 24.1374 - val_mae: 3.5929\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 18.2355 - mse: 18.2355 - mae: 3.0523 - val_loss: 25.1573 - val_mse: 25.1573 - val_mae: 3.7930\n",
       "Epoch 9/75\n",
-      "404/404 [==============================] - 0s 367us/sample - loss: 14.1717 - mse: 14.1717 - mae: 2.5937 - val_loss: 24.4829 - val_mse: 24.4829 - val_mae: 3.5639\n",
+      "404/404 [==============================] - 0s 151us/sample - loss: 17.0389 - mse: 17.0389 - mae: 2.8789 - val_loss: 24.7789 - val_mse: 24.7789 - val_mae: 3.6811\n",
       "Epoch 10/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 13.5002 - mse: 13.5002 - mae: 2.5633 - val_loss: 25.0170 - val_mse: 25.0170 - val_mae: 3.5601\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 15.9364 - mse: 15.9364 - mae: 2.8112 - val_loss: 23.3110 - val_mse: 23.3110 - val_mae: 3.5391\n",
       "Epoch 11/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.8641 - mse: 12.8641 - mae: 2.4963 - val_loss: 25.1162 - val_mse: 25.1162 - val_mae: 3.5449\n",
+      "404/404 [==============================] - 0s 166us/sample - loss: 14.9259 - mse: 14.9259 - mae: 2.6924 - val_loss: 25.5845 - val_mse: 25.5845 - val_mae: 3.6511\n",
       "Epoch 12/75\n",
-      "404/404 [==============================] - 0s 351us/sample - loss: 12.4033 - mse: 12.4033 - mae: 2.5224 - val_loss: 25.0382 - val_mse: 25.0382 - val_mae: 3.4858\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 14.4204 - mse: 14.4204 - mae: 2.7149 - val_loss: 24.1573 - val_mse: 24.1573 - val_mae: 3.5151\n",
       "Epoch 13/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 12.2653 - mse: 12.2653 - mae: 2.4637 - val_loss: 26.7274 - val_mse: 26.7274 - val_mae: 3.6054\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 13.5589 - mse: 13.5589 - mae: 2.5993 - val_loss: 26.0383 - val_mse: 26.0383 - val_mae: 3.5737\n",
       "Epoch 14/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 11.8249 - mse: 11.8249 - mae: 2.4648 - val_loss: 25.2347 - val_mse: 25.2347 - val_mae: 3.4602\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 12.8373 - mse: 12.8373 - mae: 2.5387 - val_loss: 23.7821 - val_mse: 23.7821 - val_mae: 3.3784\n",
       "Epoch 15/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 11.3965 - mse: 11.3965 - mae: 2.4134 - val_loss: 25.3070 - val_mse: 25.3070 - val_mae: 3.4305\n",
+      "404/404 [==============================] - 0s 153us/sample - loss: 12.4389 - mse: 12.4389 - mae: 2.5080 - val_loss: 24.4227 - val_mse: 24.4227 - val_mae: 3.3729\n",
       "Epoch 16/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 11.0982 - mse: 11.0982 - mae: 2.3616 - val_loss: 25.0599 - val_mse: 25.0599 - val_mae: 3.3784\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 11.8916 - mse: 11.8916 - mae: 2.4585 - val_loss: 24.8121 - val_mse: 24.8121 - val_mae: 3.3640\n",
       "Epoch 17/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 11.1969 - mse: 11.1969 - mae: 2.3806 - val_loss: 25.1976 - val_mse: 25.1976 - val_mae: 3.3732\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 11.6812 - mse: 11.6812 - mae: 2.4225 - val_loss: 26.4333 - val_mse: 26.4333 - val_mae: 3.4408\n",
       "Epoch 18/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 10.9278 - mse: 10.9278 - mae: 2.3653 - val_loss: 24.2875 - val_mse: 24.2875 - val_mae: 3.3114\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 11.3037 - mse: 11.3037 - mae: 2.4010 - val_loss: 24.4181 - val_mse: 24.4181 - val_mae: 3.3026\n",
       "Epoch 19/75\n",
-      "404/404 [==============================] - 0s 365us/sample - loss: 10.5854 - mse: 10.5854 - mae: 2.3170 - val_loss: 26.1450 - val_mse: 26.1450 - val_mae: 3.3971\n",
+      "404/404 [==============================] - 0s 153us/sample - loss: 11.1517 - mse: 11.1517 - mae: 2.3736 - val_loss: 25.5466 - val_mse: 25.5466 - val_mae: 3.3604\n",
       "Epoch 20/75\n",
-      "404/404 [==============================] - 0s 401us/sample - loss: 10.2546 - mse: 10.2546 - mae: 2.2813 - val_loss: 26.5278 - val_mse: 26.5278 - val_mae: 3.4465\n",
+      "404/404 [==============================] - 0s 166us/sample - loss: 10.9354 - mse: 10.9355 - mae: 2.3871 - val_loss: 25.4167 - val_mse: 25.4167 - val_mae: 3.2933\n",
       "Epoch 21/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 10.1321 - mse: 10.1321 - mae: 2.2866 - val_loss: 24.0363 - val_mse: 24.0363 - val_mae: 3.2792\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 10.5695 - mse: 10.5695 - mae: 2.3195 - val_loss: 23.9471 - val_mse: 23.9471 - val_mae: 3.1993\n",
       "Epoch 22/75\n",
-      "404/404 [==============================] - 0s 421us/sample - loss: 9.9169 - mse: 9.9169 - mae: 2.2907 - val_loss: 23.7310 - val_mse: 23.7310 - val_mae: 3.2334\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 10.7775 - mse: 10.7775 - mae: 2.3826 - val_loss: 25.2380 - val_mse: 25.2380 - val_mae: 3.2568\n",
       "Epoch 23/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.6588 - mse: 9.6588 - mae: 2.2284 - val_loss: 23.6472 - val_mse: 23.6472 - val_mae: 3.2013\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 10.1978 - mse: 10.1978 - mae: 2.2830 - val_loss: 24.6718 - val_mse: 24.6718 - val_mae: 3.2214\n",
       "Epoch 24/75\n",
-      "404/404 [==============================] - 0s 363us/sample - loss: 9.6887 - mse: 9.6887 - mae: 2.2468 - val_loss: 23.5379 - val_mse: 23.5379 - val_mae: 3.1921\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 9.8674 - mse: 9.8674 - mae: 2.2537 - val_loss: 26.1690 - val_mse: 26.1690 - val_mae: 3.3098\n",
       "Epoch 25/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 9.4049 - mse: 9.4049 - mae: 2.1999 - val_loss: 23.7713 - val_mse: 23.7713 - val_mae: 3.2273\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 9.9234 - mse: 9.9234 - mae: 2.2708 - val_loss: 25.5566 - val_mse: 25.5566 - val_mae: 3.2252\n",
       "Epoch 26/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 9.2304 - mse: 9.2304 - mae: 2.1946 - val_loss: 23.5093 - val_mse: 23.5093 - val_mae: 3.2072\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 9.6175 - mse: 9.6175 - mae: 2.2380 - val_loss: 25.6819 - val_mse: 25.6819 - val_mae: 3.2484\n",
       "Epoch 27/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 9.0493 - mse: 9.0493 - mae: 2.1528 - val_loss: 23.7969 - val_mse: 23.7969 - val_mae: 3.2005\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 9.4436 - mse: 9.4436 - mae: 2.2165 - val_loss: 25.8741 - val_mse: 25.8741 - val_mae: 3.2481\n",
       "Epoch 28/75\n",
-      "404/404 [==============================] - 0s 359us/sample - loss: 8.9363 - mse: 8.9363 - mae: 2.1475 - val_loss: 22.1030 - val_mse: 22.1030 - val_mae: 3.0707\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 9.2792 - mse: 9.2792 - mae: 2.1641 - val_loss: 25.8379 - val_mse: 25.8379 - val_mae: 3.2350\n",
       "Epoch 29/75\n",
-      "404/404 [==============================] - 0s 373us/sample - loss: 8.7834 - mse: 8.7834 - mae: 2.1231 - val_loss: 22.5153 - val_mse: 22.5153 - val_mae: 3.1532\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 9.5098 - mse: 9.5098 - mae: 2.2216 - val_loss: 24.3955 - val_mse: 24.3955 - val_mae: 3.1503\n",
       "Epoch 30/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.7925 - mse: 8.7925 - mae: 2.1531 - val_loss: 22.0449 - val_mse: 22.0449 - val_mae: 3.1245\n",
+      "404/404 [==============================] - 0s 151us/sample - loss: 8.9694 - mse: 8.9694 - mae: 2.1516 - val_loss: 24.0384 - val_mse: 24.0384 - val_mae: 3.1125\n",
       "Epoch 31/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 9.1879 - mse: 9.1879 - mae: 2.2029 - val_loss: 22.1780 - val_mse: 22.1780 - val_mae: 3.0623\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 9.0936 - mse: 9.0936 - mae: 2.1824 - val_loss: 24.7618 - val_mse: 24.7618 - val_mae: 3.1443\n",
       "Epoch 32/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.7136 - mse: 8.7136 - mae: 2.1164 - val_loss: 21.9815 - val_mse: 21.9815 - val_mae: 3.0969\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 9.1270 - mse: 9.1270 - mae: 2.1868 - val_loss: 23.5554 - val_mse: 23.5554 - val_mae: 3.0424\n",
       "Epoch 33/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 8.3018 - mse: 8.3018 - mae: 2.0639 - val_loss: 21.0477 - val_mse: 21.0477 - val_mae: 2.9645\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 8.7967 - mse: 8.7967 - mae: 2.1304 - val_loss: 24.2795 - val_mse: 24.2795 - val_mae: 3.1008\n",
       "Epoch 34/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 8.4156 - mse: 8.4156 - mae: 2.0970 - val_loss: 22.6659 - val_mse: 22.6659 - val_mae: 3.1235\n",
+      "404/404 [==============================] - 0s 168us/sample - loss: 8.8469 - mse: 8.8469 - mae: 2.1311 - val_loss: 24.1872 - val_mse: 24.1872 - val_mae: 3.1228\n",
       "Epoch 35/75\n",
-      "404/404 [==============================] - 0s 350us/sample - loss: 8.2938 - mse: 8.2938 - mae: 2.0567 - val_loss: 20.9574 - val_mse: 20.9574 - val_mae: 2.9746\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 8.4650 - mse: 8.4650 - mae: 2.1037 - val_loss: 24.1886 - val_mse: 24.1886 - val_mae: 3.0625\n",
       "Epoch 36/75\n",
-      "404/404 [==============================] - 0s 357us/sample - loss: 8.0515 - mse: 8.0515 - mae: 2.0591 - val_loss: 23.2063 - val_mse: 23.2063 - val_mae: 3.1980\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 8.5157 - mse: 8.5157 - mae: 2.1238 - val_loss: 22.8082 - val_mse: 22.8082 - val_mae: 3.0244\n",
       "Epoch 37/75\n",
-      "404/404 [==============================] - 0s 381us/sample - loss: 8.1403 - mse: 8.1403 - mae: 2.0584 - val_loss: 24.5238 - val_mse: 24.5237 - val_mae: 3.3531\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 8.5744 - mse: 8.5744 - mae: 2.0760 - val_loss: 22.9590 - val_mse: 22.9590 - val_mae: 3.0205\n",
       "Epoch 38/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 8.0043 - mse: 8.0043 - mae: 2.0776 - val_loss: 22.5424 - val_mse: 22.5424 - val_mae: 3.1494\n",
+      "404/404 [==============================] - 0s 168us/sample - loss: 8.4869 - mse: 8.4869 - mae: 2.1122 - val_loss: 22.1074 - val_mse: 22.1074 - val_mae: 2.9642\n",
       "Epoch 39/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 8.1182 - mse: 8.1182 - mae: 2.0683 - val_loss: 19.7576 - val_mse: 19.7576 - val_mae: 2.8799\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 8.2782 - mse: 8.2782 - mae: 2.0620 - val_loss: 22.3750 - val_mse: 22.3750 - val_mae: 2.9712\n",
       "Epoch 40/75\n",
-      "404/404 [==============================] - 0s 374us/sample - loss: 7.8578 - mse: 7.8578 - mae: 2.0131 - val_loss: 20.7728 - val_mse: 20.7728 - val_mae: 2.9499\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 8.0564 - mse: 8.0564 - mae: 2.0377 - val_loss: 23.0760 - val_mse: 23.0760 - val_mae: 2.9919\n",
       "Epoch 41/75\n",
-      "404/404 [==============================] - 0s 382us/sample - loss: 7.5711 - mse: 7.5711 - mae: 1.9896 - val_loss: 20.6170 - val_mse: 20.6170 - val_mae: 2.9936\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 7.8837 - mse: 7.8837 - mae: 2.0143 - val_loss: 23.2903 - val_mse: 23.2903 - val_mae: 2.9887\n",
       "Epoch 42/75\n",
-      "404/404 [==============================] - 0s 385us/sample - loss: 7.5822 - mse: 7.5822 - mae: 1.9683 - val_loss: 20.8541 - val_mse: 20.8541 - val_mae: 3.0054\n",
+      "404/404 [==============================] - 0s 166us/sample - loss: 7.7386 - mse: 7.7386 - mae: 1.9804 - val_loss: 22.4281 - val_mse: 22.4281 - val_mae: 2.9666\n",
       "Epoch 43/75\n",
-      "404/404 [==============================] - 0s 408us/sample - loss: 7.4533 - mse: 7.4533 - mae: 1.9645 - val_loss: 20.4473 - val_mse: 20.4473 - val_mae: 2.8861\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 7.6346 - mse: 7.6346 - mae: 1.9758 - val_loss: 22.6116 - val_mse: 22.6116 - val_mae: 2.9866\n",
       "Epoch 44/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 7.5226 - mse: 7.5226 - mae: 1.9509 - val_loss: 20.5193 - val_mse: 20.5193 - val_mae: 2.9619\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 7.7108 - mse: 7.7108 - mae: 1.9978 - val_loss: 23.2730 - val_mse: 23.2730 - val_mae: 3.0062\n",
       "Epoch 45/75\n",
-      "404/404 [==============================] - 0s 355us/sample - loss: 7.2819 - mse: 7.2819 - mae: 1.9350 - val_loss: 21.4862 - val_mse: 21.4862 - val_mae: 2.9908\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 7.6819 - mse: 7.6819 - mae: 1.9850 - val_loss: 23.4598 - val_mse: 23.4598 - val_mae: 2.9923\n",
       "Epoch 46/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 7.0130 - mse: 7.0130 - mae: 1.9152 - val_loss: 20.1577 - val_mse: 20.1577 - val_mae: 2.9370\n",
+      "404/404 [==============================] - 0s 168us/sample - loss: 7.4403 - mse: 7.4403 - mae: 1.9390 - val_loss: 22.3272 - val_mse: 22.3272 - val_mae: 2.9512\n",
       "Epoch 47/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.9431 - mse: 6.9431 - mae: 1.8819 - val_loss: 21.1210 - val_mse: 21.1210 - val_mae: 2.9746\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 7.3572 - mse: 7.3572 - mae: 1.9608 - val_loss: 22.6367 - val_mse: 22.6367 - val_mae: 2.9479\n",
       "Epoch 48/75\n",
-      "404/404 [==============================] - 0s 371us/sample - loss: 6.8982 - mse: 6.8982 - mae: 1.9037 - val_loss: 19.2999 - val_mse: 19.2999 - val_mae: 2.8638\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 7.3647 - mse: 7.3647 - mae: 1.9266 - val_loss: 22.9716 - val_mse: 22.9716 - val_mae: 2.9845\n",
       "Epoch 49/75\n",
-      "404/404 [==============================] - 0s 368us/sample - loss: 6.9521 - mse: 6.9521 - mae: 1.8862 - val_loss: 20.7825 - val_mse: 20.7825 - val_mae: 2.9369\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 7.1508 - mse: 7.1508 - mae: 1.9264 - val_loss: 23.1182 - val_mse: 23.1182 - val_mae: 2.9594\n",
       "Epoch 50/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.8718 - mse: 6.8718 - mae: 1.8889 - val_loss: 20.0288 - val_mse: 20.0288 - val_mae: 2.8915\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 7.2133 - mse: 7.2133 - mae: 1.9619 - val_loss: 21.0537 - val_mse: 21.0537 - val_mae: 2.8148\n",
       "Epoch 51/75\n",
-      "404/404 [==============================] - 0s 354us/sample - loss: 6.7111 - mse: 6.7111 - mae: 1.8702 - val_loss: 20.4913 - val_mse: 20.4913 - val_mae: 3.0116\n",
+      "404/404 [==============================] - 0s 153us/sample - loss: 7.0005 - mse: 7.0005 - mae: 1.8888 - val_loss: 21.7946 - val_mse: 21.7946 - val_mae: 2.8981\n",
       "Epoch 52/75\n",
-      "404/404 [==============================] - 0s 361us/sample - loss: 6.7492 - mse: 6.7492 - mae: 1.8482 - val_loss: 18.3008 - val_mse: 18.3008 - val_mae: 2.7362\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 6.8007 - mse: 6.8007 - mae: 1.8530 - val_loss: 21.0419 - val_mse: 21.0419 - val_mae: 2.8175\n",
       "Epoch 53/75\n",
-      "404/404 [==============================] - 0s 356us/sample - loss: 6.6262 - mse: 6.6262 - mae: 1.8395 - val_loss: 18.1885 - val_mse: 18.1885 - val_mae: 2.6920\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 6.9437 - mse: 6.9437 - mae: 1.9274 - val_loss: 20.1983 - val_mse: 20.1983 - val_mae: 2.8273\n",
       "Epoch 54/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 6.7148 - mse: 6.7148 - mae: 1.8611 - val_loss: 18.5764 - val_mse: 18.5764 - val_mae: 2.6977\n",
+      "404/404 [==============================] - 0s 153us/sample - loss: 6.7113 - mse: 6.7113 - mae: 1.8593 - val_loss: 22.3505 - val_mse: 22.3505 - val_mae: 2.9939\n",
       "Epoch 55/75\n",
-      "404/404 [==============================] - 0s 358us/sample - loss: 6.5425 - mse: 6.5425 - mae: 1.8522 - val_loss: 19.5772 - val_mse: 19.5772 - val_mae: 2.8326\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 6.4656 - mse: 6.4656 - mae: 1.8530 - val_loss: 20.1633 - val_mse: 20.1633 - val_mae: 2.8043\n",
       "Epoch 56/75\n",
-      "404/404 [==============================] - 0s 423us/sample - loss: 6.3349 - mse: 6.3349 - mae: 1.8175 - val_loss: 19.0932 - val_mse: 19.0932 - val_mae: 2.8260\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 6.7096 - mse: 6.7096 - mae: 1.8472 - val_loss: 20.2534 - val_mse: 20.2534 - val_mae: 2.7810\n",
       "Epoch 57/75\n",
-      "404/404 [==============================] - 0s 375us/sample - loss: 6.4253 - mse: 6.4253 - mae: 1.7972 - val_loss: 20.4036 - val_mse: 20.4036 - val_mae: 2.9258\n",
+      "404/404 [==============================] - 0s 151us/sample - loss: 6.5312 - mse: 6.5312 - mae: 1.8173 - val_loss: 22.2696 - val_mse: 22.2696 - val_mae: 2.9322\n",
       "Epoch 58/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.2897 - mse: 6.2897 - mae: 1.7785 - val_loss: 21.2845 - val_mse: 21.2845 - val_mae: 3.0715\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 6.6078 - mse: 6.6078 - mae: 1.8656 - val_loss: 22.6642 - val_mse: 22.6642 - val_mae: 2.9474\n",
       "Epoch 59/75\n",
-      "404/404 [==============================] - 0s 378us/sample - loss: 6.7839 - mse: 6.7839 - mae: 1.9027 - val_loss: 18.6853 - val_mse: 18.6853 - val_mae: 2.7709\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 6.2407 - mse: 6.2407 - mae: 1.8064 - val_loss: 20.5084 - val_mse: 20.5084 - val_mae: 2.8084\n",
       "Epoch 60/75\n",
-      "404/404 [==============================] - 0s 395us/sample - loss: 6.7178 - mse: 6.7178 - mae: 1.8871 - val_loss: 19.5394 - val_mse: 19.5394 - val_mae: 2.8101\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 6.1732 - mse: 6.1732 - mae: 1.7668 - val_loss: 20.5319 - val_mse: 20.5319 - val_mae: 2.7971\n",
       "Epoch 61/75\n",
-      "404/404 [==============================] - 0s 366us/sample - loss: 6.4152 - mse: 6.4152 - mae: 1.8175 - val_loss: 18.2377 - val_mse: 18.2377 - val_mae: 2.7450\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 6.1966 - mse: 6.1966 - mae: 1.7546 - val_loss: 20.7932 - val_mse: 20.7932 - val_mae: 2.9102\n",
       "Epoch 62/75\n",
-      "404/404 [==============================] - 0s 384us/sample - loss: 5.9727 - mse: 5.9727 - mae: 1.7630 - val_loss: 19.0252 - val_mse: 19.0252 - val_mae: 2.7960\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 6.2948 - mse: 6.2948 - mae: 1.7852 - val_loss: 19.5782 - val_mse: 19.5782 - val_mae: 2.7435\n",
       "Epoch 63/75\n",
-      "404/404 [==============================] - 0s 380us/sample - loss: 6.0973 - mse: 6.0973 - mae: 1.8071 - val_loss: 18.8069 - val_mse: 18.8069 - val_mae: 2.8894\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 6.1167 - mse: 6.1167 - mae: 1.7790 - val_loss: 19.7281 - val_mse: 19.7281 - val_mae: 2.7645\n",
       "Epoch 64/75\n",
-      "404/404 [==============================] - 0s 362us/sample - loss: 6.1074 - mse: 6.1074 - mae: 1.7978 - val_loss: 18.4702 - val_mse: 18.4702 - val_mae: 2.7851\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 6.0010 - mse: 6.0010 - mae: 1.7360 - val_loss: 19.5005 - val_mse: 19.5005 - val_mae: 2.7373\n",
       "Epoch 65/75\n",
-      "404/404 [==============================] - 0s 369us/sample - loss: 5.9329 - mse: 5.9329 - mae: 1.7545 - val_loss: 18.5321 - val_mse: 18.5321 - val_mae: 2.7933\n",
+      "404/404 [==============================] - 0s 161us/sample - loss: 5.9214 - mse: 5.9214 - mae: 1.7356 - val_loss: 21.1325 - val_mse: 21.1325 - val_mae: 2.8423\n",
       "Epoch 66/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.7473 - mse: 5.7473 - mae: 1.7211 - val_loss: 18.5536 - val_mse: 18.5536 - val_mae: 2.8010\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 6.1376 - mse: 6.1376 - mae: 1.7799 - val_loss: 22.1765 - val_mse: 22.1765 - val_mae: 2.9805\n",
       "Epoch 67/75\n",
-      "404/404 [==============================] - 0s 339us/sample - loss: 5.8866 - mse: 5.8866 - mae: 1.7224 - val_loss: 18.0067 - val_mse: 18.0067 - val_mae: 2.7054\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 5.9703 - mse: 5.9703 - mae: 1.7643 - val_loss: 20.8771 - val_mse: 20.8771 - val_mae: 2.8101\n",
       "Epoch 68/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.7885 - mse: 5.7885 - mae: 1.7391 - val_loss: 17.5502 - val_mse: 17.5502 - val_mae: 2.6767\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 5.7285 - mse: 5.7285 - mae: 1.7263 - val_loss: 19.8477 - val_mse: 19.8477 - val_mae: 2.7662\n",
       "Epoch 69/75\n",
-      "404/404 [==============================] - 0s 331us/sample - loss: 5.8809 - mse: 5.8809 - mae: 1.7542 - val_loss: 17.0280 - val_mse: 17.0280 - val_mae: 2.6404\n",
+      "404/404 [==============================] - 0s 153us/sample - loss: 5.6448 - mse: 5.6448 - mae: 1.6999 - val_loss: 19.1481 - val_mse: 19.1481 - val_mae: 2.7466\n",
       "Epoch 70/75\n",
-      "404/404 [==============================] - 0s 343us/sample - loss: 5.6028 - mse: 5.6028 - mae: 1.6972 - val_loss: 17.7188 - val_mse: 17.7188 - val_mae: 2.6979\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 5.3907 - mse: 5.3907 - mae: 1.6686 - val_loss: 19.6300 - val_mse: 19.6300 - val_mae: 2.7617\n",
       "Epoch 71/75\n",
-      "404/404 [==============================] - 0s 337us/sample - loss: 5.4361 - mse: 5.4361 - mae: 1.6741 - val_loss: 16.8852 - val_mse: 16.8852 - val_mae: 2.6126\n",
+      "404/404 [==============================] - 0s 158us/sample - loss: 5.6235 - mse: 5.6235 - mae: 1.7072 - val_loss: 19.4050 - val_mse: 19.4050 - val_mae: 2.7751\n",
       "Epoch 72/75\n",
-      "404/404 [==============================] - 0s 345us/sample - loss: 5.5608 - mse: 5.5608 - mae: 1.7252 - val_loss: 16.7483 - val_mse: 16.7483 - val_mae: 2.6063\n",
+      "404/404 [==============================] - 0s 156us/sample - loss: 5.6815 - mse: 5.6815 - mae: 1.6873 - val_loss: 18.9009 - val_mse: 18.9009 - val_mae: 2.7787\n",
       "Epoch 73/75\n",
-      "404/404 [==============================] - 0s 341us/sample - loss: 5.5022 - mse: 5.5022 - mae: 1.6912 - val_loss: 17.6786 - val_mse: 17.6786 - val_mae: 2.7316\n",
+      "404/404 [==============================] - 0s 154us/sample - loss: 5.4091 - mse: 5.4091 - mae: 1.6579 - val_loss: 20.2019 - val_mse: 20.2019 - val_mae: 2.8314\n",
       "Epoch 74/75\n",
-      "404/404 [==============================] - 0s 396us/sample - loss: 5.2794 - mse: 5.2794 - mae: 1.6478 - val_loss: 17.6115 - val_mse: 17.6115 - val_mae: 2.6773\n",
+      "404/404 [==============================] - 0s 163us/sample - loss: 5.6521 - mse: 5.6521 - mae: 1.7438 - val_loss: 19.6080 - val_mse: 19.6080 - val_mae: 2.7354\n",
       "Epoch 75/75\n",
-      "404/404 [==============================] - 0s 338us/sample - loss: 5.4796 - mse: 5.4796 - mae: 1.6876 - val_loss: 17.2835 - val_mse: 17.2835 - val_mae: 2.7126\n"
+      "404/404 [==============================] - 0s 161us/sample - loss: 5.3548 - mse: 5.3548 - mae: 1.6431 - val_loss: 19.4933 - val_mse: 19.4933 - val_mae: 2.8019\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f36340c6b38>"
+       "<tensorflow.python.keras.callbacks.History at 0x1ddfdc37cc0>"
       ]
      },
-     "execution_count": 3,
+     "execution_count": 4,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -371,7 +380,7 @@
     "\n",
     "# Fit Model\n",
     "model.fit(x_train, y_train, \n",
-    "          validation_data=(x_test,y_test), \n",
+    "          validation_data=(x_test,y_test), #\n",
     "          epochs=epochs, \n",
     "          batch_size=batch_size\n",
     "         )"
@@ -444,12 +453,14 @@
    "source": [
     "## Batch Size\n",
     "\n",
+    "You still go over the entire dataset, but it's how much of the data we look over before calculating a gradient. Images, text, GPU acceleration are important when considering batch size. Here it's not such a big deal, small toy set. \n",
+    "\n",
     "Batch size determines how many observations the model is shown before it calculates loss/error and updates the model weights via gradient descent. You're looking for a sweet spot here where you're showing it enough observations that you have enough information to updates the weights, but not such a large batch size that you don't get a lot of weight update iterations performed in a given epoch. Feed-forward Neural Networks aren't as sensitive to bach_size as other networks, but it is still an important hyperparameter to tune. Smaller batch sizes will also take longer to train. "
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 6,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -460,25 +471,17 @@
     "outputId": "ae996575-78e2-43fb-9dbe-5d44aaf0b430"
    },
    "outputs": [
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
-      "  warnings.warn(CV_WARNING, FutureWarning)\n"
-     ]
-    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Best: 0.65234375 using {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.65234375, Stdev: 0.033298728782667764 with: {'batch_size': 10, 'epochs': 20}\n",
-      "Means: 0.6263020833333334, Stdev: 0.01813592223591682 with: {'batch_size': 20, 'epochs': 20}\n",
-      "Means: 0.6041666666666666, Stdev: 0.037782859709757574 with: {'batch_size': 40, 'epochs': 20}\n",
-      "Means: 0.5533854166666666, Stdev: 0.03210632293213009 with: {'batch_size': 60, 'epochs': 20}\n",
-      "Means: 0.61328125, Stdev: 0.024079742199097563 with: {'batch_size': 80, 'epochs': 20}\n",
-      "Means: 0.5611979166666666, Stdev: 0.038450060052691144 with: {'batch_size': 100, 'epochs': 20}\n"
+      "Best: 0.6692386150360108 using {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6692386150360108, Stdev: 0.03869999250105506 with: {'batch_size': 10, 'epochs': 20}\n",
+      "Means: 0.6431966781616211, Stdev: 0.061255737067304306 with: {'batch_size': 20, 'epochs': 20}\n",
+      "Means: 0.622510826587677, Stdev: 0.044330833226344034 with: {'batch_size': 40, 'epochs': 20}\n",
+      "Means: 0.6027671694755554, Stdev: 0.04779651952180196 with: {'batch_size': 60, 'epochs': 20}\n",
+      "Means: 0.5377557098865509, Stdev: 0.07033867081369344 with: {'batch_size': 80, 'epochs': 20}\n",
+      "Means: 0.5729225158691407, Stdev: 0.08636233760096981 with: {'batch_size': 100, 'epochs': 20}\n"
      ]
     }
    ],
@@ -488,7 +491,10 @@
     "from sklearn.model_selection import GridSearchCV\n",
     "from tensorflow.keras.models import Sequential\n",
     "from tensorflow.keras.layers import Dense\n",
-    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
+    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier # this is new \n",
+    "# it is a sk wrapper for Keras so we can just toss it into grid search, fit, and \n",
+    "# other scikit learn stuff so we don't have to write in between code for example\n",
+    "\n",
     "\n",
     "# fix random seed for reproducibility\n",
     "seed = 7\n",
@@ -521,11 +527,12 @@
     "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
     "\n",
     "# define the grid search parameters\n",
+    "# total obs is 781 so batches far under that make sense\n",
     "param_grid = {'batch_size': [10, 20, 40, 60, 80, 100],\n",
     "              'epochs': [20]}\n",
     "\n",
     "# Create Grid Search\n",
-    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
+    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1) # these can't be parallelized \n",
     "grid_result = grid.fit(X, Y)\n",
     "\n",
     "# Report Results\n",
@@ -546,7 +553,7 @@
    "source": [
     "## Epochs\n",
     "\n",
-    "The number of training epochs has a large and direct affect on the accuracy, However, more epochs is almost always goign to better than less epochs. This means that if you tune this parameter at the beginning and try and maintain the same value all throughout your training, you're going to be waiting a long time for each iteration of GridSearch. I suggest picking a fixed moderat # of epochs all throughout your training and then Grid Searching this parameter at the very end. "
+    "The number of training epochs has a large and direct affect on the accuracy, However, more epochs is almost always going to better than less epochs. This means that if you tune this parameter at the beginning and try and maintain the same value all throughout your training, you're going to be waiting a long time for each iteration of GridSearch. I suggest picking a fixed moderate # of epochs all throughout your training and then Grid Searching this parameter at the very end. "
    ]
   },
   {
@@ -627,7 +634,7 @@
     "id": "gNTBUWd1aLlA"
    },
    "source": [
-    "## Momentum\n",
+    "## Momentum --SGD Specific\n",
     "\n",
     "Momentum is a hyperparameter that is more commonly associated with Stochastic Gradient Descent. SGD is a common optimizer because it's what people understand and know, but I doubt it will get you the best results, you can try hyperparameter tuning its attributes and see if you can beat the performance from adam. Momentum is a property that decides the willingness of an optimizer to overshoot the minimum. Imagine a ball rolling down one side of a bowl and then up the opposite side a little bit before settling back to the bottom. The purpose of momentum is to try and escale local minima."
    ]
@@ -730,39 +737,17 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 7,
    "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "\n",
-       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
-       "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro</a><br/>\n",
-       "            "
-      ],
-      "text/plain": [
-       "<IPython.core.display.HTML object>"
-      ]
-     },
-     "metadata": {},
-     "output_type": "display_data"
-    },
-    {
-     "data": {
-      "text/plain": [
-       "W&B Run: https://app.wandb.ai/lambda-ds7/boston/runs/whw09rro"
-      ]
-     },
-     "execution_count": 6,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "outputs": [],
    "source": [
     "import wandb\n",
-    "from wandb.keras import WandbCallback"
+    "from wandb.keras import WandbCallback # uses callback to send results to their server\n",
+    "\n",
+    "# to automatically login\n",
+    "# can also set config file, go look-up so less work later\n",
+    "!wandb login 511a1885661d9b7baa13c50c3b8395d5dee3ed19\n",
+    "# WandAI key: 511a1885661d9b7baa13c50c3b8395d5dee3ed19"
    ]
   },
   {
@@ -778,13 +763,34 @@
     "outputId": "b05e251e-508f-46e6-865b-f869ae2a5dc4"
    },
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: ERROR Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
+     ]
+    },
+    {
+     "name": "stdin",
+     "output_type": "stream",
+     "text": [
+      "API Key:  \n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\benjamin/.netrc\n"
+     ]
+    },
     {
      "data": {
       "text/html": [
        "\n",
        "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
        "                Project page: <a href=\"https://app.wandb.ai/lambda-ds7/boston\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston</a><br/>\n",
-       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/kkgdtc31</a><br/>\n",
+       "                Run page: <a href=\"https://app.wandb.ai/lambda-ds7/boston/runs/40qmpy6h\" target=\"_blank\">https://app.wandb.ai/lambda-ds7/boston/runs/40qmpy6h</a><br/>\n",
        "            "
       ],
       "text/plain": [
@@ -794,117 +800,124 @@
      "metadata": {},
      "output_type": "display_data"
     },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
       "Train on 270 samples, validate on 134 samples\n",
       "Epoch 1/50\n",
-      "270/270 [==============================] - 1s 3ms/sample - loss: 492.3539 - mse: 492.3539 - mae: 20.3197 - val_loss: 481.5445 - val_mse: 481.5445 - val_mae: 19.6138\n",
+      "270/270 [==============================] - 1s 2ms/sample - loss: 467.9831 - mse: 467.9830 - mae: 19.6788 - val_loss: 431.3124 - val_mse: 431.3124 - val_mae: 18.2953\n",
       "Epoch 2/50\n",
-      "270/270 [==============================] - 0s 591us/sample - loss: 239.4999 - mse: 239.4999 - mae: 12.8064 - val_loss: 113.8561 - val_mse: 113.8561 - val_mae: 8.2962\n",
+      "270/270 [==============================] - 0s 319us/sample - loss: 204.0537 - mse: 204.0537 - mae: 12.0661 - val_loss: 104.3700 - val_mse: 104.3700 - val_mae: 8.1972\n",
       "Epoch 3/50\n",
-      "270/270 [==============================] - 0s 618us/sample - loss: 56.2921 - mse: 56.2921 - mae: 5.8988 - val_loss: 62.7912 - val_mse: 62.7912 - val_mae: 5.6465\n",
+      "270/270 [==============================] - 0s 304us/sample - loss: 59.0650 - mse: 59.0651 - mae: 5.9766 - val_loss: 55.4364 - val_mse: 55.4364 - val_mae: 5.4746\n",
       "Epoch 4/50\n",
-      "270/270 [==============================] - 0s 613us/sample - loss: 29.4994 - mse: 29.4994 - mae: 3.9653 - val_loss: 37.9256 - val_mse: 37.9256 - val_mae: 4.1730\n",
+      "270/270 [==============================] - 0s 322us/sample - loss: 26.5790 - mse: 26.5790 - mae: 3.8353 - val_loss: 34.0382 - val_mse: 34.0382 - val_mae: 4.0039\n",
       "Epoch 5/50\n",
-      "270/270 [==============================] - 0s 608us/sample - loss: 20.6919 - mse: 20.6919 - mae: 3.3022 - val_loss: 31.7489 - val_mse: 31.7489 - val_mae: 3.7113\n",
+      "270/270 [==============================] - 0s 304us/sample - loss: 18.8152 - mse: 18.8152 - mae: 3.2582 - val_loss: 26.9755 - val_mse: 26.9755 - val_mae: 3.4172\n",
       "Epoch 6/50\n",
-      "270/270 [==============================] - 0s 602us/sample - loss: 17.2701 - mse: 17.2701 - mae: 3.0291 - val_loss: 27.3921 - val_mse: 27.3921 - val_mae: 3.4958\n",
+      "270/270 [==============================] - 0s 308us/sample - loss: 15.7192 - mse: 15.7192 - mae: 2.9405 - val_loss: 24.1291 - val_mse: 24.1291 - val_mae: 3.1333\n",
       "Epoch 7/50\n",
-      "270/270 [==============================] - 0s 671us/sample - loss: 15.5172 - mse: 15.5172 - mae: 2.8537 - val_loss: 25.3208 - val_mse: 25.3208 - val_mae: 3.3650\n",
+      "270/270 [==============================] - 0s 341us/sample - loss: 13.2330 - mse: 13.2330 - mae: 2.7414 - val_loss: 23.3808 - val_mse: 23.3808 - val_mae: 3.0938\n",
       "Epoch 8/50\n",
-      "270/270 [==============================] - 0s 661us/sample - loss: 13.7548 - mse: 13.7548 - mae: 2.7089 - val_loss: 23.8920 - val_mse: 23.8920 - val_mae: 3.2746\n",
+      "270/270 [==============================] - 0s 319us/sample - loss: 12.1790 - mse: 12.1790 - mae: 2.6457 - val_loss: 21.5901 - val_mse: 21.5901 - val_mae: 2.9780\n",
       "Epoch 9/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 12.3745 - mse: 12.3745 - mae: 2.5662 - val_loss: 22.1294 - val_mse: 22.1294 - val_mae: 3.1509\n",
+      "270/270 [==============================] - 0s 304us/sample - loss: 10.8595 - mse: 10.8595 - mae: 2.4649 - val_loss: 21.0290 - val_mse: 21.0290 - val_mae: 3.0222\n",
       "Epoch 10/50\n",
-      "270/270 [==============================] - 0s 614us/sample - loss: 11.2424 - mse: 11.2424 - mae: 2.4804 - val_loss: 20.5718 - val_mse: 20.5718 - val_mae: 3.0461\n",
+      "270/270 [==============================] - 0s 307us/sample - loss: 10.6808 - mse: 10.6808 - mae: 2.4472 - val_loss: 20.6653 - val_mse: 20.6653 - val_mae: 2.9230\n",
       "Epoch 11/50\n",
-      "270/270 [==============================] - 0s 605us/sample - loss: 10.6098 - mse: 10.6098 - mae: 2.4178 - val_loss: 20.3467 - val_mse: 20.3467 - val_mae: 3.0251\n",
+      "270/270 [==============================] - 0s 304us/sample - loss: 9.6107 - mse: 9.6107 - mae: 2.3890 - val_loss: 19.0705 - val_mse: 19.0705 - val_mae: 2.8856\n",
       "Epoch 12/50\n",
-      "270/270 [==============================] - 0s 576us/sample - loss: 10.0011 - mse: 10.0011 - mae: 2.3257 - val_loss: 18.4283 - val_mse: 18.4283 - val_mae: 2.8938\n",
+      "270/270 [==============================] - 0s 326us/sample - loss: 9.4731 - mse: 9.4731 - mae: 2.3368 - val_loss: 18.1945 - val_mse: 18.1945 - val_mae: 2.8449\n",
       "Epoch 13/50\n",
-      "270/270 [==============================] - 0s 666us/sample - loss: 9.1287 - mse: 9.1287 - mae: 2.2384 - val_loss: 18.2024 - val_mse: 18.2024 - val_mae: 2.9116\n",
+      "270/270 [==============================] - 0s 219us/sample - loss: 8.5719 - mse: 8.5719 - mae: 2.2209 - val_loss: 18.9970 - val_mse: 18.9970 - val_mae: 2.8608\n",
       "Epoch 14/50\n",
-      "270/270 [==============================] - 0s 603us/sample - loss: 8.6211 - mse: 8.6211 - mae: 2.1980 - val_loss: 17.4749 - val_mse: 17.4749 - val_mae: 2.8290\n",
+      "270/270 [==============================] - 0s 219us/sample - loss: 8.4063 - mse: 8.4063 - mae: 2.2340 - val_loss: 19.0868 - val_mse: 19.0868 - val_mae: 2.8812\n",
       "Epoch 15/50\n",
-      "270/270 [==============================] - 0s 463us/sample - loss: 8.4558 - mse: 8.4558 - mae: 2.2087 - val_loss: 17.7878 - val_mse: 17.7878 - val_mae: 2.8516\n",
+      "270/270 [==============================] - 0s 304us/sample - loss: 8.8935 - mse: 8.8935 - mae: 2.2887 - val_loss: 17.7457 - val_mse: 17.7457 - val_mae: 2.7889\n",
       "Epoch 16/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 8.3626 - mse: 8.3626 - mae: 2.2031 - val_loss: 16.7101 - val_mse: 16.7101 - val_mae: 2.7820\n",
+      "270/270 [==============================] - 0s 330us/sample - loss: 7.9352 - mse: 7.9352 - mae: 2.1074 - val_loss: 17.4676 - val_mse: 17.4676 - val_mae: 2.8337\n",
       "Epoch 17/50\n",
-      "270/270 [==============================] - 0s 607us/sample - loss: 7.9180 - mse: 7.9180 - mae: 2.1265 - val_loss: 16.6064 - val_mse: 16.6064 - val_mae: 2.7419\n",
+      "270/270 [==============================] - 0s 233us/sample - loss: 7.7677 - mse: 7.7677 - mae: 2.1253 - val_loss: 17.9595 - val_mse: 17.9595 - val_mae: 2.8287\n",
       "Epoch 18/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 7.5552 - mse: 7.5552 - mae: 2.0235 - val_loss: 17.2872 - val_mse: 17.2872 - val_mae: 2.8539\n",
+      "270/270 [==============================] - 0s 307us/sample - loss: 7.4711 - mse: 7.4711 - mae: 2.0827 - val_loss: 16.7921 - val_mse: 16.7921 - val_mae: 2.7821\n",
       "Epoch 19/50\n",
-      "270/270 [==============================] - 0s 616us/sample - loss: 7.0971 - mse: 7.0971 - mae: 2.0038 - val_loss: 16.5110 - val_mse: 16.5110 - val_mae: 2.8042\n",
+      "270/270 [==============================] - 0s 215us/sample - loss: 7.2400 - mse: 7.2400 - mae: 2.0584 - val_loss: 17.1948 - val_mse: 17.1948 - val_mae: 2.8051\n",
       "Epoch 20/50\n",
-      "270/270 [==============================] - 0s 606us/sample - loss: 6.7068 - mse: 6.7068 - mae: 1.9539 - val_loss: 15.5886 - val_mse: 15.5886 - val_mae: 2.7048\n",
+      "270/270 [==============================] - 0s 237us/sample - loss: 7.5532 - mse: 7.5532 - mae: 2.0560 - val_loss: 16.8533 - val_mse: 16.8533 - val_mae: 2.7720\n",
       "Epoch 21/50\n",
-      "270/270 [==============================] - 0s 461us/sample - loss: 6.8542 - mse: 6.8542 - mae: 1.9979 - val_loss: 17.2378 - val_mse: 17.2378 - val_mae: 2.8853\n",
+      "270/270 [==============================] - 0s 315us/sample - loss: 7.3195 - mse: 7.3195 - mae: 2.0303 - val_loss: 16.5477 - val_mse: 16.5477 - val_mae: 2.7494\n",
       "Epoch 22/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 6.5719 - mse: 6.5719 - mae: 1.9312 - val_loss: 16.3043 - val_mse: 16.3043 - val_mae: 2.7756\n",
+      "270/270 [==============================] - 0s 214us/sample - loss: 7.4330 - mse: 7.4330 - mae: 2.0776 - val_loss: 18.2157 - val_mse: 18.2157 - val_mae: 2.8499\n",
       "Epoch 23/50\n",
-      "270/270 [==============================] - 0s 478us/sample - loss: 6.6161 - mse: 6.6161 - mae: 1.9572 - val_loss: 15.7992 - val_mse: 15.7992 - val_mae: 2.7219\n",
+      "270/270 [==============================] - 0s 315us/sample - loss: 7.0735 - mse: 7.0735 - mae: 2.0103 - val_loss: 16.4492 - val_mse: 16.4491 - val_mae: 2.7246\n",
       "Epoch 24/50\n",
-      "270/270 [==============================] - 0s 491us/sample - loss: 7.1269 - mse: 7.1269 - mae: 2.0137 - val_loss: 16.5402 - val_mse: 16.5402 - val_mae: 2.8005\n",
+      "270/270 [==============================] - 0s 211us/sample - loss: 6.3923 - mse: 6.3923 - mae: 1.9015 - val_loss: 16.5070 - val_mse: 16.5070 - val_mae: 2.7543\n",
       "Epoch 25/50\n",
-      "270/270 [==============================] - 0s 479us/sample - loss: 6.3382 - mse: 6.3382 - mae: 1.8540 - val_loss: 16.5034 - val_mse: 16.5034 - val_mae: 2.7864\n",
+      "270/270 [==============================] - 0s 320us/sample - loss: 6.3871 - mse: 6.3871 - mae: 1.9071 - val_loss: 16.3918 - val_mse: 16.3918 - val_mae: 2.6975\n",
       "Epoch 26/50\n",
-      "270/270 [==============================] - 0s 488us/sample - loss: 5.9442 - mse: 5.9442 - mae: 1.8251 - val_loss: 15.6558 - val_mse: 15.6558 - val_mae: 2.7102\n",
+      "270/270 [==============================] - 0s 233us/sample - loss: 6.2018 - mse: 6.2018 - mae: 1.8936 - val_loss: 16.8174 - val_mse: 16.8174 - val_mae: 2.7538\n",
       "Epoch 27/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 5.5832 - mse: 5.5832 - mae: 1.7432 - val_loss: 15.3021 - val_mse: 15.3021 - val_mae: 2.6862\n",
+      "270/270 [==============================] - 0s 322us/sample - loss: 6.0341 - mse: 6.0341 - mae: 1.8140 - val_loss: 15.8352 - val_mse: 15.8352 - val_mae: 2.7071\n",
       "Epoch 28/50\n",
-      "270/270 [==============================] - 0s 436us/sample - loss: 5.4530 - mse: 5.4530 - mae: 1.7354 - val_loss: 15.4570 - val_mse: 15.4570 - val_mae: 2.6846\n",
+      "270/270 [==============================] - 0s 200us/sample - loss: 5.9596 - mse: 5.9596 - mae: 1.8302 - val_loss: 16.2779 - val_mse: 16.2779 - val_mae: 2.7660\n",
       "Epoch 29/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 5.3070 - mse: 5.3070 - mae: 1.7079 - val_loss: 15.8510 - val_mse: 15.8510 - val_mae: 2.7644\n",
+      "270/270 [==============================] - 0s 207us/sample - loss: 6.0287 - mse: 6.0287 - mae: 1.8398 - val_loss: 16.4549 - val_mse: 16.4549 - val_mae: 2.7180\n",
       "Epoch 30/50\n",
-      "270/270 [==============================] - 0s 477us/sample - loss: 5.4157 - mse: 5.4157 - mae: 1.7321 - val_loss: 15.9160 - val_mse: 15.9160 - val_mae: 2.7134\n",
+      "270/270 [==============================] - 0s 308us/sample - loss: 5.7174 - mse: 5.7174 - mae: 1.7859 - val_loss: 15.7449 - val_mse: 15.7449 - val_mae: 2.6993\n",
       "Epoch 31/50\n",
-      "270/270 [==============================] - 0s 452us/sample - loss: 5.2639 - mse: 5.2639 - mae: 1.6981 - val_loss: 15.3554 - val_mse: 15.3554 - val_mae: 2.6662\n",
+      "270/270 [==============================] - 0s 333us/sample - loss: 5.6383 - mse: 5.6383 - mae: 1.7859 - val_loss: 15.6856 - val_mse: 15.6856 - val_mae: 2.6691\n",
       "Epoch 32/50\n",
-      "270/270 [==============================] - 0s 475us/sample - loss: 5.7687 - mse: 5.7687 - mae: 1.8045 - val_loss: 15.7151 - val_mse: 15.7151 - val_mae: 2.6867\n",
+      "270/270 [==============================] - 0s 312us/sample - loss: 5.5338 - mse: 5.5338 - mae: 1.7493 - val_loss: 15.6844 - val_mse: 15.6844 - val_mae: 2.6743\n",
       "Epoch 33/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 5.5210 - mse: 5.5210 - mae: 1.7367 - val_loss: 15.4227 - val_mse: 15.4227 - val_mae: 2.6561\n",
+      "270/270 [==============================] - 0s 296us/sample - loss: 5.4903 - mse: 5.4903 - mae: 1.7565 - val_loss: 15.3509 - val_mse: 15.3509 - val_mae: 2.6560\n",
       "Epoch 34/50\n",
-      "270/270 [==============================] - 0s 474us/sample - loss: 5.5663 - mse: 5.5663 - mae: 1.7294 - val_loss: 15.3376 - val_mse: 15.3376 - val_mae: 2.6991\n",
+      "270/270 [==============================] - 0s 263us/sample - loss: 5.1933 - mse: 5.1933 - mae: 1.7330 - val_loss: 16.6567 - val_mse: 16.6567 - val_mae: 2.7299\n",
       "Epoch 35/50\n",
-      "270/270 [==============================] - 0s 626us/sample - loss: 5.0063 - mse: 5.0063 - mae: 1.6196 - val_loss: 15.2642 - val_mse: 15.2642 - val_mae: 2.6796\n",
+      "270/270 [==============================] - 0s 207us/sample - loss: 5.1498 - mse: 5.1498 - mae: 1.7357 - val_loss: 16.6105 - val_mse: 16.6105 - val_mae: 2.7471\n",
       "Epoch 36/50\n",
-      "270/270 [==============================] - 0s 459us/sample - loss: 4.7251 - mse: 4.7251 - mae: 1.5727 - val_loss: 15.4858 - val_mse: 15.4858 - val_mae: 2.7288\n",
+      "270/270 [==============================] - 0s 307us/sample - loss: 5.3917 - mse: 5.3917 - mae: 1.7253 - val_loss: 15.3130 - val_mse: 15.3130 - val_mae: 2.6539\n",
       "Epoch 37/50\n",
-      "270/270 [==============================] - 0s 604us/sample - loss: 4.6394 - mse: 4.6394 - mae: 1.5854 - val_loss: 15.1139 - val_mse: 15.1139 - val_mae: 2.6305\n",
+      "270/270 [==============================] - 0s 215us/sample - loss: 5.4485 - mse: 5.4485 - mae: 1.7538 - val_loss: 16.9709 - val_mse: 16.9709 - val_mae: 2.7345\n",
       "Epoch 38/50\n",
-      "270/270 [==============================] - 0s 592us/sample - loss: 4.5669 - mse: 4.5669 - mae: 1.5548 - val_loss: 14.9898 - val_mse: 14.9898 - val_mae: 2.6340\n",
+      "270/270 [==============================] - 0s 207us/sample - loss: 5.5646 - mse: 5.5646 - mae: 1.7860 - val_loss: 16.8329 - val_mse: 16.8329 - val_mae: 2.6953\n",
       "Epoch 39/50\n",
-      "270/270 [==============================] - 0s 458us/sample - loss: 4.4480 - mse: 4.4480 - mae: 1.5334 - val_loss: 15.6389 - val_mse: 15.6389 - val_mae: 2.7337\n",
+      "270/270 [==============================] - 0s 211us/sample - loss: 5.1656 - mse: 5.1656 - mae: 1.7383 - val_loss: 15.4439 - val_mse: 15.4439 - val_mae: 2.6607\n",
       "Epoch 40/50\n",
-      "270/270 [==============================] - 0s 455us/sample - loss: 4.4119 - mse: 4.4119 - mae: 1.5426 - val_loss: 15.0723 - val_mse: 15.0723 - val_mae: 2.6709\n",
+      "270/270 [==============================] - 0s 208us/sample - loss: 5.0184 - mse: 5.0184 - mae: 1.6846 - val_loss: 16.0934 - val_mse: 16.0934 - val_mae: 2.6308\n",
       "Epoch 41/50\n",
-      "270/270 [==============================] - 0s 473us/sample - loss: 4.0797 - mse: 4.0797 - mae: 1.4725 - val_loss: 15.4706 - val_mse: 15.4706 - val_mae: 2.6707\n",
+      "270/270 [==============================] - 0s 219us/sample - loss: 4.7907 - mse: 4.7907 - mae: 1.6674 - val_loss: 16.4855 - val_mse: 16.4855 - val_mae: 2.7091\n",
       "Epoch 42/50\n",
-      "270/270 [==============================] - 0s 449us/sample - loss: 4.0619 - mse: 4.0619 - mae: 1.4692 - val_loss: 15.2423 - val_mse: 15.2423 - val_mae: 2.6165\n",
+      "270/270 [==============================] - 0s 326us/sample - loss: 4.9246 - mse: 4.9246 - mae: 1.6599 - val_loss: 15.1504 - val_mse: 15.1504 - val_mae: 2.5720\n",
       "Epoch 43/50\n",
-      "270/270 [==============================] - 0s 465us/sample - loss: 4.1861 - mse: 4.1861 - mae: 1.5076 - val_loss: 15.7510 - val_mse: 15.7510 - val_mae: 2.7279\n",
+      "270/270 [==============================] - 0s 219us/sample - loss: 4.6432 - mse: 4.6432 - mae: 1.6235 - val_loss: 15.3043 - val_mse: 15.3043 - val_mae: 2.6166\n",
       "Epoch 44/50\n",
-      "270/270 [==============================] - 0s 462us/sample - loss: 4.1128 - mse: 4.1128 - mae: 1.4810 - val_loss: 15.4814 - val_mse: 15.4814 - val_mae: 2.6562\n",
+      "270/270 [==============================] - 0s 226us/sample - loss: 4.3992 - mse: 4.3992 - mae: 1.5564 - val_loss: 15.2977 - val_mse: 15.2977 - val_mae: 2.6267\n",
       "Epoch 45/50\n",
-      "270/270 [==============================] - 0s 441us/sample - loss: 4.2171 - mse: 4.2171 - mae: 1.5205 - val_loss: 16.3839 - val_mse: 16.3839 - val_mae: 2.8194\n",
+      "270/270 [==============================] - 0s 225us/sample - loss: 4.7058 - mse: 4.7058 - mae: 1.6265 - val_loss: 15.6111 - val_mse: 15.6111 - val_mae: 2.6855\n",
       "Epoch 46/50\n",
-      "270/270 [==============================] - 0s 422us/sample - loss: 4.2609 - mse: 4.2609 - mae: 1.5548 - val_loss: 15.3587 - val_mse: 15.3587 - val_mae: 2.7161\n",
+      "270/270 [==============================] - 0s 211us/sample - loss: 5.1424 - mse: 5.1424 - mae: 1.7455 - val_loss: 16.8227 - val_mse: 16.8227 - val_mae: 2.6894\n",
       "Epoch 47/50\n",
-      "270/270 [==============================] - 0s 454us/sample - loss: 4.4635 - mse: 4.4635 - mae: 1.5440 - val_loss: 15.7736 - val_mse: 15.7736 - val_mae: 2.7184\n",
+      "270/270 [==============================] - 0s 300us/sample - loss: 4.4972 - mse: 4.4972 - mae: 1.6076 - val_loss: 14.8339 - val_mse: 14.8339 - val_mae: 2.5972\n",
       "Epoch 48/50\n",
-      "270/270 [==============================] - 0s 426us/sample - loss: 3.7406 - mse: 3.7406 - mae: 1.4147 - val_loss: 15.6718 - val_mse: 15.6718 - val_mae: 2.7468\n",
+      "270/270 [==============================] - 0s 207us/sample - loss: 4.5349 - mse: 4.5349 - mae: 1.6233 - val_loss: 15.4342 - val_mse: 15.4342 - val_mae: 2.6567\n",
       "Epoch 49/50\n",
-      "270/270 [==============================] - 0s 445us/sample - loss: 3.6173 - mse: 3.6173 - mae: 1.3816 - val_loss: 15.7291 - val_mse: 15.7291 - val_mae: 2.7789\n",
+      "270/270 [==============================] - 0s 211us/sample - loss: 4.2952 - mse: 4.2952 - mae: 1.5607 - val_loss: 16.7860 - val_mse: 16.7860 - val_mae: 2.7311\n",
       "Epoch 50/50\n",
-      "270/270 [==============================] - 0s 430us/sample - loss: 3.6303 - mse: 3.6303 - mae: 1.4266 - val_loss: 15.4937 - val_mse: 15.4937 - val_mae: 2.7390\n"
+      "270/270 [==============================] - 0s 300us/sample - loss: 4.2646 - mse: 4.2646 - mae: 1.5281 - val_loss: 14.3684 - val_mse: 14.3684 - val_mae: 2.5073\n"
      ]
     },
     {
      "data": {
       "text/plain": [
-       "<tensorflow.python.keras.callbacks.History at 0x7f315c319be0>"
+       "<tensorflow.python.keras.callbacks.History at 0x1dd864248d0>"
       ]
      },
      "execution_count": 8,
@@ -913,7 +926,8 @@
     }
    ],
    "source": [
-    "wandb.init(project=\"boston\", entity=\"lambda-ds7\") #Initializes and Experiment\n",
+    "# entity is \n",
+    "wandb.init(project=\"boston\", entity=\"ds8\") #Initializes and Experiment\n",
     "\n",
     "# Important Hyperparameters\n",
     "X =  x_train\n",
@@ -1153,9 +1167,9 @@
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "conda_tensorflow_p36",
+   "display_name": "U4-S2-NN",
    "language": "python",
-   "name": "conda_tensorflow_p36"
+   "name": "u4-s2-nn"
   },
   "language_info": {
    "codemirror_mode": {
@@ -1167,7 +1181,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.5"
+   "version": "3.7.0"
   }
  },
  "nbformat": 4,
